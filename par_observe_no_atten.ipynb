{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1489, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#從grid_search_weight中找尋不同的file \n",
    "path = '../Data/grid_search_weight/0130_15D_no_atten/'\n",
    "files = os.listdir(path)\n",
    "len(files)\n",
    "np.load(path+files[0])['U'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_sum(pars):\n",
    "    all_squ_sum = []\n",
    "    for par in pars:\n",
    "        all_squ_sum.append(np.sum(np.multiply(par,par)))\n",
    "    return all_squ_sum \n",
    "def shape_sum(pars):\n",
    "    all_shape = []\n",
    "    for par in pars:\n",
    "        all_shape.append(par.shape)\n",
    "    return all_shape\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_category after normalized by max...\n",
      "user_category_norm shape  (1489, 17)\n",
      "Min number of followings  5\n",
      "Max number of followings  34\n",
      "5.466666666666667\n"
     ]
    }
   ],
   "source": [
    "user_following = np.load('../Data/npy/user_following_1489.npy')\n",
    "all_3374 = np.load('../Data/npy/all_3239_NormnoEmbedding.npy')\n",
    "user_category = np.load('../Data/npy/user_category_1489.npy')\n",
    "YouTuber_category = np.load('../Data/npy/YouTuber_category_0.7.npy')\n",
    "active_users = np.load('../Data/npy/active_userID_1489.npy')\n",
    "\n",
    "#over5 = 0\n",
    "#for num in YouTuber_followers:\n",
    "#    if num >= 5:\n",
    "#        over5+=1\n",
    "#print('The num of followers over 5:',over5)\n",
    "user_category_norm = np.zeros(user_category.shape)\n",
    "for i in range(len(user_category)):\n",
    "    user_category_norm[i] = user_category[i]/np.max(user_category[i])\n",
    "print('user_category after normalized by max...')\n",
    "print('user_category_norm shape ',user_category_norm.shape)\n",
    "following_true = [0]*len(user_following)\n",
    "for i in range(len(user_following)):\n",
    "    each_user = []\n",
    "    for j in range(len(user_following[i])):\n",
    "        if user_following[i][j] == 1:\n",
    "            each_user.append(j)\n",
    "    following_true[i] = each_user\n",
    "#print(following_true)\n",
    "#最少跟最多的following \n",
    "minlen = 10000\n",
    "maxlen = 0\n",
    "num_of_follower = []\n",
    "for i in range(len(following_true)):\n",
    "    if len(following_true[i]) < minlen:\n",
    "        minlen = len(following_true[i])\n",
    "    if len(following_true[i]) > maxlen:\n",
    "        maxlen = len(following_true[i])\n",
    "    num_of_follower.append(len(following_true[i]))\n",
    "print('Min number of followings ',minlen)\n",
    "print('Max number of followings ',maxlen)\n",
    "test_amount = 150\n",
    "yt_test_amount = 18\n",
    "user_idx = [i for i in range(len(user_following))]\n",
    "#user_idx = user_idx_over10\n",
    "#test_idx is the number of user for testing\n",
    "random.seed(5)\n",
    "test_idx = random.sample(user_idx,test_amount)\n",
    "# Training  and Testing --New\n",
    "train_t = [0]*(len(user_following))\n",
    "train_f = [0]*(len(user_following))\n",
    "# Testing \n",
    "test_t = [0]*test_amount\n",
    "test_f = [0]*test_amount\n",
    "test_pos = -1\n",
    "\n",
    "for i in range(len(user_following)):\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "        for j in range(88):\n",
    "            if user_following[i][j] == 1:\n",
    "                t_for_train.append(j)\n",
    "            else:\n",
    "                f_for_train.append(j)\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train\n",
    "        \n",
    "    else: #if in test id, choose 2 true and other \n",
    "        test_pos += 1\n",
    "        temp_t = []\n",
    "        temp_f = []\n",
    "        for j in range(88):\n",
    "            if user_following[i][j] == 1:\n",
    "                temp_t.append(j)\n",
    "            else:\n",
    "                temp_f.append(j)\n",
    "        #print(len(temp_t),math.ceil(0.5*len(temp_t)))\n",
    "        t_for_test = random.sample(temp_t,math.ceil(0.5*len(temp_t)))\n",
    "        f_for_test  = random.sample(temp_f,yt_test_amount-len(t_for_test))\n",
    "        \n",
    "        test_t[test_pos] = t_for_test\n",
    "        test_f[test_pos] = f_for_test\n",
    "        \n",
    "        #other for training\n",
    "        t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "        #print(len(t_for_train ))\n",
    "        f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test/test_amount\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScoreMatrix(RS):\n",
    "    #取出test的資料\n",
    "    testRS = np.zeros((test_amount,yt_test_amount)) #shape 150*20\n",
    "    target = np.zeros((test_amount,yt_test_amount))\n",
    "    #test_t 是true的\n",
    "    #test_f 是false的\n",
    "\n",
    "    for z in range(test_amount):\n",
    "        user_id = test_idx[z]\n",
    "        #positive target YouTuber list\n",
    "        youtube_t = test_t[z] \n",
    "        #not target YouTuber list\n",
    "        youtube_f = test_f[z]\n",
    "\n",
    "        #前兩個放target的RS\n",
    "        for i in range(len(youtube_t)):\n",
    "            testRS[z][i] = RS[z][youtube_t[i]]\n",
    "            target[z][i] = 1\n",
    "        for i in range(len(youtube_f)):\n",
    "            testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]\n",
    "    sumtarget = 0\n",
    "    for i in range(len(target)):\n",
    "        #print(np.sum(target[i]))\n",
    "        sumtarget += np.sum(target[i])\n",
    "    print('num of positive data in testing:',sumtarget)\n",
    "    print('total testing data:',test_amount*yt_test_amount)\n",
    "    return target, testRS,sumtarget\n",
    "\n",
    "def topN(sortlist,n):\n",
    "    topList = []\n",
    "    for i in range(n):\n",
    "        topList.append(sortlist.index(max(sortlist)))\n",
    "        #print(max(sortlist))\n",
    "        #print(sortlist.index(max(sortlist)))\n",
    "        sortlist[sortlist.index(max(sortlist))] = -1000000000\n",
    "    return topList\n",
    "\n",
    "def F1_score(prec,rec):\n",
    "    f1 = (2*prec*rec)/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTOP1(target,testRS,sumtarget):\n",
    "    print('top1')\n",
    "    correct = 0\n",
    "    for i in range(len(testRS)):\n",
    "        top_0 = topN(list(testRS[i]),1) #取一個\n",
    "        \n",
    "        #print(top_0)\n",
    "        if top_0[0] < int(np.sum(target[i])):\n",
    "            correct += 1\n",
    "    top1_prec = correct/len(testRS)\n",
    "    top1_recall = correct/(sumtarget)\n",
    "    print('prec ',top1_prec,'recall ',top1_recall)\n",
    "    #f1 score\n",
    "    print('F1_score:',F1_score(top1_prec,top1_recall))\n",
    "    return top1_prec,top1_recall,F1_score(top1_prec,top1_recall)\n",
    "def getTOP3(target,testRS,sumtarget):\n",
    "    print('top3')\n",
    "    correct = 0\n",
    "    for i in range(len(testRS)):\n",
    "        top_3 = topN(list(testRS[i]),3) #取一個\n",
    "        \n",
    "        #print(top_3)\n",
    "        for j in range(len(top_3)):\n",
    "            if top_3[j] < int(np.sum(target[i])):\n",
    "                correct += 1\n",
    "    top3_prec = correct/(len(testRS)*3)\n",
    "    top3_recall = correct/(sumtarget)\n",
    "    print('prec ',top3_prec,'recall ',top3_recall)\n",
    "    #f1 score\n",
    "    print('F1_score:',F1_score(top3_prec,top3_recall))\n",
    "    return top3_prec,top3_recall,F1_score(top3_prec,top3_recall)\n",
    "def getTOP5(target,testRS,sumtarget):\n",
    "    print('top5')\n",
    "    correct = 0\n",
    "    for i in range(len(testRS)):\n",
    "        top_5 = topN(list(testRS[i]),5) #取一個\n",
    "       \n",
    "        #print(top_5)\n",
    "        for j in range(len(top_5)):\n",
    "            if top_5[j] < int(np.sum(target[i])):\n",
    "                correct += 1\n",
    "    top5_prec = correct/(len(testRS)*5)\n",
    "    top5_recall = correct/(sumtarget)\n",
    "    print('prec ',top5_prec,'recall ',top5_recall)\n",
    "    #f1 score\n",
    "    print('F1_score:',F1_score(top5_prec,top5_recall))\n",
    "    return top5_prec,top5_recall,F1_score(top5_prec,top5_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NDCG\n",
    "https://daiwk.github.io/posts/nlp-ndcg.html\n",
    "\"\"\"\n",
    "# pre_list\n",
    "\"\"\"\n",
    "test_amount = 150\n",
    "yt_test_amount = 18\n",
    "\"\"\"\n",
    "def NDCG(target,testRS):\n",
    "    all_sort = []\n",
    "    num_ndcg = 10\n",
    "    pre_matrix = np.zeros(shape=(test_amount,yt_test_amount))\n",
    "    for i in range(test_amount):\n",
    "        top_n = topN(list(testRS[i]),num_ndcg) #取一個\n",
    "        #print(top_n)\n",
    "        all_sort.append(topN(list(testRS[i]),len(testRS[i])))\n",
    "        for j in range(len(top_n)):\n",
    "            pre_matrix[i][top_n[j]] = 1\n",
    "\n",
    "    #Ideal DCG，理想状况下的DCG。也就是说，相关性完全由高到低排序时算出的DCG：\n",
    "    def IDCG(ideal_list): #ideal_list example = [1,1,1,1,1,0,0,....]\n",
    "        idcg=0\n",
    "        #print('ideal',ideal_list)\n",
    "        for i in range(len(ideal_list)):\n",
    "            #print((2**true_list[i]-1),math.log2(i+2))\n",
    "            idcg+= (2**ideal_list[i]-1)/ math.log2(i+2)\n",
    "        #print('idcg',idcg)\n",
    "        return idcg\n",
    "    def DCG(prec_list): #找出前n名的[1,1,1,0,...]\n",
    "        dcg=0\n",
    "        print('prec',prec_list)\n",
    "        for i in range(len(prec_list)):\n",
    "            dcg+= (2**prec_list[i]-1)/ math.log2(i+2)\n",
    "        #print('dcg',dcg)\n",
    "        return dcg\n",
    "    total_ndcg = 0\n",
    "    \n",
    "    for m in range(test_amount): # the number of testing users\n",
    "        idcg = IDCG(target[m][:num_ndcg])\n",
    "        pre_list = []\n",
    "        least_pre_list = []\n",
    "        for s in all_sort[m][:num_ndcg]:\n",
    "            #print(s)\n",
    "            #print(target[m][s])\n",
    "            pre_list.append(target[m][s]) #把prec_list 的 score加進去\n",
    "        for s in all_sort[m][num_ndcg:]:\n",
    "            #print(s)\n",
    "            #print(target[m][s])\n",
    "            least_pre_list.append(target[m][s]) #把prec_list 的 score加進去\n",
    "        dcg = DCG(pre_list)\n",
    "        ndcg = dcg/idcg\n",
    "        #print(ndcg)\n",
    "        total_ndcg += ndcg\n",
    "    avg_ndcg = total_ndcg/test_amount\n",
    "    print('NDCG:',avg_ndcg)\n",
    "    return pre_matrix,avg_ndcg\n",
    "\n",
    "# MAP\n",
    "\"\"\"\n",
    ">>> y_true = np.array([0, 0, 1, 1])\n",
    ">>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    ">>> average_precision_score(y_true, y_scores)\n",
    "\"\"\"\n",
    "def MAP(target,pre_matrix):\n",
    "    print('target:',target)\n",
    "    print('predict:',pre_matrix)\n",
    "    total_prec = 0\n",
    "    for u in range(test_amount):\n",
    "        y_true = target[u]\n",
    "        y_scores = pre_matrix[u]\n",
    "        total_prec+=average_precision_score(y_true, y_scores)\n",
    "    Map_value = total_prec/test_amount\n",
    "    print('MAP',Map_value)\n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(U, Y, E,B):\n",
    "    \"\"\"\n",
    "    print('U shape',U.shape)\n",
    "    print('Y shape',Y.shape)\n",
    "    print('A shape',A.shape)\n",
    "    print('E shape',E.shape)\n",
    "    print('Wv shape',Av.shape)\n",
    "    print(np.max(Au))\n",
    "    print(np.max(Ay))\n",
    "    print(np.max(Aa))\n",
    "    print(np.max(Av))\n",
    "    print(np.max(B))\n",
    "    \"\"\"\n",
    "    test_amount = 150\n",
    "    yt_test_amount = 18\n",
    "    result=np.zeros((test_amount,88))\n",
    "    RS=np.zeros((test_amount,88))\n",
    "    #test_idx --> Test 的 index\n",
    "    sum_alpha = 0\n",
    "    for s in range(test_amount):\n",
    "        #print(s,test_idx[s])\n",
    "\n",
    "            \n",
    "            \n",
    "        mul=np.zeros((1,64))\n",
    "        #print('alpha--------',alpha)\n",
    "        #print('add alpha------------',np.add(alpha,0.000000001))\n",
    "        #added_alpha = np.add(alpha,0.0000000001)\n",
    "        #norm_alpha = added_alpha/np.sum(added_alpha)\n",
    "        #print('alpha-----------',alpha)\n",
    "        #print('norm alpha--------------',norm_alpha)\n",
    "        #sum_alpha += np.sum(alpha)\n",
    "        #for i in range(len(sample)):\n",
    "        #    mul+=norm_alpha[i]*A[sample[i]] #attention alpha*Ai part\n",
    "        new_mul=mul+U[test_idx[s]]  #(U+auxilary)\n",
    "    \n",
    "        \n",
    "        \n",
    "        for k in range(88):\n",
    "            result[s][k]=np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "            RS[s][k] = np.dot(new_mul,Y[k].T)+np.dot(B[test_idx[s]],np.dot(E, all_3374[k].T))\n",
    "            \"\"\"\n",
    "            print('================================')\n",
    "            print('U',np.sum(U[test_idx[s]] ))\n",
    "            print('A',np.sum(mul))\n",
    "            print('Y',np.sum(Y[k]))\n",
    "            print('B',np.sum(B[test_idx[s]]))\n",
    "            print('E',np.sum(np.dot(E, all_3374[k].T)))\n",
    "            print('User',np.dot(U[test_idx[s]],Y[k].T))\n",
    "            print('Aux',np.dot(mul,Y[k].T))\n",
    "            print('Former',np.dot(new_mul,Y[k].T))\n",
    "            print('Later',np.dot(B[test_idx[s]],np.dot(E, all_3374[k].T)))\n",
    "            print('RS',np.dot(new_mul,Y[k].T)+np.dot(B[test_idx[s]],np.dot(E, all_3374[k].T)))\n",
    "            print('--------------------------------')\n",
    "            \"\"\"\n",
    "            \n",
    "    #print('sum_alpha',sum_alpha)\n",
    "    return RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.001_0.01_Edims200.npz']\n"
     ]
    }
   ],
   "source": [
    "#With Embedding\n",
    "import os \n",
    "#從grid_search_weight中找尋不同的file \n",
    "path = '../Data/grid_search_weight/0130_15D_no_atten/'\n",
    "all_files = os.listdir(path)\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.001_0.01']\n",
      "0.001_0.01_Edims200.npz\n",
      "num of positive data in testing: 820.0\n",
      "total testing data: 2700\n",
      "top1\n",
      "prec  0.5866666666666667 recall  0.1073170731707317\n",
      "F1_score: 0.18144329896907216\n",
      "top3\n",
      "prec  0.56 recall  0.3073170731707317\n",
      "F1_score: 0.3968503937007874\n",
      "top5\n",
      "prec  0.5386666666666666 recall  0.4926829268292683\n",
      "F1_score: 0.5146496815286624\n",
      "prec [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]\n",
      "prec [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "prec [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "prec [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]\n",
      "prec [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]\n",
      "prec [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]\n",
      "prec [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]\n",
      "prec [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]\n",
      "prec [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]\n",
      "prec [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]\n",
      "prec [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]\n",
      "prec [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]\n",
      "prec [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]\n",
      "prec [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]\n",
      "prec [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "prec [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "prec [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]\n",
      "prec [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n",
      "prec [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]\n",
      "prec [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]\n",
      "prec [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]\n",
      "prec [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "prec [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]\n",
      "prec [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n",
      "prec [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "prec [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n",
      "prec [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]\n",
      "prec [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]\n",
      "prec [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]\n",
      "prec [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "prec [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n",
      "prec [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]\n",
      "prec [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n",
      "prec [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "prec [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "prec [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]\n",
      "NDCG: 0.7089218750763386\n",
      "target: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "predict: [[1. 1. 0. ... 0. 1. 0.]\n",
      " [1. 1. 1. ... 0. 1. 0.]\n",
      " [0. 1. 1. ... 1. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 1.]]\n",
      "MAP 0.4376954563954565\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "par_files = list(set([file.split('_Edims')[0] for file in all_files]))\n",
    "print(par_files)\n",
    "for par_file in par_files:\n",
    "    NDCG_List = []\n",
    "    MAP_List = []\n",
    "    DIM_List = []\n",
    "    TOP1_Prec = []\n",
    "    TOP3_Prec = []\n",
    "    TOP5_Prec = []\n",
    "    TOP1_F1 = []\n",
    "    TOP3_F1 = []\n",
    "    TOP5_F1 = []\n",
    "    TOP1_Recall = []\n",
    "    TOP3_Recall = []\n",
    "    TOP5_Recall = []\n",
    "    \n",
    "    csv_path = '../Data/grid_search_weight/CSV_Tan/'\n",
    "    for file in all_files:\n",
    "        if par_file in file:\n",
    "            print(file)\n",
    "            par_data = np.load(path+file)\n",
    "            U = par_data['U']\n",
    "            Y = par_data['Y']\n",
    "            #A = par_data['A']\n",
    "            E = par_data['E']\n",
    "            #W1 = par_data['W1']\n",
    "            #Wu = par_data['Wu']\n",
    "            #Wy = par_data['Wy']\n",
    "            #Wa = par_data['Wa']\n",
    "            #Wv = par_data['Wv']\n",
    "            B = par_data['B']\n",
    "            RS = testing(U, Y, E,B)\n",
    "            target,testRS,sumtarget = getScoreMatrix(RS)\n",
    "            prec_1,recall_1,f1_1 = getTOP1(target,testRS,sumtarget)\n",
    "            prec_3,recall_3,f1_3 = getTOP3(target,testRS,sumtarget)\n",
    "            prec_5,recall_5,f1_5 = getTOP5(target,testRS,sumtarget)\n",
    "            pre_matrix,avg_ndcg = NDCG(target,testRS)\n",
    "            Map_value = MAP(target,pre_matrix)\n",
    "            NDCG_List.append(avg_ndcg)\n",
    "            MAP_List.append(Map_value)\n",
    "            DIM_List.append(file.split('Edims')[1].split('.npz')[0])\n",
    "            TOP1_Prec.append(prec_1)\n",
    "            TOP1_Recall.append(recall_1)\n",
    "            TOP1_F1.append(f1_1)\n",
    "            TOP3_Prec.append(prec_3)\n",
    "            TOP3_Recall.append(recall_3)\n",
    "            TOP3_F1.append(f1_3)\n",
    "            TOP5_Prec.append(prec_5)\n",
    "            TOP5_Recall.append(recall_5)\n",
    "            TOP5_F1.append(f1_5)\n",
    "            print('--------------------------------------------------------------------------------------------')\n",
    "    #print(NDCG_List)\n",
    "    #print(DIM_List)\n",
    "    result_dict = {'Dims':DIM_List,'NDCG':NDCG_List,'MAP':MAP_List,\n",
    "                   'TOP1 Precision':TOP1_Prec,'TOP1 Recall':TOP1_Recall,'TOP1 F1':TOP1_F1,\n",
    "                  'TOP3 Precision':TOP3_Prec,'TOP3 Recall':TOP3_Recall,'TOP3 F1':TOP3_F1,\n",
    "                  'TOP5 Precision':TOP5_Prec,'TOP5 Recall':TOP5_Recall,'TOP5 F1':TOP5_F1}\n",
    "    df = pd.DataFrame(result_dict)\n",
    "    df.to_csv(csv_path+par_file+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.01_0.01_0.001_0.01']\n",
      "0.01_0.01_0.001_0.01 0.01_0.01_0.001_0.01_Edims100.npz\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Wve is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-600c92c6d0a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mWa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpar_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Wa'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mWv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpar_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Wv'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mWve\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpar_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Wve'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpar_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'B'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mRS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mWu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mWve\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not a file in the archive\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Wve is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "#With Embedding\n",
    "import os \n",
    "#從grid_search_weight中找尋不同的file \n",
    "path = '../Data/grid_search_weight/0113/'\n",
    "all_files = os.listdir(path)\n",
    "#print(files)\n",
    "par_files = list(set([file.split('_Edims')[0] for file in all_files]))\n",
    "print(par_files)\n",
    "for par_file in par_files:\n",
    "    NDCG_List = []\n",
    "    MAP_List = []\n",
    "    DIM_List = []\n",
    "    csv_path = '../Data/grid_search_weight/CSV_Tan/'\n",
    "    for file in all_files:\n",
    "        if par_file in file:\n",
    "            print(par_file,file)\n",
    "            par_data = np.load(path+file)\n",
    "            U = par_data['U']\n",
    "            Y = par_data['Y']\n",
    "            A = par_data['A']\n",
    "            E = par_data['E']\n",
    "            #W1 = par_data['W1']\n",
    "            Wu = par_data['Wu']\n",
    "            Wy = par_data['Wy']\n",
    "            Wa = par_data['Wa']\n",
    "            Wv = par_data['Wv']\n",
    "            Wve = par_data['Wve']\n",
    "            B = par_data['B']\n",
    "            RS = testing(U, Y, A, E,Wu, Wy, Wa, Wv,Wve,B)\n",
    "            target,testRS,sumtarget = getScoreMatrix(RS)\n",
    "            getTOP1(target,testRS,sumtarget)\n",
    "            getTOP3(target,testRS,sumtarget)\n",
    "            getTOP5(target,testRS,sumtarget)\n",
    "            pre_matrix,avg_ndcg = NDCG(target,testRS)\n",
    "            Map_value = MAP(target,pre_matrix)\n",
    "            NDCG_List.append(avg_ndcg)\n",
    "            MAP_List.append(Map_value)\n",
    "            DIM_List.append(file.split('Edims')[1].split('.npz')[0])\n",
    "            print('--------------------------------------------------------------------------------------------')\n",
    "    #print(NDCG_List)\n",
    "    #print(DIM_List)\n",
    "    result_dict = {'Dims':DIM_List,'NDCG':NDCG_List,'MAP':MAP_List}\n",
    "    df = pd.DataFrame(result_dict)\n",
    "    #df.to_csv(csv_path+par_file+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(NDCG_List)):\n",
    "    print(NDCG_List[i],MAP_List[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDCG For Different Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## code here !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN(sortlist,n):\n",
    "    topList = []\n",
    "    for i in range(n):\n",
    "        topList.append(sortlist.index(max(sortlist)))\n",
    "        #print(max(sortlist))\n",
    "        #print(sortlist.index(max(sortlist)))\n",
    "        sortlist[sortlist.index(max(sortlist))] = -1000000000\n",
    "    return topList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1]\n",
      "[3, 6, 2]\n",
      "[1, 2, 13, 4, 5, 3, 17]\n",
      "[1, 10, 8, 2, 5, 4]\n",
      "[4, 1, 12]\n",
      "[1, 15, 11]\n",
      "[2, 1, 10, 0]\n",
      "[3, 2, 5, 7, 4, 18]\n",
      "[3, 18, 8, 5, 13]\n",
      "[12, 16, 7, 0, 9]\n",
      "avg_accuarcy for count_0: 0.24\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "count_0_all = []\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),int(np.sum(target[i])))\n",
    "    count_0_all.append(top_0)\n",
    "    print(top_0)\n",
    "\n",
    "acc_0 = 0\n",
    "total = 0\n",
    "for i in range(len(count_0_all)):\n",
    "    for j in range(len(count_0_all[i])):\n",
    "        #print(int(np.sum(target[i])))\n",
    "        total+=int(np.sum(target[i]))\n",
    "        if count_0_all[i][j] < int(np.sum(target[i])): #代表是0或1 (也就是target)\n",
    "            acc_0 += 1\n",
    "avg_acc = acc_0/100\n",
    "print('avg_accuarcy for count_0:',avg_acc)\n",
    "print(acc_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOP1,TOP3,TOP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = (2*prec*rec)/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDCG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14409628, 0.14409674, 0.14135303, 0.14211949, 0.14409625,\n",
       "       0.14211893, 0.14211929])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_list = [0.02162337, 0.02162659, 0.00240219, 0.00780985, 0.02162318, 0.00780592, 0.00780849]\n",
    "softmax(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
