{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_following = np.load('../Data/npy/user_following.npy')\n",
    "image_2048 = np.load('../Data/npy/Social_64D.npy')\n",
    "user_category = np.load('../Data/npy/user_category_1216.npy')\n",
    "YouTuber_category = np.load('../Data/npy/YouTuber_category_0.7.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_following shape  (1489, 88)\n",
      "following_64 shape  (88, 64)\n",
      "user_category shape  (1489, 17)\n",
      "YouTuber_category shape  (88, 17)\n"
     ]
    }
   ],
   "source": [
    "print('user_following shape ',user_following.shape)\n",
    "print('following_64 shape ',image_2048.shape)\n",
    "print('user_category shape ',user_category.shape)\n",
    "print('YouTuber_category shape ',YouTuber_category.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_category after normalized by max...\n",
      "user_category_norm shape  (1489, 17)\n"
     ]
    }
   ],
   "source": [
    "user_category_norm = np.zeros(user_category.shape)\n",
    "for i in range(len(user_category)):\n",
    "    user_category_norm[i] = user_category[i]/np.max(user_category[i])\n",
    "print('user_category after normalized by max...')\n",
    "print('user_category_norm shape ',user_category_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13, 15, 16, 24, 29, 37, 44], [3, 25, 67, 71, 74, 75, 82], [8, 11, 24, 28, 41, 63, 67, 79, 86], [8, 24, 28, 29, 63, 70, 79], [8, 24, 37, 63, 67, 70, 79], [8, 17, 24, 25, 31, 43, 63, 67, 70, 73, 74, 79], [3, 10, 11, 22, 40, 44, 47, 74, 76, 82], [8, 17, 21, 27, 28, 32, 33, 45, 49, 67, 75, 82, 84], [3, 25, 63, 74, 79], [3, 10, 11, 14, 25, 40, 45, 54, 60, 65, 67, 74, 75, 79, 82], [3, 11, 22, 24, 40, 54, 57, 63, 67, 74, 76, 79], [7, 11, 14, 24, 25, 40, 43, 54, 63, 67, 75, 79], [7, 8, 24, 41, 63, 79], [0, 11, 12, 25, 26, 27, 32, 33, 42, 44, 45, 60, 67, 69, 71, 72, 74, 76, 79, 82, 84], [8, 24, 29, 43, 57, 63, 67, 76, 79], [3, 8, 25, 28, 40, 75, 79], [8, 54, 63, 67, 70, 79], [3, 9, 10, 25, 40, 44, 45, 54, 60, 67, 71, 74, 76, 82, 84], [8, 10, 28, 40, 43, 45, 54, 67, 76, 79], [25, 32, 33, 67, 71, 82, 83, 84], [8, 24, 43, 63, 67, 70, 79], [8, 24, 28, 29, 41, 44, 57, 79], [8, 14, 24, 29, 41, 43, 57, 63, 67, 78, 79], [0, 12, 26, 27, 32, 33, 53, 55, 72, 84], [12, 17, 18, 27, 32, 33, 43, 45, 56, 63, 67, 71, 75, 84], [16, 25, 67, 71, 74, 76, 79], [8, 17, 24, 28, 41, 57, 63, 67, 70, 74, 79], [17, 19, 25, 26, 27, 42, 43, 71, 74, 83], [8, 17, 24, 28, 41, 43, 57, 63, 67, 70, 71, 79], [12, 25, 26, 27, 32, 44, 59, 60, 72, 74, 82], [8, 11, 14, 25, 28, 29, 40, 54, 63, 70, 71, 74, 76, 79], [8, 24, 29, 63, 79], [7, 8, 24, 28, 29, 40, 54, 63, 67, 79], [8, 10, 11, 12, 17, 18, 22, 25, 28, 40, 43, 54, 63, 67, 74, 76, 79], [2, 11, 24, 43, 47, 66], [12, 17, 18, 19, 39, 86], [8, 24, 37, 43, 57, 79], [3, 8, 10, 25, 31, 40, 54, 67, 71, 74, 79], [2, 14, 40, 54, 79], [45, 74, 76, 82, 84], [0, 9, 16, 21, 26, 27, 32, 33, 35, 37, 45, 60, 67, 71, 72, 74, 75, 79, 82, 84], [27, 32, 33, 59, 60, 84], [10, 11, 14, 24, 29, 43, 54, 67, 74, 79], [3, 8, 11, 17, 24, 28, 40, 41, 70, 79], [0, 12, 17, 25, 27, 32, 33, 43, 60, 67, 71, 72, 74, 82, 84, 86], [3, 25, 26, 27, 37, 45, 54, 60, 67, 74, 82, 84], [8, 10, 24, 28, 29, 41, 43, 57, 63, 67, 70], [17, 25, 32, 33, 45, 56, 60, 67, 69, 74, 84], [11, 25, 40, 44, 76], [0, 8, 24, 32, 43, 79], [0, 21, 27, 32, 33, 45, 60, 67, 74, 82, 84], [20, 28, 29, 43, 63, 67, 79], [8, 17, 24, 28, 29, 41, 43, 63, 67, 70, 79], [8, 24, 40, 43, 79], [3, 10, 14, 24, 25, 29, 40, 49, 54, 63, 67, 75, 79], [8, 54, 67, 71, 74, 79, 82], [0, 26, 27, 32, 33, 42, 45, 59, 74, 82, 84], [8, 11, 24, 28, 29, 41, 43, 57], [12, 26, 27, 32, 33, 43, 45, 55, 60, 67, 71, 72, 84], [8, 17, 24, 60, 63, 67, 71, 79], [10, 14, 25, 74, 79], [0, 11, 12, 17, 21, 25, 27, 32, 43, 45, 49, 60, 67, 71, 74, 75, 79, 82, 84], [8, 25, 28, 45, 47, 60, 67, 74, 82, 84], [3, 7, 10, 11, 16], [3, 7, 10, 14, 29, 40, 54, 67, 76, 79], [8, 17, 24, 25, 28, 29, 43, 45, 57, 63, 67, 71, 74, 75, 79, 82], [8, 17, 24, 28, 41, 43, 57, 63, 67, 70, 79], [3, 10, 11, 21, 25, 28, 29, 40, 41, 45, 49, 60, 63, 67, 74, 75, 79, 80, 82], [8, 10, 54, 67, 74, 79], [10, 11, 14, 38, 40, 54], [3, 9, 11, 25, 40, 45, 67, 79, 82], [3, 14, 25, 32, 33, 45, 49, 60, 67, 74, 75, 76, 79, 83, 84], [3, 8, 17, 25, 41, 43, 63, 67, 70, 76, 79], [11, 12, 26, 27, 33, 54, 72, 74, 84], [10, 11, 14, 22, 71, 74, 76], [10, 11, 25, 40, 54, 60, 63, 67, 74, 79, 82], [11, 16, 67, 74, 76, 79, 80], [8, 11, 28, 43, 57, 63, 67, 70, 74, 79], [17, 21, 25, 28, 45, 49, 60, 62, 67, 74, 82], [7, 8, 10, 11, 40, 43, 54, 67, 75, 79], [8, 24, 29, 43, 57, 63, 67, 70, 79], [8, 9, 11, 17, 25, 37, 43, 60, 63, 67, 79, 82], [8, 17, 24, 28, 54, 63, 67, 70, 79], [4, 7, 9, 10, 74, 77], [3, 7, 10, 11, 24, 25, 40, 49, 54, 63, 67, 74, 79], [3, 10, 11, 25, 40, 45, 54, 60, 74, 79, 82, 86], [8, 11, 14, 24, 67, 79], [8, 24, 28, 29, 41, 43, 57, 63, 70, 79], [8, 14, 25, 45, 54, 60, 67, 74, 79, 82], [3, 7, 9, 10, 16, 37, 40, 44, 78], [8, 17, 24, 28, 29, 41, 43, 57, 63, 67, 70, 79], [3, 7, 9, 10, 25, 43, 57, 67, 74, 75, 76, 79, 80], [8, 24, 28, 29, 57, 67, 79], [11, 14, 24, 54, 63, 67, 74, 79], [3, 8, 25, 28, 29, 45, 67, 71, 74, 76, 82], [3, 7, 10, 11, 14, 37, 38, 40, 44, 45, 49, 54, 60, 74, 76, 78, 79, 82, 86], [8, 10, 11, 17, 24, 40, 41, 43, 63, 67, 74, 79, 86], [3, 8, 11, 17, 24, 25, 57, 63, 67, 71, 74, 79], [25, 26, 27, 32, 33, 35, 53, 60, 62, 82, 84], [17, 25, 40, 49, 54, 67, 71], [2, 16, 20, 37, 44, 46, 76], [3, 8, 10, 11, 14, 23, 24, 28, 31, 40, 50, 63, 67, 70, 75, 79, 80], [8, 11, 17, 24, 28, 41, 43, 57, 63, 67, 70, 74, 79], [8, 11, 54, 67, 79], [0, 26, 27, 32, 33, 45, 60, 67, 72, 74, 82, 84], [3, 11, 25, 38, 40, 49, 60], [10, 21, 25, 32, 33, 45, 54, 60, 71, 74, 82, 84], [0, 6, 12, 26, 32, 33, 36, 44, 53, 59, 72], [17, 18, 24, 29, 32, 43, 55, 70, 71], [10, 21, 25, 44, 45, 60, 67, 75, 82, 84], [8, 24, 41, 76, 79, 80], [3, 11, 25, 63, 67, 74, 76], [25, 26, 27, 32, 33, 45, 59, 60, 67, 74, 79, 84], [8, 11, 17, 24, 28, 43, 63, 67, 70, 74, 79], [16, 25, 31, 36, 40, 71, 80, 82], [8, 13, 16, 28, 40, 41, 43, 63, 70, 76, 79], [3, 8, 10, 14, 25, 28, 29, 40, 54, 63, 74, 75, 79], [3, 7, 10, 11, 14, 38, 40, 49, 54, 67, 71, 74, 76, 79], [8, 17, 24, 28, 29, 41, 43, 63, 67, 70, 79], [8, 14, 17, 18, 24, 25, 41, 43, 45, 54, 60, 63, 67, 70, 79, 82], [11, 16, 22, 40, 49, 79], [3, 7, 8, 25, 33, 43, 63, 67, 74, 79, 83], [11, 14, 25, 67, 74, 76, 79], [0, 4, 10, 11, 16, 20, 25, 26, 33, 37, 38, 44, 45, 54, 74, 76, 82], [8, 28, 63, 67, 79], [4, 10, 25, 32, 33, 40, 45, 60, 67, 74, 76, 82], [13, 16, 37, 67, 74], [11, 12, 17, 25, 27, 32, 33, 45, 55, 60, 72, 73, 74, 76, 84], [0, 8, 25, 42, 67, 69, 71, 74, 76, 79], [0, 12, 21, 25, 27, 30, 32, 33, 67, 72], [3, 7, 8, 17, 24, 25, 28, 29, 38, 40, 41, 43, 57, 63, 67, 70, 75, 79], [0, 11, 12, 26, 27, 32, 33, 53, 60, 72, 74, 75, 81, 82, 84], [3, 8, 17, 24, 28, 29, 41, 43, 54, 63, 67, 70, 79], [8, 40, 54, 74, 79], [28, 29, 43, 67, 79], [25, 67, 74, 76, 79], [25, 27, 33, 60, 74, 83, 84, 86], [0, 25, 60, 72, 74, 76, 82, 84], [8, 24, 28, 29, 57, 63], [0, 25, 33, 59, 76, 83, 84], [3, 8, 11, 25, 28, 49, 60, 63, 67, 74, 79, 82], [3, 10, 11, 21, 25, 27, 33, 40, 45, 60, 67, 74, 82, 84], [0, 25, 27, 32, 33, 42, 44, 60, 67, 71, 72, 82, 84], [7, 10, 11, 40, 49, 74, 79], [3, 8, 11, 14, 25, 32, 33, 40, 43, 45, 49, 54, 60, 67, 70, 71, 74, 75, 79, 82], [7, 17, 18, 25, 31, 43], [29, 43, 54, 57, 79], [11, 14, 24, 36, 37, 40, 43, 54, 57, 67, 76, 79], [0, 6, 12, 26, 27, 32, 33, 44, 59, 67, 72, 83, 84], [11, 12, 27, 32, 67, 79, 84], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [11, 22, 24, 38, 75], [17, 25, 32, 45, 67, 71, 74, 82, 84], [3, 7, 11, 25, 27, 32, 33, 45, 60, 67, 71, 79, 82, 84], [9, 16, 17, 21, 24, 27, 32, 33, 37, 43, 60, 63, 67, 74, 79, 82, 83, 84], [3, 8, 10, 11, 14, 25, 40, 54, 63, 74, 76, 79], [21, 25, 32, 33, 45, 60, 67, 71, 74, 82, 84], [9, 10, 11, 15, 16, 37, 76], [22, 25, 44, 45, 57, 67, 71, 74, 76, 79, 82], [3, 25, 67, 74, 79, 82, 86], [8, 11, 14, 25, 49, 59, 63, 67, 71, 74, 75, 82], [0, 21, 31, 60, 76, 82, 84], [8, 11, 14, 17, 24, 28, 41, 43, 54, 63, 67, 70, 74, 76, 78, 79], [0, 12, 25, 26, 27, 32, 33, 35, 37, 44, 55, 60, 72, 74, 76, 82, 83, 84], [10, 11, 21, 38, 67, 74, 76], [3, 20, 25, 74, 82], [8, 24, 41, 63, 67, 79], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [3, 9, 10, 11, 40, 57, 66], [11, 25, 32, 45, 60, 67, 74, 76, 82, 84], [7, 26, 32, 33, 45, 60, 84], [3, 10, 11, 14, 25, 40, 67, 71, 75, 79, 82], [3, 7, 11, 25, 40], [3, 7, 17, 24, 25, 40, 67, 74, 75, 79], [26, 27, 44, 67, 71, 74, 76, 79, 83, 84], [30, 32, 33, 60, 72, 84], [0, 25, 27, 32, 33, 45, 67, 74, 76, 82, 84], [8, 24, 40, 43, 54, 63, 67, 78, 82], [3, 8, 10, 11, 14, 17, 24, 25, 28, 29, 40, 44, 54, 63, 67, 74, 76, 79, 82], [3, 7, 8, 10, 11, 24, 25, 28, 38, 40, 44, 49, 54, 60, 63, 67, 71, 74, 75, 79, 82], [3, 11, 67, 75, 79], [24, 28, 41, 63, 79, 80], [27, 32, 33, 37, 45, 67, 71, 74, 76, 82, 84], [3, 11, 40, 59, 67, 79], [0, 12, 26, 32, 33, 59, 60, 72, 74, 84], [7, 8, 10, 11, 28, 40, 63, 67, 79], [11, 25, 38, 40, 44, 74, 76], [3, 8, 10, 11, 24, 29, 40, 43, 44, 57, 63, 76, 79], [0, 21, 25, 26, 30, 32, 33, 35, 45, 55, 59, 60, 72, 74, 76, 82, 84, 86], [8, 11, 24, 28, 29, 63, 67, 79], [7, 8, 14, 17, 24, 43, 54, 63, 67, 71, 74, 79], [10, 11, 25, 54, 71, 82], [3, 25, 49, 67, 71, 76, 79, 80], [0, 6, 19, 25, 27, 32, 33, 45, 60, 67, 72, 74, 82, 83], [3, 14, 25, 31, 54, 67, 71, 72, 74, 76, 79, 86], [0, 12, 25, 26, 27, 42, 45, 54, 60, 67, 71, 72, 74, 79, 82, 84], [8, 14, 24, 40, 43, 54, 63, 79], [8, 24, 28, 29, 57, 67, 79], [0, 12, 17, 18, 21, 32, 67, 71, 84], [0, 3, 8, 10, 11, 14, 17, 24, 25, 27, 28, 38, 40, 41, 43, 49, 54, 63, 67, 71, 74, 75, 79, 82], [3, 7, 11, 17, 24, 25, 27, 32, 38, 40, 49, 60, 63, 67, 75, 79], [3, 25, 29, 40, 49, 60, 63, 67, 74, 75, 76, 79, 82], [3, 7, 10, 11, 14, 25, 38, 40, 67, 75, 79], [8, 17, 28, 29, 43, 63, 67, 79], [8, 11, 14, 40, 54], [3, 7, 8, 10, 11, 24, 25, 40, 63, 67, 70, 74, 79], [7, 8, 25, 28, 49, 63, 67, 70, 75, 79], [8, 17, 24, 28, 41, 63, 67, 70, 79], [8, 11, 14, 24, 28, 40, 43, 54, 63, 67, 76, 79], [8, 17, 18, 28, 29, 41, 43, 54, 63, 67, 79], [7, 9, 10, 11, 25, 40, 54, 67, 79, 82], [14, 24, 54, 67, 76, 79], [3, 7, 10, 11, 24, 25, 28, 40, 45, 49, 54, 60, 63, 67, 71, 74, 79, 82, 86], [8, 11, 14, 17, 24, 25, 40, 54, 63, 67, 74, 75, 79], [3, 11, 24, 38, 40, 79], [3, 7, 10, 11, 14, 24, 40, 54, 57, 67, 74, 79], [0, 3, 12, 25, 40, 49, 67, 71, 74, 75, 82, 84], [7, 10, 11, 22, 75, 76, 79], [0, 3, 10, 21, 25, 27, 30, 32, 33, 40, 42, 45, 60, 62, 63, 67, 69, 71, 74, 76, 79, 82, 84], [8, 11, 24, 57, 79], [0, 21, 32, 33, 45, 55, 72, 74, 83, 84], [11, 14, 40, 57, 78, 79], [8, 10, 14, 24, 40, 63, 67, 79], [3, 8, 10, 11, 17, 24, 25, 28, 29, 40, 41, 43, 57, 63, 67, 70, 74, 79], [0, 12, 26, 27, 32, 33, 35, 53, 55, 60, 67, 68, 72, 84], [0, 10, 25, 40, 67, 71, 76, 82, 85, 86], [3, 8, 10, 11, 14, 17, 24, 38, 40, 54, 57, 63, 67, 74, 75, 76, 79, 82], [3, 7, 11, 14, 25, 29, 40, 49, 54, 67, 71, 74, 75, 79, 82], [25, 26, 74, 82, 84], [0, 10, 11, 25, 26, 27, 32, 33, 40, 45, 59, 60, 69, 71, 72, 74, 76, 79, 80, 82, 84], [8, 10, 24, 28, 40, 43, 54, 63, 67, 79], [40, 49, 67, 75, 79], [9, 11, 14, 22, 40, 54, 79], [8, 14, 24, 28, 54, 63, 67], [2, 9, 32, 33, 37, 44, 69, 74, 76, 79], [7, 8, 10, 11, 14, 24, 28, 29, 40, 49, 63, 67, 74, 79], [0, 8, 26, 27, 33, 67, 72, 74, 84], [3, 8, 17, 21, 25, 27, 28, 32, 41, 43, 45, 60, 63, 67, 70, 71, 74, 75, 79, 82, 83, 84], [7, 10, 25, 40, 54, 60, 63, 67, 74, 79, 82], [8, 17, 28, 43, 57, 63, 67, 73, 76, 79], [7, 10, 11, 25, 40, 54, 67, 75], [0, 3, 10, 11, 14, 25, 40, 45, 54, 60, 67, 71, 74, 76, 82], [7, 8, 10, 14, 24, 28, 29, 40, 41, 43, 49, 54, 57, 63, 67, 70, 76, 78, 79], [3, 7, 10, 11, 40, 67, 79, 82], [3, 8, 10, 25, 28, 40, 41, 54, 63, 67, 70, 79, 80], [8, 11, 17, 24, 28, 29, 43, 63, 67, 70, 74, 79], [8, 24, 28, 29, 40, 41, 43, 63, 79], [8, 14, 24, 28, 40, 57, 63, 67, 71, 79], [11, 14, 54, 67, 79], [2, 9, 11, 22, 23, 76, 80], [8, 17, 24, 28, 29, 41, 43, 67, 70, 74, 79], [0, 12, 17, 26, 32, 33, 35, 55, 59, 72, 84], [8, 17, 24, 28, 29, 37, 41, 43, 63, 67, 70, 71, 79], [2, 13, 15, 16, 31, 44, 58, 76, 80], [3, 8, 14, 24, 28, 41, 63, 67, 70, 74, 78, 79], [8, 11, 24, 40, 63, 67, 79], [8, 17, 18, 24, 28, 29, 41, 43, 63, 67, 70, 79], [8, 24, 63, 67, 79], [8, 10, 28, 41, 63, 70, 79], [8, 24, 28, 41, 43, 57, 63, 70, 79], [7, 8, 17, 24, 28, 29, 41, 43, 70, 79], [3, 7, 9, 25, 44, 45, 60, 67, 74, 75, 79, 80, 82], [3, 25, 37, 40, 44, 49, 60, 67, 71, 74, 79, 82], [29, 63, 67, 74, 79], [0, 6, 12, 27, 32, 33, 35, 44, 53, 55, 60, 72, 74, 76, 83, 84], [3, 8, 14, 24, 29, 79], [4, 7, 26, 63, 76, 79, 80], [12, 26, 27, 32, 33, 35, 44, 55, 59, 72, 84], [10, 25, 33, 40, 45, 60, 71, 82], [3, 4, 9, 11, 22, 25, 38, 40, 54, 74, 75, 76, 79, 82, 85], [11, 22, 33, 45, 69, 76], [8, 10, 40, 46, 76, 79], [31, 44, 71, 76, 79, 82], [24, 28, 29, 41, 79], [8, 28, 29, 41, 49, 67], [3, 22, 32, 40, 45, 60, 71, 74, 76, 82], [3, 8, 10, 14, 17, 24, 25, 28, 54, 63, 67, 74, 79, 82], [28, 43, 45, 49, 60, 67, 71, 74, 75, 79, 82, 84], [8, 24, 28, 67, 79], [3, 7, 9, 11, 14, 20, 22, 24, 38, 44, 67, 76, 79], [11, 25, 54, 71, 79, 82], [0, 24, 25, 27, 33, 37, 54, 63, 67, 69, 79], [3, 10, 11, 14, 40, 74, 79], [0, 26, 27, 32, 33, 60, 72, 74, 82, 83, 84], [11, 25, 44, 67, 71, 74, 76], [8, 28, 40, 41, 70], [3, 7, 10, 11, 29, 40, 49, 54, 59, 67, 74, 75, 79, 82], [0, 25, 30, 32, 45, 60, 72, 84], [0, 14, 25, 32, 33, 40, 45, 54, 60, 72, 76, 79, 84], [8, 14, 24, 28, 29, 41, 43, 54, 57, 63, 67, 70, 79], [8, 11, 22, 24, 28, 41, 63, 67, 79], [8, 24, 29, 63, 79], [0, 13, 16, 26, 27, 32, 33, 44, 45, 60, 76, 79, 82, 83, 84], [8, 11, 14, 24, 28, 44, 46, 63, 74, 76, 79], [8, 14, 17, 24, 29, 43, 57, 63, 67, 79], [0, 6, 12, 26, 27, 32, 33, 53, 55, 68, 72, 84], [8, 24, 28, 41, 63, 67], [0, 3, 11, 17, 22, 25, 27, 32, 33, 43, 45, 59, 60, 67, 69, 71, 72, 74, 79, 82, 84], [8, 24, 28, 43, 63, 67, 79], [17, 38, 41, 43, 67, 79], [6, 12, 26, 27, 32, 33, 53, 55, 72, 84], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [8, 11, 24, 40, 63, 67, 74, 76, 79], [3, 8, 11, 24, 28, 43, 57, 79], [0, 8, 11, 12, 17, 24, 25, 26, 27, 32, 33, 43, 44, 63, 71, 72, 74, 79, 82, 83, 84], [11, 14, 43, 67, 79], [8, 17, 24, 28, 45, 60, 63, 67, 70, 74, 79], [8, 17, 18, 24, 28, 29, 40, 41, 43, 67, 70, 79], [0, 12, 26, 27, 32, 33, 35, 55, 59, 72, 81, 83, 84], [3, 7, 40, 49, 54, 74, 76, 79], [3, 8, 10, 11, 14, 28, 40, 49, 54, 74, 76, 79], [3, 11, 17, 21, 25, 26, 32, 33, 43, 45, 56, 60, 67, 71, 72, 74, 79, 82, 84], [7, 28, 43, 67, 79, 86], [17, 28, 29, 45, 63, 67, 79], [3, 11, 38, 40, 49, 54, 60, 74, 75, 79, 82, 86], [8, 9, 13, 16, 24, 27, 28, 29, 33, 37, 63, 67, 70, 79, 83], [8, 11, 14, 22, 24, 29, 40, 43, 54, 57, 63, 67, 74, 79], [8, 28, 43, 67, 74, 79], [8, 24, 28, 29, 41, 63, 70, 79], [8, 9, 11, 17, 24, 25, 29, 40, 43, 63, 67, 74, 75, 79], [8, 24, 43, 67, 79], [8, 24, 29, 43, 63, 67, 79], [8, 24, 28, 41, 43, 67, 70, 74, 79], [8, 25, 26, 43, 63, 67, 74, 79, 82], [3, 7, 11, 25, 40, 54, 74, 79, 82], [3, 11, 21, 43, 49, 67, 74, 79, 82], [8, 14, 43, 67, 74, 80], [3, 8, 25, 40, 44, 63, 67, 71, 75, 79, 82], [3, 6, 19, 25, 27, 33, 45, 59, 67, 71, 74, 79, 82, 83], [11, 37, 44, 46, 76], [11, 24, 25, 28, 63, 79], [0, 12, 26, 27, 32, 33, 51, 53, 59, 67, 72, 74, 83, 84], [0, 3, 10, 11, 25, 42, 60, 63, 66, 67, 69, 74, 79, 82], [8, 24, 28, 29, 41, 45, 60, 63, 67, 70, 79, 82], [3, 7, 8, 20, 25, 40, 45, 60, 74, 79, 82], [4, 7, 8, 10, 11, 24, 37, 38, 40, 44, 54, 79], [8, 24, 28, 32, 41, 43, 45, 60, 63, 67, 70, 71, 79], [0, 12, 33, 72, 84], [10, 12, 20, 25, 26, 27, 32, 33, 55, 59, 67, 71, 72, 74, 76, 82, 83, 84], [8, 14, 17, 24, 25, 28, 29, 40, 43, 45, 54, 63, 67, 71, 79, 82], [14, 22, 29, 76, 79], [0, 21, 25, 33, 40, 45, 59, 67, 76, 83, 84], [3, 11, 25, 40, 49, 74, 84], [3, 11, 40, 71, 74, 82], [8, 14, 24, 28, 43, 44, 54, 63, 67, 79], [3, 8, 10, 25, 43, 45, 54, 63, 67, 71, 74, 79, 82], [11, 17, 32, 43, 45, 55, 60, 71, 74, 82, 84], [0, 20, 27, 32, 33, 42, 55, 67, 74, 76, 82, 83, 84], [6, 12, 25, 26, 27, 32, 33, 35, 45, 55, 60, 72, 74, 84], [3, 8, 25, 28, 40, 67, 71, 79], [10, 11, 14, 24, 40, 54, 67, 74, 79], [3, 4, 10, 11, 25, 37, 67, 74, 76, 80, 82], [0, 11, 25, 33, 40, 49, 56, 60, 67, 71, 74], [3, 7, 10, 11, 14, 25, 38, 40, 49, 54, 60, 67, 71, 74, 75, 79, 82], [3, 10, 25, 63, 74, 76, 79], [8, 17, 25, 41, 76, 79], [3, 8, 10, 11, 24, 41, 63, 79], [3, 8, 11, 25, 40, 43, 49, 74, 75, 79, 82], [3, 8, 11, 16, 17, 19, 25, 28, 32, 37, 38, 43, 44, 45, 49, 57, 63, 67, 71, 74, 76, 79, 82], [0, 12, 16, 26, 27, 32, 33, 72, 84], [7, 10, 11, 33, 37, 43, 54, 59, 63, 67, 71, 74, 76, 79, 82], [8, 14, 24, 28, 43, 70, 78], [8, 14, 24, 54, 57, 63, 76], [11, 38, 44, 54, 71, 74, 76], [29, 41, 67, 76, 79], [3, 10, 11, 25, 38, 40, 49, 74, 75], [3, 10, 11, 25, 27, 32, 33, 60, 67, 71, 74, 76, 82, 84], [25, 26, 27, 32, 33, 35, 55, 59, 74, 84], [8, 11, 24, 28, 29, 41, 43, 63, 67, 70, 79], [4, 9, 40, 44, 47, 76, 80], [8, 17, 24, 27, 42, 43, 57, 63, 67, 72, 79, 84], [8, 11, 17, 24, 25, 43, 44, 63, 67, 71, 79, 82], [8, 11, 24, 25, 38, 44, 57, 63, 67, 74, 76, 79, 86], [8, 17, 18, 24, 25, 43, 63, 67, 74, 79], [3, 10, 11, 14, 38, 40, 43, 49, 54, 66, 67, 74, 78, 79], [8, 11, 17, 24, 41, 43, 63, 67, 75, 76, 79], [3, 11, 14, 24, 40, 43, 54, 63, 67, 79], [0, 12, 26, 32, 33, 35, 43, 53, 55, 72, 84], [17, 25, 32, 33, 43, 45, 60, 63, 67, 71, 74, 79, 82, 84], [27, 69, 71, 72, 74, 82, 84], [8, 11, 17, 24, 25, 27, 28, 32, 33, 43, 45, 60, 63, 67, 70, 74, 79, 82, 84], [3, 11, 25, 26, 27, 32, 33, 45, 60, 74, 75, 84], [8, 10, 11, 14, 24, 28, 40, 41, 67, 70, 79], [8, 11, 14, 24, 29, 40, 54, 57, 63, 67, 79], [0, 9, 12, 27, 32, 33, 44, 72, 73, 84, 86], [11, 25, 40, 76, 79], [28, 41, 54, 67, 79], [0, 6, 12, 26, 27, 30, 32, 33, 45, 55, 60, 72, 74, 76, 84], [3, 7, 8, 17, 24, 25, 28, 43, 50, 63, 67, 71, 74], [3, 8, 11, 17, 22, 24, 25, 38, 40, 63, 67, 74, 76, 79], [17, 24, 28, 29, 41, 43, 67, 70, 79], [0, 12, 26, 32, 33, 35, 55, 59, 72, 76, 84], [8, 17, 25, 28, 43, 45, 49, 60, 67, 70, 74, 82], [0, 3, 10, 11, 21, 25, 27, 32, 33, 40, 45, 60, 67, 71, 74, 76, 79, 82, 84], [8, 17, 24, 28, 29, 41, 43, 63, 67, 70, 74, 79], [21, 27, 32, 33, 37, 44, 45, 60, 67, 74, 82, 84], [14, 40, 43, 63, 67, 70, 74, 79], [17, 25, 26, 27, 32, 33, 43, 45, 60, 67, 74, 79, 82, 84], [0, 3, 9, 21, 25, 45, 60, 67, 71, 74, 82, 84], [2, 3, 8, 16, 20, 28, 40, 75, 76, 79, 80], [3, 10, 11, 20, 25, 38, 40, 46, 67, 74, 76, 79], [0, 20, 25, 27, 33, 59, 72, 74, 76], [3, 7, 8, 10, 11, 14, 17, 24, 25, 28, 29, 40, 43, 45, 54, 57, 67, 70, 79], [7, 8, 17, 24, 28, 40, 43, 63, 67, 70, 79], [8, 11, 24, 63, 75, 79], [0, 11, 12, 26, 27, 32, 33, 38, 43, 55, 60, 67, 72, 82, 84], [8, 26, 27, 32, 33, 35, 45, 74, 83, 84], [8, 11, 14, 17, 28, 29, 41, 43, 54, 63, 67, 74, 79], [0, 12, 26, 27, 32, 33, 72, 84], [0, 12, 26, 27, 59, 60, 72, 84], [3, 7, 10, 14, 24, 25, 40, 74, 79], [8, 11, 24, 28, 40, 41, 63, 67, 70, 75, 79], [25, 43, 67, 71, 74], [14, 63, 67, 71, 74, 79], [3, 8, 11, 25, 28, 38, 40, 41, 43, 67, 74, 76, 79], [0, 12, 27, 32, 33, 53, 55, 68, 72, 84], [7, 8, 28, 74, 79], [3, 10, 11, 14, 24, 40, 63, 67, 71, 74, 76, 78, 79], [3, 9, 10, 11, 25, 36, 38, 40, 43, 48, 49, 67, 71, 74, 75, 79, 80, 82], [45, 60, 67, 71, 74, 82], [3, 10, 17, 22, 25, 32, 43, 60, 67, 69, 73, 74, 76, 79, 82, 84], [0, 12, 25, 26, 27, 32, 33, 35, 37, 45, 53, 55, 59, 60, 68, 72, 74, 82, 84, 85], [3, 8, 10, 14, 24, 25, 29, 43, 57, 63, 67, 70, 74, 79], [0, 12, 27, 32, 33, 45, 60, 71, 82, 84], [7, 8, 11, 14, 54, 76, 79], [3, 25, 40, 63, 67, 74, 76, 79], [9, 27, 32, 33, 45, 60, 76, 79, 80, 84], [3, 8, 10, 11, 14, 24, 28, 29, 38, 40, 41, 57, 63, 79], [8, 14, 24, 28, 41, 63, 70, 79], [25, 26, 32, 60, 67, 74], [0, 12, 19, 27, 33, 67, 84], [0, 6, 12, 21, 27, 30, 33, 55, 72, 84], [3, 11, 25, 32, 33, 45, 54, 60, 67, 74], [11, 25, 27, 32, 33, 43, 45, 60, 67, 74, 79, 82, 84], [7, 21, 25, 26, 27, 43, 63, 67, 71, 76, 84], [3, 7, 11, 17, 18, 25, 26, 27, 44, 45, 50, 67, 71, 74, 76, 79, 80, 82, 84], [3, 25, 67, 74, 76, 79], [3, 8, 10, 17, 25, 28, 40, 45, 60, 63, 67, 71, 74, 79, 82], [8, 17, 24, 28, 29, 37, 41, 43, 63, 67, 70, 79], [0, 8, 40, 41, 67, 79], [8, 17, 24, 28, 29, 30, 43, 54, 60, 63, 67, 71, 74, 79], [17, 25, 45, 60, 67, 71, 74, 79, 82], [7, 11, 40, 54, 63, 67, 71, 74, 79], [3, 16, 17, 18, 25, 27, 32, 33, 37, 43, 45, 47, 60, 63, 67, 72, 74, 79, 83, 84], [3, 8, 10, 14, 24, 40, 57, 63, 79], [11, 25, 26, 27, 32, 33, 40, 45, 54, 60, 67, 71, 74, 76, 82, 83, 84], [33, 60, 76, 80, 82, 84], [11, 25, 26, 27, 32, 33, 45, 63, 67, 71, 74, 79], [3, 11, 38, 40, 54, 57, 63, 67, 71, 76, 79, 82], [17, 43, 67, 71, 74, 82], [8, 24, 57, 63, 67], [3, 10, 17, 40, 45, 59, 60, 74, 79], [8, 17, 18, 24, 41, 43, 57, 63, 67, 70, 74, 79], [10, 44, 48, 76, 80], [0, 6, 9, 12, 27, 32, 33, 53, 72, 84], [35, 44, 71, 74, 76, 84], [25, 27, 59, 60, 67, 74, 75, 79, 82, 84], [8, 17, 24, 28, 29, 41, 63, 67, 70, 79], [7, 8, 11, 17, 24, 25, 29, 43, 59, 63, 67, 74, 79], [8, 11, 17, 24, 28, 40, 43, 54, 67, 79], [4, 25, 32, 45, 54, 60, 74, 76, 82], [7, 10, 11, 45, 67, 71, 74, 79, 82], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [7, 8, 10, 11, 24, 28, 54, 63, 67, 70, 71, 74, 79, 82], [25, 32, 40, 42, 45, 54, 59, 60, 67, 71, 74, 82, 84], [25, 28, 45, 60, 67, 74, 79, 82], [8, 28, 54, 67, 74, 78, 79], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [25, 43, 45, 67, 74, 76, 84], [7, 8, 10, 14, 24, 28, 40, 41, 43, 54, 63, 67, 70, 79], [3, 25, 45, 54, 60, 67, 74, 82], [7, 10, 25, 44, 74, 82, 85], [0, 3, 12, 16, 25, 26, 27, 33, 40, 42, 43, 44, 45, 59, 60, 61, 67, 71, 72, 76, 79, 82, 83, 84], [8, 22, 24, 28, 29, 41, 43, 46, 63, 67, 76, 79], [28, 29, 41, 59, 67], [21, 25, 54, 60, 75, 79, 82, 86], [3, 11, 25, 57, 60, 63, 67, 71, 74, 75, 76, 79, 82], [0, 2, 11, 12, 20, 21, 25, 32, 33, 44, 45, 50, 53, 54, 60, 67, 71, 72, 74, 76, 82, 84, 87], [8, 25, 43, 71, 74], [26, 27, 32, 33, 53, 55, 60, 84], [13, 16, 17, 25, 27, 33, 55, 80, 84], [0, 11, 12, 25, 27, 32, 33, 60, 67, 71, 72, 74, 82, 84], [3, 8, 11, 17, 18, 25, 28, 45, 49, 56, 60, 62, 67, 75, 79, 82], [0, 6, 12, 32, 33, 60, 72, 84], [0, 8, 17, 21, 25, 27, 28, 32, 33, 43, 45, 60, 63, 67, 71, 72, 73, 74, 82, 84], [8, 17, 24, 28, 29, 41, 43, 57, 63, 67, 79], [3, 8, 10, 11, 14, 22, 24, 25, 29, 40, 43, 54, 57, 63, 67, 71, 74, 79, 82], [3, 10, 11, 14, 38, 40, 54, 66, 78, 79], [0, 21, 30, 32, 33, 42, 45, 60, 72, 82, 84], [0, 12, 25, 26, 27, 33, 44, 53, 59, 72, 84], [8, 14, 24, 41, 54, 63, 67, 70, 79], [8, 17, 24, 41, 63, 67, 74, 76], [25, 27, 33, 45, 59, 60, 67, 71, 79, 82, 84], [3, 10, 11, 25, 74, 76, 84], [8, 26, 27, 35, 43, 67, 71, 76, 79, 82], [3, 11, 25, 40, 49, 54, 67, 74, 78, 82], [7, 8, 14, 40, 49, 54, 70, 79], [8, 24, 28, 41, 63, 67, 70, 79], [8, 11, 24, 28, 40, 43, 57, 63, 70, 79], [27, 32, 33, 45, 55, 83, 84], [4, 25, 27, 32, 33, 40, 45, 60, 62, 76, 80, 82, 84], [0, 11, 40, 42, 45, 54, 60, 79, 82, 84], [7, 9, 10, 20, 38, 40, 44, 46, 60, 77], [25, 27, 32, 60, 74, 82, 84], [0, 12, 25, 26, 27, 32, 33, 55, 60, 72, 74, 82, 84], [0, 6, 12, 33, 53, 55, 72, 84], [11, 14, 28, 44, 74, 76, 82], [0, 21, 33, 42, 67, 76, 79, 84], [3, 8, 11, 14, 24, 25, 28, 40, 49, 57, 67, 70, 75, 79], [25, 43, 60, 67, 71, 74, 82], [0, 8, 11, 67, 74, 79, 82], [11, 24, 25, 38, 40, 44, 54, 76, 79], [17, 21, 27, 31, 32, 33, 55, 59, 60, 73, 74, 84], [8, 11, 24, 57, 67, 79], [3, 8, 11, 17, 25, 43, 49, 67, 79, 84], [8, 24, 25, 67, 74, 79], [3, 8, 11, 14, 24, 25, 28, 29, 37, 40, 41, 49, 54, 63, 66, 67, 70, 74, 76, 79, 80, 82], [12, 27, 32, 33, 74, 84], [8, 17, 28, 29, 41, 43, 63, 67, 70, 79], [9, 13, 16, 37, 44, 76], [17, 25, 27, 30, 43, 60, 67, 71, 74, 79, 82, 84], [10, 11, 24, 28, 29, 41, 70, 79], [0, 25, 26, 63, 67, 74, 82, 83, 84], [7, 67, 76, 79, 80], [8, 16, 18, 24, 25, 28, 31, 33, 41, 43, 45, 60, 63, 67, 70, 73, 74, 79, 82], [8, 25, 28, 29, 41, 63, 67, 70, 79], [8, 11, 24, 29, 54, 63, 78, 79], [3, 7, 10, 11, 25, 40, 44, 60, 67, 71, 74, 76, 79, 82], [3, 10, 11, 21, 25, 27, 32, 33, 37, 45, 56, 60, 71, 74, 79, 82, 84], [25, 26, 27, 32, 35, 59, 71, 76, 84], [8, 11, 24, 43, 57, 63, 67, 79], [3, 9, 38, 40, 49, 67, 76, 79], [3, 10, 11, 25, 38, 40, 49, 67, 74, 79], [11, 25, 27, 32, 33, 45, 60, 67, 71, 72, 74, 76, 82, 84], [8, 44, 56, 67, 74, 82], [3, 8, 11, 17, 24, 25, 28, 29, 40, 41, 43, 57, 63, 67, 70, 74, 79, 82], [8, 24, 28, 29, 79], [8, 17, 24, 28, 29, 41, 43, 63, 67, 70, 79], [3, 7, 11, 14, 79], [8, 17, 43, 63, 74, 75, 79], [25, 43, 45, 60, 67, 71, 74, 79, 82], [0, 2, 12, 25, 27, 32, 33, 67, 69, 72, 74, 84], [8, 11, 14, 28, 41, 43, 67, 79], [8, 24, 28, 43, 44, 47, 57, 63, 67, 76, 79], [11, 21, 32, 33, 45, 49, 60, 71, 74, 79, 82, 84], [3, 11, 25, 27, 45, 60, 63, 67, 71, 74, 79, 82, 84], [4, 10, 21, 25, 27, 32, 33, 42, 45, 50, 60, 67, 74, 76, 82, 83], [11, 27, 33, 55, 67, 74, 79, 84], [3, 21, 26, 27, 32, 40, 43, 45, 54, 63, 70, 71, 79, 84], [11, 28, 40, 63, 67, 79], [37, 44, 45, 54, 57, 60, 67, 71, 74, 79, 82], [12, 25, 26, 27, 33, 59, 76, 82, 84], [3, 8, 11, 44, 54, 57, 79], [37, 63, 67, 74, 79], [10, 11, 14, 24, 25, 40, 50, 54, 67, 79, 80], [40, 63, 67, 74, 76, 79, 80], [8, 17, 18, 43, 54, 63, 67, 70, 71, 74, 79, 82], [3, 7, 25, 67, 74, 82], [3, 11, 21, 24, 67, 79], [3, 7, 10, 11, 25, 38, 49, 74, 75], [3, 11, 25, 32, 38, 40, 45, 49, 50, 60, 67, 74, 76, 82, 84], [8, 17, 24, 28, 29, 41, 63, 70, 79], [8, 17, 24, 28, 29, 41, 54, 63, 67, 70, 74, 79], [3, 8, 9, 11, 17, 24, 25, 32, 33, 40, 43, 60, 67, 71, 76, 79, 82], [8, 41, 43, 63, 67, 79], [21, 25, 26, 27, 33, 35, 45, 54, 55, 59, 60, 67, 74, 82, 83, 84, 85], [3, 10, 11, 21, 25, 27, 32, 33, 40, 45, 49, 60, 67, 71, 74, 79, 82], [0, 6, 12, 17, 20, 21, 26, 32, 45, 55, 68, 72, 83, 84], [3, 8, 17, 24, 28, 29, 41, 43, 49, 63, 67, 70, 79], [3, 25, 60, 71, 74, 75, 82], [13, 16, 37, 44, 67, 71, 79], [3, 10, 40, 79, 80], [3, 40, 49, 63, 75, 79], [10, 14, 24, 74, 79], [3, 7, 8, 10, 11, 21, 24, 25, 29, 32, 38, 40, 41, 43, 49, 57, 60, 63, 67, 74, 79, 82], [3, 7, 8, 10, 11, 14, 25, 40, 50, 54, 67, 79, 82], [8, 24, 40, 41, 54, 67, 70, 79], [17, 21, 25, 26, 27, 29, 32, 33, 45, 49, 56, 60, 67, 71, 75, 79, 82, 83, 84], [8, 10, 11, 17, 18, 25, 29, 43, 63, 67, 71, 74, 79, 82], [8, 24, 28, 29, 41, 57, 63, 67, 70, 74, 79], [17, 25, 27, 32, 43, 45, 56, 60, 62, 63, 67, 71, 74, 84], [7, 27, 33, 44, 60, 67, 83, 84], [10, 11, 17, 18, 25, 40, 43, 45, 54, 56, 63, 67, 74, 79], [17, 21, 25, 26, 27, 32, 33, 45, 60, 67, 71, 74, 82, 84], [8, 10, 24, 29, 63, 67, 79], [3, 7, 10, 11, 22, 25, 40, 54, 75, 79], [5, 10, 49, 57, 63, 67, 75, 79], [10, 11, 25, 44, 45, 54, 67, 71, 74, 75, 76, 79, 82], [3, 8, 11, 14, 24, 57, 70, 78, 79], [0, 12, 21, 25, 26, 27, 32, 33, 35, 53, 59, 72, 74, 76, 82, 83, 84], [8, 43, 63, 67, 79], [10, 11, 14, 24, 28, 29, 40, 54, 63, 67, 78, 79], [10, 11, 38, 40, 67, 74], [0, 12, 26, 27, 32, 33, 35, 59, 60, 72, 83, 84], [11, 14, 40, 43, 54, 76, 79], [17, 25, 29, 67, 71, 74, 82], [8, 17, 24, 28, 29, 41, 43, 63, 67, 70, 79], [0, 11, 21, 25, 26, 27, 32, 33, 74, 76, 82, 84, 86], [8, 17, 24, 28, 41, 43, 63, 67, 70, 74], [17, 24, 26, 27, 32, 33, 43, 45, 54, 60, 71, 74, 76, 84], [3, 11, 25, 32, 40, 45, 49, 54, 56, 60, 74, 82, 84], [8, 14, 24, 28, 41, 43, 57, 63, 67, 70, 74], [8, 14, 24, 28, 29, 40, 41, 49, 54, 57, 63, 67, 70, 79], [8, 17, 24, 28, 41, 43, 56, 63, 67, 70, 74, 79], [10, 11, 14, 25, 71, 74, 80, 82], [3, 8, 11, 24, 28, 29, 41, 43, 49, 63, 67, 70, 79], [26, 32, 33, 45, 83, 84], [3, 11, 14, 25, 40, 54, 74, 78, 79], [3, 10, 11, 17, 24, 25, 30, 40, 43, 45, 54, 60, 63, 67, 71, 74, 79, 82], [0, 3, 8, 11, 17, 25, 33, 43, 63, 67, 71, 73, 74, 76, 79, 84], [3, 11, 25, 40, 67, 79, 82], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [11, 17, 24, 43, 67, 74], [7, 11, 25, 26, 40, 43, 44, 69, 74, 79, 82], [11, 12, 16, 21, 25, 26, 27, 32, 33, 35, 44, 45, 55, 60, 67, 74, 82, 83, 84], [0, 6, 27, 32, 33, 53, 68, 72, 76, 84], [7, 63, 67, 78, 79], [8, 17, 24, 28, 29, 40, 41, 43, 63, 67, 70, 79], [9, 16, 17, 18, 25, 38, 44, 67, 76, 79, 82], [8, 17, 24, 28, 29, 43, 57, 63, 67, 76, 79], [27, 32, 33, 60, 67, 79, 82, 84], [8, 14, 22, 23, 24, 25, 28, 40, 41, 63, 64, 74, 75, 79, 80, 86], [8, 11, 14, 17, 22, 23, 54, 63, 67, 69, 70, 79, 86], [8, 28, 43, 63, 67, 70], [3, 11, 25, 43, 63, 67, 74, 79, 82], [8, 11, 14, 24, 57, 63, 67, 79], [0, 21, 25, 27, 32, 33, 45, 60, 83, 84], [27, 45, 67, 71, 74, 79, 82, 84, 86], [6, 19, 27, 33, 45, 55, 60, 67, 71, 76, 83, 84], [8, 28, 29, 57, 67, 79], [2, 11, 54, 76, 78], [10, 11, 25, 45, 60, 74, 82], [26, 27, 32, 45, 54, 74, 84], [3, 8, 11, 25, 28, 40, 43, 54, 63, 67, 71, 74, 79, 82], [13, 16, 25, 31, 40, 44, 54, 60, 71, 73, 74, 76, 80, 82], [0, 12, 26, 27, 32, 33, 60, 72, 74, 84, 87], [16, 25, 26, 37, 44, 67, 74, 76, 84], [8, 24, 28, 43, 56, 57, 63, 79], [3, 8, 10, 11, 14, 25, 38, 40, 54, 63, 67, 74, 79, 82], [13, 17, 18, 43, 67, 71, 74, 79], [3, 7, 8, 14, 25, 40, 43, 54, 67, 71, 74, 75, 82], [3, 7, 25, 27, 33, 40, 45, 54, 60, 84], [10, 11, 14, 40, 54, 79], [8, 29, 38, 54, 67, 76, 79], [3, 8, 25, 40, 67, 71, 76, 79], [0, 3, 8, 10, 12, 17, 25, 27, 28, 32, 33, 37, 42, 43, 45, 60, 67, 72, 74, 75, 76, 79, 82, 83, 84, 86], [8, 11, 14, 28, 41, 43, 67, 79], [0, 12, 51, 52, 72, 76], [3, 25, 63, 67, 71, 82], [8, 17, 24, 28, 41, 63, 67, 70], [10, 11, 40, 54, 79], [0, 3, 8, 12, 14, 17, 25, 27, 28, 32, 33, 43, 45, 54, 60, 63, 67, 70, 71, 72, 74, 79, 82, 83, 84], [21, 25, 30, 32, 44, 60, 74, 82, 84], [8, 11, 25, 38, 40, 54, 63, 67, 71, 74, 79, 82], [0, 12, 32, 33, 72, 74, 82, 84], [3, 10, 11, 14, 22, 40, 54, 67, 78, 79], [0, 3, 11, 21, 25, 26, 27, 32, 33, 45, 59, 60, 67, 74, 79, 82, 84], [0, 26, 27, 31, 33, 49, 60, 67, 71, 72, 76, 84], [3, 11, 40, 49, 63, 67, 79], [8, 17, 18, 24, 28, 29, 40, 41, 43, 63, 70, 79], [8, 17, 24, 41, 43, 63, 67, 79], [8, 24, 41, 63, 67, 79], [3, 25, 67, 75, 79], [3, 8, 11, 25, 28, 40, 45, 49, 54, 60, 66, 67, 74, 82], [3, 8, 11, 40, 63], [24, 29, 30, 43, 63, 67, 74, 79, 86], [21, 26, 27, 32, 33, 45, 55, 72, 84], [11, 22, 24, 28, 41, 63, 67, 79], [2, 4, 9, 15, 16, 20, 37, 44, 46, 76, 80, 85], [8, 21, 25, 27, 28, 32, 33, 40, 45, 60, 67, 74, 76, 82, 83, 84], [8, 17, 43, 63, 67, 79], [9, 25, 37, 39, 67, 73, 74, 79, 86], [8, 11, 74, 76, 82], [3, 10, 11, 24, 25, 45, 54, 60, 71, 79, 82], [8, 17, 24, 25, 26, 27, 28, 29, 32, 33, 43, 56, 60, 63, 67, 71, 74, 75, 79, 82, 83], [8, 28, 41, 67, 70, 79], [7, 10, 25, 28, 40, 60, 63, 67, 74, 75, 82, 86], [3, 8, 10, 11, 16, 17, 24, 25, 28, 43, 44, 45, 60, 63, 67, 71, 76, 79, 82], [0, 11, 12, 21, 25, 26, 27, 32, 33, 35, 45, 49, 56, 60, 61, 67, 71, 74, 76, 82, 83, 84], [21, 27, 32, 33, 45, 60, 67, 76, 83, 84], [14, 24, 40, 41, 54, 74, 79], [3, 8, 49, 63, 67, 70], [3, 8, 24, 25, 28, 38, 40, 43, 49, 63, 66, 67, 74, 79, 82], [8, 24, 28, 41, 43, 57, 63, 67, 70, 79], [7, 8, 17, 22, 24, 25, 28, 29, 43, 63, 67, 70, 79], [8, 14, 28, 43, 63, 79], [25, 33, 40, 45, 60, 67, 74, 82, 84], [8, 17, 24, 28, 40, 41, 43, 49, 63, 67, 70, 74, 79], [3, 8, 11, 25, 40, 45, 49, 60, 63, 67, 71, 74, 75, 79, 82, 84], [6, 12, 19, 26, 27, 32, 33, 43, 60, 67, 74, 76, 84], [11, 40, 43, 54, 63, 67, 74, 76, 79], [8, 24, 28, 29, 41, 70], [11, 16, 24, 40, 63], [21, 25, 26, 27, 32, 33, 45, 60, 67, 71, 74, 82, 84, 86], [3, 10, 11, 14, 40, 41, 54, 67, 74, 76, 79], [0, 25, 27, 33, 74, 76, 84], [0, 12, 21, 27, 30, 32, 33, 45, 53, 55, 60, 72, 74, 84], [3, 7, 11, 24, 25, 40, 63, 67, 75, 79, 82], [3, 8, 14, 25, 40, 49, 63, 79], [0, 6, 12, 26, 27, 30, 32, 33, 35, 53, 55, 68, 72, 83, 84], [8, 43, 57, 63, 76, 79], [24, 29, 57, 76, 79], [3, 7, 10, 11, 25, 40, 44, 63, 67, 71, 74, 79, 82], [25, 45, 60, 74, 76, 82], [3, 11, 25, 26, 32, 33, 44, 45, 60, 67, 71, 74, 75, 76, 78, 82, 84], [3, 7, 32, 37, 44, 46, 67, 79], [7, 8, 10, 11, 14, 17, 25, 43, 44, 60, 63, 67, 71, 73, 74, 76, 79, 82], [0, 12, 21, 25, 26, 27, 32, 33, 35, 42, 45, 56, 60, 67, 72, 74, 82, 84], [8, 24, 28, 41, 63, 67, 70, 79], [25, 26, 27, 32, 33, 44, 59, 67, 69, 71, 74, 76, 83, 84], [0, 8, 9, 11, 24, 25, 38, 40, 41, 43, 44, 57, 63, 67, 74, 76, 79, 82], [0, 21, 27, 32, 33, 44, 45, 60, 67, 71, 74, 76, 82, 83, 84], [3, 8, 11, 14, 24, 28, 40, 41, 49, 54, 57, 63, 67, 70, 74, 76, 79], [3, 7, 10, 11, 38, 40, 79], [11, 25, 40, 54, 67, 79], [8, 14, 24, 29, 40, 57, 63, 79], [10, 11, 16, 24, 40, 45, 54, 60, 63, 74, 75, 79, 82], [8, 25, 45, 74, 76], [11, 40, 41, 49, 75, 79], [8, 17, 28, 41, 43, 63, 67, 70, 74, 79], [8, 17, 24, 41, 43, 44, 63, 67, 70, 74, 76, 79], [7, 10, 11, 25, 74, 75], [3, 8, 25, 28, 43, 45, 60, 63, 67, 71, 74, 82], [8, 11, 24, 25, 28, 63, 67, 79], [14, 24, 28, 40, 41, 54, 63, 67, 79], [0, 12, 22, 25, 26, 27, 42, 69, 72, 76, 84, 86], [8, 14, 24, 28, 29, 40, 43, 54, 63, 67, 79], [8, 11, 24, 25, 43, 63, 67, 74, 76, 79], [7, 8, 10, 11, 14, 25, 28, 29, 40, 54, 63, 67, 70, 79], [25, 45, 60, 67, 74, 82], [0, 3, 21, 26, 27, 32, 45, 49, 60, 67, 74, 76, 82], [3, 11, 28, 43, 75, 79], [25, 67, 71, 74, 82], [7, 8, 24, 34, 43, 67, 74, 76, 79], [8, 14, 17, 24, 29, 43, 54, 63, 67, 74, 79], [8, 10, 11, 14, 28, 38, 40, 54, 63, 67, 71, 74, 79], [25, 44, 67, 71, 74, 76], [3, 8, 11, 24, 28, 40, 76, 79], [11, 15, 16, 22, 23, 25, 31, 39, 40, 44, 46, 54, 60, 74, 76, 79, 82, 86], [10, 11, 21, 25, 32, 45, 54, 59, 60, 67, 74, 75, 79], [3, 8, 10, 11, 25, 45, 67, 76, 82], [3, 17, 18, 25, 26, 27, 43, 45, 63, 67, 71, 74, 76, 79, 82, 84], [8, 14, 22, 28, 63, 78, 79, 80], [3, 7, 25, 67, 75, 82], [3, 7, 8, 14, 24, 43, 45, 54, 60, 63, 67, 71, 74, 79, 82], [17, 19, 24, 25, 28, 29, 33, 43, 55, 63, 67, 74, 79, 84], [3, 8, 17, 24, 25, 32, 33, 38, 40, 49, 60, 63, 67, 71, 74, 75, 79, 82], [24, 28, 29, 63, 70, 79], [8, 11, 14, 17, 24, 25, 28, 40, 43, 54, 63, 67, 74, 76, 79], [8, 24, 28, 41, 63, 67, 70, 79], [8, 17, 24, 28, 29, 41, 63, 70, 76], [11, 24, 40, 49, 63, 67, 79], [11, 14, 25, 76, 79], [8, 10, 11, 20, 25, 27, 28, 32, 45, 49, 60, 67, 71, 74, 79, 82], [0, 12, 26, 27, 32, 33, 42, 60, 72, 84], [3, 11, 24, 40, 49, 63, 67, 71, 74, 76, 79], [8, 14, 17, 24, 28, 29, 40, 41, 43, 54, 63, 67, 79], [8, 17, 24, 32, 41, 63, 67, 70, 74, 79], [8, 17, 24, 28, 29, 41, 63, 67, 70, 79], [0, 8, 17, 28, 42, 43, 45, 67, 79, 84], [3, 11, 25, 36, 54, 67, 74, 75, 76, 79, 82], [8, 11, 24, 28, 41, 43, 54, 57, 63, 67, 70, 79], [11, 17, 24, 25, 43, 54, 67, 76, 79], [0, 3, 10, 11, 25, 32, 33, 44, 60, 74, 76, 83, 84], [8, 17, 24, 28, 29, 41, 43, 45, 67, 71, 79], [11, 25, 27, 32, 33, 67, 84], [8, 17, 24, 28, 29, 41, 43, 57, 63, 67, 70, 79], [17, 28, 43, 67, 76], [3, 7, 9, 16, 29, 43, 44, 57, 60, 67, 69, 71, 74, 76, 79, 82, 83], [8, 11, 24, 28, 40, 67, 74, 79], [32, 54, 67, 69, 74, 79], [8, 24, 28, 29, 43, 63, 67, 70, 74, 79], [11, 25, 40, 54, 59, 74, 76, 82], [3, 10, 11, 24, 28, 40, 49, 54, 63, 67, 79], [8, 11, 14, 24, 28, 63, 67, 74, 79], [17, 18, 25, 26, 27, 40, 63, 67, 70, 73, 74, 79, 82], [12, 13, 21, 25, 27, 32, 33, 37, 44, 55, 60, 83, 84], [10, 11, 25, 38, 40, 49, 74, 79, 80], [3, 8, 10, 11, 17, 24, 25, 40, 41, 49, 63, 74, 79], [10, 11, 40, 54, 79], [12, 27, 30, 32, 33, 55, 83, 84], [8, 17, 25, 43, 63, 67, 69, 73, 74, 79], [3, 8, 12, 19, 21, 25, 26, 27, 33, 40, 43, 45, 60, 67, 71, 74, 75, 79, 82, 84], [8, 17, 24, 28, 41, 43, 54, 63, 67, 70, 79], [3, 11, 25, 43, 44, 57, 66, 67, 71, 74, 79, 82], [3, 8, 11, 14, 24, 25, 40, 43, 45, 54, 63, 76, 79], [8, 10, 11, 22, 24, 25, 38, 40, 41, 63, 70, 76, 79], [8, 25, 28, 43, 44, 63, 67, 74, 76, 79], [3, 8, 10, 17, 25, 32, 33, 40, 45, 49, 56, 60, 71, 74, 79, 82, 84], [9, 10, 11, 38, 40, 76, 80], [26, 27, 43, 63, 67, 84], [0, 4, 9, 12, 16, 27, 37, 44, 45, 60, 67, 72, 76, 82, 83], [43, 45, 57, 63, 67, 79], [8, 11, 17, 24, 28, 29, 41, 63, 67, 70, 79], [11, 63, 67, 76, 79], [3, 10, 11, 14, 22, 40, 54, 78, 79], [11, 40, 49, 75, 79], [10, 17, 24, 40, 44, 57, 63], [3, 8, 11, 24, 25, 28, 29, 43, 63, 67, 70, 79, 82], [7, 24, 28, 29, 41, 43, 63, 67, 79], [7, 14, 24, 54, 67, 79], [8, 11, 14, 22, 24, 41, 43, 54, 57, 63, 67, 70, 74, 79, 80], [11, 25, 40, 45, 67, 74, 76, 82], [8, 10, 11, 14, 24, 40, 54, 63, 67, 79], [10, 11, 22, 74, 76, 82], [8, 14, 22, 28, 43, 57, 63, 67, 79], [8, 11, 24, 40, 43, 60, 63, 67, 74, 79], [13, 16, 25, 37, 55, 63, 67, 74, 76, 79, 82], [8, 11, 24, 28, 40, 41, 63, 67, 79], [25, 67, 69, 71, 74, 79, 82, 84], [8, 28, 29, 41, 43, 63, 70, 79], [8, 11, 25, 26, 28, 33, 43, 60, 67, 71, 74, 79, 82, 84], [3, 8, 11, 17, 25, 28, 41, 43, 63, 67, 74, 75, 79], [3, 7, 11, 14, 25, 54, 63, 74, 75, 82], [10, 11, 44, 46, 76, 80], [3, 7, 8, 24, 63, 67, 78, 79], [3, 11, 25, 27, 32, 33, 40, 45, 54, 60, 67, 71, 74, 76, 79, 82, 84], [8, 24, 28, 40, 41, 43, 57, 63, 67, 70, 79], [3, 10, 11, 25, 38, 45, 49, 74], [14, 24, 41, 70, 79], [8, 11, 24, 28, 40, 41, 63, 67, 79], [0, 12, 26, 27, 32, 33, 55, 60, 68, 72, 84], [25, 26, 32, 67, 71, 74, 79], [3, 8, 17, 28, 41, 43, 57, 63, 70, 74, 79], [3, 11, 14, 24, 28, 37, 43, 57, 63, 67, 74, 76, 79, 82], [8, 11, 14, 24, 29, 43, 57, 63, 67, 70, 79], [8, 11, 24, 28, 40, 43, 57, 63, 67, 79], [7, 8, 10, 11, 24, 28, 29, 43, 63, 67, 74, 79], [7, 8, 10, 11, 17, 24, 25, 28, 40, 43, 54, 63, 67, 71, 74, 76, 78, 79, 82], [3, 8, 24, 25, 38, 40, 49, 63, 67, 71, 75, 79], [25, 32, 45, 60, 74, 82, 84], [3, 8, 24, 25, 28, 43, 45, 49, 60, 63, 67, 71, 74, 79, 82], [14, 29, 41, 54, 57], [8, 17, 24, 28, 29, 40, 43, 57, 63, 67, 74, 76, 79], [3, 7, 10, 25, 75, 79], [8, 17, 24, 28, 41, 43, 57, 63, 67, 79], [8, 28, 41, 43, 70, 79], [3, 11, 24, 40, 41, 70, 74, 75, 76, 78, 79], [3, 25, 45, 60, 71, 74, 82, 84], [11, 67, 74, 76, 79], [8, 10, 11, 14, 24, 25, 40, 63, 67, 70, 79], [8, 10, 11, 14, 54, 67, 70, 74, 76, 79], [10, 11, 40, 67, 74], [2, 8, 17, 25, 28, 40, 43, 45, 60, 63, 67, 74, 79, 82, 84], [10, 16, 45, 60, 74, 82], [0, 21, 25, 26, 27, 30, 32, 33, 45, 59, 60, 71, 72, 74, 82, 83, 84], [25, 26, 27, 82, 84], [8, 10, 11, 24, 28, 38, 43, 63, 67, 70, 79], [8, 11, 17, 24, 28, 63, 67, 79], [14, 43, 46, 76, 79], [0, 27, 32, 33, 45, 60, 67, 71, 72, 74, 76, 82, 84], [8, 13, 17, 28, 63, 67, 79], [3, 10, 14, 40, 43, 54, 79], [16, 25, 42, 69, 76, 82, 86], [11, 14, 22, 40, 54, 71, 76, 79], [3, 10, 11, 25, 40, 79], [3, 8, 11, 16, 24, 25, 32, 40, 49, 63, 67, 71, 79], [8, 22, 24, 28, 41, 43, 79], [8, 11, 17, 28, 41, 43, 44, 63, 70, 73, 76, 79, 86], [3, 8, 24, 28, 40, 41, 63, 67, 79], [3, 25, 28, 42, 45, 49, 60, 67, 71, 74, 75, 76, 79, 82], [11, 24, 38, 40, 43, 57], [8, 17, 18, 24, 28, 43, 63, 67, 70, 71, 73, 79], [9, 10, 11, 37, 71, 74, 82], [10, 11, 16, 17, 25, 43, 44, 54, 74, 76], [8, 17, 24, 28, 29, 41, 43, 63, 67, 79], [8, 11, 17, 24, 28, 29, 40, 41, 43, 54, 63, 70, 79], [8, 17, 24, 28, 29, 43, 54, 57, 63, 70, 74, 79], [3, 10, 11, 14, 22, 38, 40, 44, 49, 66, 67, 74, 78, 79, 80, 82], [8, 24, 28, 43, 44, 63, 67, 70, 79], [0, 12, 21, 24, 25, 26, 27, 32, 33, 45, 56, 60, 63, 67, 71, 74, 79, 82, 83, 84], [8, 24, 28, 40, 41, 43, 54, 63, 67, 70, 71, 74, 79], [8, 24, 29, 43, 57, 63, 67, 79], [8, 11, 17, 28, 41, 43, 63, 67, 70, 79], [43, 44, 63, 67, 79, 82], [8, 24, 28, 41, 57], [0, 12, 21, 26, 27, 30, 32, 33, 35, 45, 55, 72, 84], [25, 27, 32, 42, 60, 67, 71, 72, 74, 82], [8, 28, 43, 63, 67, 70, 74, 79], [11, 19, 32, 33, 44, 63, 67, 71, 74, 75, 79, 82, 84], [8, 14, 24, 28, 43, 54, 57, 63, 67, 70, 79], [7, 8, 11, 14, 24, 28, 40, 54, 63, 67, 75, 79], [7, 25, 40, 49, 63, 67, 70, 74, 79], [10, 11, 22, 25, 27, 32, 33, 67, 71, 72, 74, 82, 84], [8, 17, 24, 28, 29, 41, 67, 70, 79], [11, 14, 40, 54, 67, 79], [8, 11, 17, 18, 28, 37, 63, 79, 86], [8, 17, 24, 28, 31, 43, 63, 67, 74, 76], [3, 8, 25, 28, 40, 49, 63, 67, 70, 79], [8, 17, 24, 28, 41, 43, 63, 67, 70], [9, 10, 11, 40, 80], [25, 33, 67, 71, 74, 79, 82], [3, 10, 11, 17, 25, 40, 49, 59, 66, 67, 71, 74, 76, 79], [3, 7, 10, 11, 40, 54, 79], [3, 11, 25, 40, 49, 60, 74, 82], [8, 28, 40, 54, 63, 67, 79], [3, 10, 11, 14, 25, 40, 54, 78, 79], [0, 12, 25, 26, 27, 32, 33, 42, 45, 55, 59, 60, 67, 71, 72, 74, 82, 83, 84], [0, 26, 27, 32, 33, 55, 60, 67, 72, 84], [8, 13, 16, 24, 28, 41, 63, 67, 70, 75, 79], [32, 33, 45, 56, 84, 87], [25, 40, 45, 49, 60, 67, 74, 82], [23, 28, 40, 41, 75], [8, 17, 24, 28, 29, 41, 63, 67, 70, 79], [8, 24, 25, 28, 29, 40, 63, 67, 79], [2, 3, 9, 10, 11, 14, 16, 25, 37, 40, 44, 48, 65, 69, 71, 74, 76, 79, 80, 82], [24, 28, 29, 37, 41, 44, 63, 70, 79, 85, 86], [3, 8, 10, 17, 25, 28, 60, 63, 67, 71, 74, 75, 79, 82], [3, 10, 11, 14, 17, 24, 40, 43, 54, 67, 74, 76, 79], [8, 24, 28, 57, 63, 67, 74, 79], [3, 7, 10, 11, 25, 40, 67, 74, 79], [3, 11, 14, 22, 25, 40, 54, 60, 63, 67, 71, 74, 75, 79, 82], [3, 25, 32, 33, 40, 45, 49, 74, 75], [8, 24, 28, 43, 57, 70], [0, 21, 25, 27, 32, 33, 45, 60, 67, 74, 82, 84], [8, 17, 24, 29, 43, 63], [3, 24, 25, 28, 38, 43, 54, 63, 67, 71, 74, 76, 79, 82], [8, 25, 28, 29, 41, 57, 67, 74, 79], [3, 8, 11, 14, 40, 54, 67, 74, 79, 82], [8, 14, 40, 41, 49, 54, 63, 67, 79], [8, 24, 28, 41, 43, 63, 67, 70, 74, 79], [21, 26, 32, 33, 45, 67, 76, 84, 86], [8, 17, 24, 25, 28, 40, 41, 44, 63, 70, 79], [0, 12, 21, 25, 32, 33, 45, 59, 60, 74, 76, 82, 84], [0, 12, 33, 53, 80, 84], [43, 63, 67, 74, 79], [8, 28, 41, 43, 63, 79], [8, 11, 43, 67, 79], [17, 26, 27, 32, 33, 43, 45, 60, 67, 71, 74, 79, 82, 84], [3, 10, 25, 38, 40, 63, 66, 67, 74, 75, 79], [7, 8, 10, 11, 14, 40, 63, 67, 79], [0, 12, 27, 32, 33, 55, 72, 84], [3, 10, 25, 49, 60, 67, 71, 74, 79, 82], [9, 11, 16, 25, 44, 54, 76, 86], [0, 25, 26, 27, 32, 33, 45, 60, 74, 82, 83, 84], [44, 54, 67, 74, 79], [3, 8, 10, 25, 43, 63, 67, 75, 76, 79], [3, 9, 10, 11, 13, 17, 25, 27, 32, 33, 37, 38, 40, 44, 54, 60, 67, 71, 74, 75, 76, 79, 82, 84], [7, 8, 10, 24, 28, 29, 49, 54, 57, 63, 67, 70, 74, 79], [3, 21, 25, 27, 33, 40, 60, 67, 71, 74, 75, 76, 79, 82, 84], [3, 11, 16, 17, 24, 25, 38, 40, 43, 44, 63, 67, 74, 79], [0, 24, 27, 32, 33, 43, 63, 67, 79, 84, 86], [3, 10, 11, 25, 31, 40, 75], [25, 32, 33, 42, 45, 60, 67, 69, 71, 74, 76, 82, 83, 84, 86], [7, 8, 14, 24, 28, 41, 43, 57, 63, 67, 75, 76, 79], [3, 7, 8, 10, 11, 17, 25, 40, 54, 67, 71, 74, 75, 76, 79, 82], [25, 67, 74, 79, 82], [10, 25, 38, 40, 54, 57, 74], [7, 8, 40, 54, 67, 74, 79], [0, 12, 26, 27, 32, 33, 55, 72, 84], [10, 25, 27, 74, 76], [10, 11, 25, 74, 79], [8, 24, 28, 29, 41, 57, 63, 67, 79], [8, 13, 16, 17, 24, 28, 29, 37, 41, 44, 63, 67, 70, 76, 79], [0, 26, 32, 33, 35, 45, 55, 76, 84], [8, 10, 11, 14, 24, 28, 38, 40, 43, 54, 70, 79, 80], [8, 40, 54, 70, 79], [8, 28, 29, 41, 43, 57, 63, 70], [8, 17, 24, 28, 40, 43, 63, 67, 79], [8, 17, 24, 25, 28, 33, 54, 60, 63, 67, 70, 74, 79], [3, 7, 8, 57, 67, 74, 79, 82], [10, 11, 24, 28, 57, 63, 67, 79], [0, 25, 26, 35, 59, 71, 74, 76, 84], [3, 10, 11, 25, 40, 44, 74, 76, 82], [17, 25, 26, 27, 32, 33, 43, 45, 59, 60, 67, 71, 74, 76, 79, 82, 83, 84], [7, 10, 40, 71, 74, 75, 79], [7, 8, 10, 14, 24, 54, 76, 79], [8, 17, 24, 25, 28, 43, 63, 67, 70, 79], [3, 7, 8, 10, 11, 14, 28, 40, 41, 54, 70, 75, 79], [12, 25, 40, 47, 67, 74, 75, 76, 79, 84], [8, 24, 29, 41, 43, 63, 70, 79], [0, 12, 20, 25, 27, 32, 33, 42, 60, 72, 76, 83, 84], [11, 25, 32, 45, 54, 60, 67, 71, 74, 79], [11, 43, 57, 74, 80], [8, 11, 24, 28, 29, 41, 63, 67, 70, 76, 79, 86], [8, 17, 24, 28, 41, 43, 57, 67, 70, 74, 79], [14, 22, 40, 54, 67, 74, 76, 79], [3, 11, 24, 40, 57], [0, 2, 4, 16, 33, 37, 44, 76], [21, 32, 45, 56, 60, 74, 82, 83, 84], [7, 10, 11, 38, 40, 67, 74, 76, 80], [3, 24, 25, 28, 32, 41, 43, 45, 60, 67, 74, 79, 82], [10, 14, 54, 63, 79, 80], [7, 8, 24, 28, 41, 43, 63, 67, 74, 79], [11, 14, 17, 57, 67, 76, 79], [0, 9, 12, 16, 25, 37, 40, 45, 47, 72, 76, 80], [0, 6, 21, 25, 26, 27, 32, 33, 45, 55, 60, 67, 71, 72, 74, 76, 82, 83, 84], [21, 25, 26, 27, 33, 45, 55, 74, 82, 83, 87], [3, 7, 8, 10, 11, 25, 40, 74, 75, 76, 79], [3, 8, 25, 45, 49, 60, 63, 67, 74, 82], [3, 8, 10, 11, 24, 25, 28, 40, 43, 54, 63, 67, 74, 79], [3, 10, 11, 25, 27, 32, 33, 38, 40, 44, 45, 60, 67, 71, 74, 79, 82, 84], [2, 4, 11, 14, 22, 37, 44, 46, 76, 78, 80], [2, 24, 40, 41, 79], [8, 17, 28, 29, 41, 63, 79], [3, 11, 17, 25, 40, 63, 67, 74, 82], [3, 7, 8, 11, 63, 67, 79], [25, 33, 40, 45, 60, 67, 71, 72, 74, 75, 79, 82, 83, 84], [8, 17, 24, 25, 28, 43, 54, 63, 67, 74, 79], [3, 11, 22, 25, 38, 40, 60, 74, 76, 80], [25, 26, 27, 32, 38, 74, 82, 84], [11, 27, 37, 43, 67, 79, 82], [11, 17, 26, 27, 28, 32, 33, 43, 57, 67, 71, 76, 79], [8, 24, 28, 43, 63, 79], [7, 8, 11, 17, 25, 43, 45, 54, 60, 63, 67, 71, 74, 79, 82], [8, 11, 24, 32, 43, 45, 60, 63, 67, 74, 79, 82], [24, 28, 63, 67, 79], [8, 28, 43, 67, 79], [17, 43, 67, 71, 74, 79], [8, 17, 24, 28, 41, 43, 57, 63, 67, 70, 79], [8, 24, 28, 29, 40, 41, 43, 54, 63, 67, 70, 79], [11, 25, 26, 32, 33, 45, 59, 60, 66, 71, 74, 82], [8, 40, 43, 63, 67, 76, 79], [3, 10, 25, 45, 50, 60, 67, 71, 74, 75, 82, 84], [11, 24, 27, 33, 37, 67, 74, 79, 84], [8, 28, 63, 67, 79], [24, 29, 63, 67, 74, 79], [11, 25, 26, 27, 35, 55, 67, 71, 74, 82], [3, 7, 8, 10, 14, 24, 25, 40, 54, 63, 67, 71, 79], [11, 17, 40, 43, 45, 49, 60, 63, 79], [3, 8, 11, 14, 40, 49, 54, 67, 74, 79], [8, 24, 28, 63, 70, 79], [3, 11, 15, 25, 37, 38, 40, 54, 74, 76], [25, 40, 67, 71, 74, 79, 82], [3, 11, 14, 25, 38, 40, 54, 67, 74, 79, 82], [8, 17, 24, 41, 63, 67, 70, 79], [3, 8, 17, 43, 54, 74, 76, 82], [25, 32, 33, 45, 56, 60, 67, 74, 82, 84], [29, 43, 44, 57, 74, 79], [0, 12, 25, 26, 27, 32, 33, 59, 60, 71, 72, 74, 83, 84], [3, 8, 11, 14, 24, 40, 43, 49, 54, 57, 63, 67, 70, 74, 76, 78, 79, 82], [14, 24, 40, 54, 57, 79], [3, 8, 11, 24, 28, 40, 41, 59, 63, 67, 70, 79], [3, 8, 14, 24, 43, 63, 67, 74, 79, 82], [3, 7, 10, 11, 22, 28, 31, 33, 37, 45, 47, 59, 60, 63, 69, 71, 75, 79, 82, 84, 86], [8, 24, 43, 57, 67, 79], [8, 11, 24, 28, 29, 41, 63, 67, 70, 79], [10, 11, 14, 40, 54, 71, 75], [0, 12, 26, 27, 32, 33, 53, 55, 59, 72, 84], [3, 11, 14, 24, 25, 40, 41, 43, 54, 63, 67, 79], [3, 8, 11, 14, 24, 40, 54, 63, 67, 74, 79], [8, 10, 37, 41, 44, 63, 67, 70, 74, 79], [21, 25, 26, 27, 32, 33, 45, 55, 59, 60, 74, 76, 83, 84], [25, 26, 45, 59, 60, 67, 74, 82], [25, 26, 35, 74, 84], [8, 17, 24, 28, 29, 41, 43, 57, 63, 67, 70, 79], [4, 9, 21, 25, 27, 32, 33, 45, 49, 67, 76, 84], [0, 6, 12, 13, 16, 25, 27, 32, 33, 37, 44, 45, 60, 67, 72, 74, 82], [0, 11, 12, 14, 25, 26, 27, 32, 33, 35, 45, 54, 59, 60, 67, 72, 74, 79, 84], [3, 8, 10, 11, 14, 25, 31, 40, 54, 67, 74, 75, 79, 82], [3, 25, 67, 71, 74, 79], [3, 10, 11, 12, 17, 20, 22, 25, 26, 27, 32, 33, 43, 45, 54, 55, 59, 60, 63, 67, 71, 74, 76, 79, 82, 84], [0, 11, 17, 18, 25, 26, 27, 32, 33, 45, 55, 59, 60, 67, 71, 72, 74, 76, 79, 82, 84], [8, 17, 24, 25, 28, 29, 41, 43, 45, 60, 63, 67, 70, 74, 82, 83], [3, 10, 25, 38, 40, 76], [8, 17, 24, 28, 41, 63, 67, 79], [8, 11, 17, 24, 28, 41, 63, 67, 70, 79], [12, 26, 27, 32, 33, 53, 55, 60, 72, 83, 84], [3, 10, 25, 60, 67, 71, 74, 79, 82], [8, 10, 11, 24, 28, 29, 41, 57, 63, 67, 70, 78, 79], [7, 11, 14, 24, 29, 54, 63, 67, 74, 79], [0, 3, 11, 17, 25, 26, 31, 33, 35, 43, 45, 51, 55, 60, 67, 74, 82, 83, 84], [8, 17, 24, 28, 29, 41, 43, 45, 63, 67, 70, 79], [3, 8, 28, 40, 41, 49, 63, 70], [7, 8, 17, 25, 27, 33, 43, 45, 54, 60, 63, 67, 71, 74, 79, 82, 84], [0, 3, 21, 25, 27, 32, 33, 45, 60, 67, 71, 74, 79, 82, 83, 84], [8, 63, 67, 74, 75, 76, 79, 80], [8, 17, 24, 25, 43, 45, 60, 63, 67, 74, 79, 82], [8, 11, 24, 28, 29, 41, 43, 57, 63, 70, 75, 79], [3, 11, 14, 38, 79], [0, 42, 45, 54, 67, 71, 72, 74, 82, 84], [11, 14, 40, 57, 67, 74, 79, 80], [8, 12, 17, 28, 32, 33, 45, 49, 60, 62, 67, 74, 75, 79, 82], [7, 8, 17, 24, 28, 41, 63, 67, 79], [3, 11, 25, 27, 33, 40, 49, 54, 59, 69, 82], [21, 25, 27, 32, 33, 45, 60, 62, 67, 69, 74, 76, 82, 83, 84, 86], [3, 8, 25, 40, 60, 63, 67, 71, 74, 76, 79, 82], [8, 25, 28, 63, 67, 74, 79], [3, 10, 11, 14, 24, 40, 54, 79], [0, 26, 27, 32, 33, 35, 45, 59, 60, 74, 84], [8, 28, 29, 41, 63, 70], [28, 29, 67, 78, 79], [8, 11, 14, 24, 25, 28, 37, 40, 54, 63, 67, 74, 79], [8, 14, 29, 41, 43, 49, 54, 70, 79], [3, 11, 14, 44, 54, 74, 76, 79, 82], [3, 8, 10, 11, 14, 24, 25, 43, 44, 54, 57, 59, 67, 71, 74, 76, 79], [0, 9, 12, 26, 27, 32, 33, 45, 60, 67, 71, 72, 74, 79, 84, 86], [3, 10, 11, 14, 54, 76, 79], [8, 24, 43, 67, 79], [3, 10, 11, 40, 49], [2, 8, 14, 24, 43, 54, 63, 76], [0, 3, 7, 8, 11, 12, 17, 21, 24, 25, 26, 27, 28, 29, 32, 33, 37, 43, 44, 45, 55, 59, 60, 63, 67, 71, 72, 74, 75, 79, 82, 83, 84, 86], [16, 37, 63, 67, 79], [2, 5, 13, 16, 37, 44], [8, 17, 24, 28, 41, 57, 63, 67, 70, 74, 79], [44, 67, 74, 76, 79, 82], [12, 25, 27, 32, 33, 44, 45, 60, 67, 74, 76, 82, 83, 84, 86], [8, 40, 63, 70, 75, 79], [11, 28, 38, 40, 50, 78, 79], [17, 25, 27, 32, 33, 40, 43, 45, 60, 67, 71, 74, 76, 79, 82, 84], [8, 17, 28, 43, 73, 79], [3, 5, 10, 11, 25, 45, 60, 67, 74, 80, 82, 83], [25, 27, 44, 60, 67, 69, 82, 84], [3, 11, 40, 63, 67, 74, 79], [8, 11, 43, 54, 63, 67, 74, 79], [8, 24, 29, 54, 63, 70, 76, 79], [17, 41, 67, 76, 80], [14, 25, 26, 32, 43, 45, 54, 60, 67, 74, 79, 82, 84], [8, 11, 13, 16, 17, 24, 28, 29, 37, 41, 44, 63, 67, 70, 74, 76, 79], [25, 40, 54, 74, 76, 82], [8, 28, 29, 41, 43, 70, 79], [12, 26, 32, 33, 53, 59, 84], [7, 11, 17, 24, 25, 40, 43, 54, 63, 67, 75, 79, 80], [8, 14, 24, 28, 41, 54, 63, 67, 70, 79], [8, 11, 17, 25, 74, 76, 79], [3, 11, 25, 43, 60, 66, 71, 74, 82], [8, 24, 29, 63, 67, 74, 79], [3, 11, 14, 24, 25, 40, 54, 57, 63, 67, 79], [11, 40, 67, 71, 79], [8, 11, 14, 17, 18, 24, 28, 37, 40, 41, 43, 54, 63, 67, 70, 79], [6, 25, 26, 32, 33, 45, 53, 55, 56, 60, 67, 71, 84], [11, 22, 38, 40, 54], [0, 10, 25, 26, 27, 31, 32, 45, 60, 67, 69, 72, 74, 82, 83, 84], [14, 54, 67, 74, 79], [11, 25, 32, 33, 55, 60, 74, 82, 84, 86], [3, 8, 10, 11, 14, 24, 28, 29, 41, 43, 54, 63, 70, 74, 76, 79], [3, 10, 11, 14, 25, 40, 49, 67, 74, 76, 79], [8, 17, 28, 41, 43, 67, 70, 79], [7, 8, 17, 24, 25, 28, 41, 43, 63, 67, 70, 79], [8, 24, 63, 67, 79], [8, 9, 13, 16, 37, 40, 63, 67, 74, 79], [32, 43, 60, 67, 71, 72, 74, 79, 82], [6, 17, 21, 32, 45, 60, 71, 74, 82, 84], [0, 12, 25, 32, 45, 60, 67, 72, 74, 82, 84], [8, 17, 43, 54, 63, 67, 79], [8, 28, 29, 41, 63, 67, 70, 79], [8, 11, 14, 17, 24, 43, 54, 57, 63, 67, 74, 79], [3, 7, 8, 10, 11, 14, 17, 22, 24, 28, 29, 38, 40, 49, 54, 63, 67, 71, 74, 75, 76, 79], [8, 17, 24, 40, 43, 54, 57, 63, 67, 79], [3, 8, 10, 11, 14, 22, 38, 40, 57, 63, 74, 75, 76, 78, 79], [0, 12, 25, 27, 32, 33, 45, 60, 67, 72, 74, 82, 84], [3, 4, 41, 43, 44, 63, 67, 76, 79], [3, 10, 11, 38, 40, 79], [8, 24, 29, 40, 70, 79], [10, 25, 37, 67, 76], [8, 17, 28, 41, 43, 54, 63, 67, 70, 79], [6, 12, 32, 45, 53, 60, 67, 74, 76, 79, 82, 84], [10, 11, 14, 38, 40, 54, 67, 78, 79], [3, 10, 11, 25, 26, 27, 33, 45, 49, 56, 60, 67, 71, 74, 75, 76, 82, 83, 84], [3, 8, 10, 11, 14, 17, 22, 24, 29, 40, 41, 43, 54, 57, 63, 74, 79], [3, 8, 24, 25, 28, 40, 43, 49, 63, 67, 70, 71, 79, 82], [8, 17, 24, 29, 41, 43, 57, 63, 67, 73, 79], [3, 7, 11, 40, 49, 54, 67, 75, 79, 82], [3, 10, 11, 14, 40, 54, 60, 67, 74, 82], [8, 10, 11, 25, 63, 67, 71, 74, 79, 82], [11, 14, 22, 43, 50, 67, 76, 78, 86], [0, 11, 12, 25, 26, 33, 40, 44, 49, 67, 74, 76, 79, 82], [11, 24, 38, 40, 57, 67, 79], [8, 17, 28, 43, 45, 63, 67, 70, 79], [8, 14, 17, 24, 28, 29, 41, 43, 57, 63, 67, 70, 79], [0, 9, 12, 26, 32, 33, 35, 51, 59, 72, 73, 83, 84], [11, 25, 27, 32, 33, 45, 60, 67, 71, 74, 82, 84], [3, 8, 10, 11, 17, 24, 28, 29, 40, 43, 54, 63, 67, 76], [8, 17, 18, 24, 25, 28, 43, 63, 67, 70, 74, 79], [9, 11, 16, 22, 44, 65, 76, 80], [8, 11, 24, 25, 28, 40, 41, 43, 63, 67, 74, 79], [8, 17, 28, 41, 43, 63, 67, 70, 79], [8, 24, 28, 29, 43, 57, 63, 67, 70, 74, 76, 79], [6, 26, 27, 32, 33, 35, 55, 72, 84], [8, 24, 28, 29, 37, 43, 63, 67, 70], [7, 11, 25, 40, 50, 54, 71, 75, 79], [7, 11, 15, 43, 54, 67, 71, 79], [26, 27, 32, 33, 60, 84], [3, 7, 25, 27, 33, 45, 60, 67, 82, 84], [7, 8, 40, 54, 79], [16, 25, 32, 37, 44, 60, 67, 71, 74, 76, 82], [11, 14, 38, 40, 54, 74, 78], [8, 16, 28, 37, 63, 76], [10, 11, 14, 25, 67, 74, 79], [3, 11, 16, 44, 76], [10, 11, 14, 25, 37, 40, 54, 67, 76, 79], [8, 17, 43, 54, 63, 67, 71, 74, 79, 82, 84], [3, 10, 11, 25, 40, 45, 49, 54, 67, 71, 75, 79, 82], [40, 67, 74, 76, 84], [3, 25, 30, 43, 54, 56, 67, 74, 76, 79, 82], [0, 3, 8, 9, 10, 21, 25, 26, 27, 32, 33, 40, 43, 45, 60, 62, 67, 74, 76, 79, 82, 83, 84], [11, 24, 38, 54, 63, 67, 74, 79], [3, 8, 16, 17, 19, 24, 25, 26, 28, 33, 44, 72, 76, 84], [8, 10, 40, 49, 60, 67, 74, 75, 79, 82], [0, 3, 7, 17, 21, 25, 26, 27, 30, 32, 33, 40, 43, 45, 49, 54, 55, 59, 60, 67, 71, 72, 74, 75, 79, 82, 83, 84], [3, 10, 11, 25, 76], [7, 8, 28, 29, 57, 63, 70], [8, 14, 24, 40, 79], [3, 7, 8, 10, 11, 17, 24, 25, 28, 40, 41, 49, 54, 63, 67, 70, 79], [7, 10, 16, 17, 25, 27, 42, 67, 69, 76, 82], [11, 12, 21, 25, 32, 33, 45, 67, 74, 84], [0, 12, 25, 26, 27, 32, 33, 35, 59, 60, 72, 82, 84], [7, 25, 29, 43, 45, 67, 74], [3, 25, 27, 32, 33, 40, 45, 49, 60, 74, 82, 84], [7, 8, 10, 14, 29, 40, 54, 76, 79], [0, 12, 26, 32, 33, 83, 84], [8, 17, 24, 28, 29, 41, 43, 63, 70, 79], [1, 2, 9, 13, 20, 34, 37, 76, 80], [25, 27, 32, 45, 60, 67, 82, 84], [8, 14, 29, 54, 63, 67], [25, 60, 67, 71, 74, 82, 84], [8, 24, 28, 41, 43, 63, 67, 70, 79], [0, 3, 11, 12, 17, 21, 25, 26, 27, 32, 33, 40, 42, 45, 60, 66, 67, 71, 72, 74, 82, 84, 86], [3, 7, 10, 11, 54, 67, 74, 79], [8, 24, 29, 57, 79], [8, 24, 63, 67, 76, 79], [0, 6, 25, 27, 32, 33, 60, 67, 72, 74, 82, 83, 84, 87], [17, 19, 20, 25, 26, 27, 32, 33, 43, 44, 55, 56, 59, 60, 67, 72, 76, 79, 82, 83, 84], [8, 11, 25, 38, 40, 67, 71, 74], [17, 25, 32, 33, 43, 44, 45, 67, 71, 74, 76, 79, 82, 83, 84], [50, 54, 59, 76, 79], [8, 24, 28, 40, 41, 43, 54, 63, 67, 70, 79], [8, 11, 24, 28, 40, 41, 63, 67, 70, 79], [8, 11, 17, 25, 43, 45, 54, 60, 63, 67, 71, 74, 79, 82], [0, 25, 26, 32, 33, 45, 59, 60, 67, 74, 82, 84], [0, 1, 12, 25, 27, 32, 33, 42, 44, 45, 60, 72, 74, 76, 82, 83, 84], [8, 17, 28, 29, 40, 41, 43, 56], [8, 11, 17, 24, 28, 29, 43, 57, 67, 79], [3, 24, 40, 41, 49, 74, 79], [8, 24, 28, 29, 41, 63, 67, 79], [14, 24, 25, 32, 43, 45, 54, 60, 67, 71, 74, 76, 79, 82], [8, 28, 54, 57, 67, 74, 79], [8, 24, 29, 41, 63, 67, 70, 79], [8, 11, 16, 17, 24, 25, 28, 38, 41, 43, 44, 63, 67, 74, 76, 79, 82], [8, 24, 63, 67, 79], [3, 10, 11, 12, 17, 20, 22, 25, 26, 27, 32, 33, 43, 45, 54, 55, 59, 60, 63, 67, 71, 74, 76, 79, 82, 84], [0, 20, 55, 68, 84], [11, 38, 40, 66, 74, 79], [14, 24, 40, 79, 80], [8, 24, 29, 63, 67, 79], [3, 7, 8, 11, 14, 40, 49, 63, 67, 75, 79], [3, 8, 10, 11, 14, 24, 25, 40, 49, 54, 63, 70, 71, 79], [7, 9, 10, 13, 16, 20, 25, 44, 46, 74, 75, 76, 80, 82], [0, 21, 25, 27, 32, 33, 40, 45, 60, 67, 71, 72, 74, 82, 83, 84], [3, 8, 11, 24, 25, 28, 29, 41, 45, 49, 60, 62, 63, 67, 70, 74, 75, 79, 82], [10, 11, 24, 25, 40, 63, 67, 76, 79], [0, 12, 13, 16, 25, 42, 72, 82, 84], [10, 11, 25, 40, 54, 74, 75, 79], [59, 60, 74, 82, 84], [0, 6, 25, 26, 27, 32, 33, 45, 60, 67, 71, 72, 74, 83, 84], [8, 24, 28, 41, 63, 67, 70, 79], [3, 7, 10, 11, 76, 78], [17, 24, 25, 32, 33, 43, 67, 71, 72, 74, 79], [3, 8, 10, 14, 24, 28, 63, 67, 71, 74, 76, 79], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [0, 12, 26, 32, 33, 35, 59, 72, 74, 84], [8, 17, 24, 28, 41, 43, 63, 67, 70, 71, 74, 79], [0, 3, 12, 13, 16, 20, 25, 27, 30, 32, 33, 37, 42, 44, 45, 60, 67, 69, 71, 72, 73, 74, 82, 83, 84], [8, 11, 14, 24, 28, 54, 63, 67, 79], [4, 8, 43, 57, 74, 76, 79], [25, 32, 43, 45, 57, 60, 67, 69, 71, 74, 82], [12, 25, 27, 32, 33, 35, 55, 56, 59, 60, 67, 68, 71, 74, 82, 84], [3, 7, 10, 40, 54, 74, 76, 79], [10, 11, 40, 75, 80], [17, 43, 45, 60, 63, 67, 79, 82], [8, 12, 17, 18, 24, 25, 41, 43, 63, 67, 73, 74, 79, 86], [7, 8, 10, 11, 24, 28, 29, 38, 57, 63, 74, 79], [24, 28, 41, 70, 79], [0, 21, 25, 26, 27, 54, 59, 60, 82, 84], [0, 3, 21, 26, 33, 45, 55, 60, 67, 72, 82, 84], [26, 27, 32, 33, 37, 45, 55, 60, 63, 67, 74, 79, 82, 84], [8, 28, 38, 40, 41, 49, 63, 70, 79], [10, 11, 14, 24, 54, 57, 74, 78, 79], [10, 25, 45, 49, 74, 75, 80, 82], [8, 17, 40, 67, 71], [8, 24, 28, 29, 43, 63, 67, 70, 79], [0, 12, 21, 26, 27, 30, 32, 33, 72, 74, 83, 84], [17, 24, 28, 41, 43, 63, 67, 70], [8, 28, 43, 63, 67, 79], [8, 10, 11, 14, 76, 79, 80], [3, 10, 11, 25, 26, 45, 54, 60, 67, 71, 74, 76, 82, 84], [3, 7, 8, 10, 25, 28, 40, 63, 67, 79], [8, 10, 11, 24, 25, 37, 44, 63, 67, 79, 82], [25, 27, 44, 45, 60, 67, 71, 74, 76, 79, 82], [8, 22, 24, 28, 63, 79], [3, 10, 11, 14, 22, 25, 38, 40, 49, 54, 60, 74, 79, 82], [8, 11, 14, 17, 24, 28, 40, 41, 43, 49, 63, 67, 76, 79], [7, 10, 11, 28, 40, 63, 67, 74, 79, 82, 86], [10, 11, 16, 17, 25, 27, 32, 33, 40, 44, 60, 67, 71, 74, 79, 82], [7, 25, 40, 54, 74, 75, 76], [3, 8, 24, 43, 49, 75], [8, 17, 25, 43, 54, 63, 67, 71, 74, 79], [3, 11, 28, 41, 43, 76, 79], [7, 10, 11, 12, 16, 22, 25, 37, 44, 64, 69, 71, 72, 74, 75, 76, 80, 82, 84], [0, 12, 26, 27, 33, 35, 53, 55, 72, 84], [0, 30, 32, 33, 60, 67, 72, 74, 79, 82, 84], [0, 11, 12, 25, 26, 27, 32, 33, 40, 54, 67, 72, 74, 79, 82, 84], [11, 25, 27, 32, 33, 38, 45, 60, 62, 67, 69, 74, 76, 82, 83, 84], [25, 26, 27, 32, 33, 45, 49, 56, 60, 67, 71, 74, 82, 84], [3, 10, 11, 38, 40, 54, 67, 74, 79], [17, 24, 25, 43, 63, 67, 79], [11, 17, 18, 24, 25, 28, 38, 40, 43, 57, 63, 67, 71, 74, 75, 79], [17, 28, 29, 43, 63, 67, 78, 79, 86], [8, 14, 17, 24, 28, 29, 40, 54, 63, 67, 79], [3, 11, 24, 25, 40, 43, 45, 60, 63, 67, 71, 74, 79, 82], [3, 8, 10, 11, 25, 40, 49, 67, 74, 79, 80, 82], [8, 17, 24, 25, 28, 29, 41, 43, 63, 67, 70, 71, 74, 79], [7, 8, 11, 28, 43, 67, 74, 79], [10, 45, 60, 67, 71, 74, 79, 82], [8, 17, 28, 41, 43, 63, 71], [11, 20, 40, 49, 63, 67, 71, 74, 79], [8, 11, 17, 24, 25, 40, 43, 63, 67, 70, 74, 76, 79], [8, 10, 11, 24, 28, 54, 57, 63, 70, 74, 79, 82], [3, 10, 25, 40, 71, 74, 76, 79, 86], [11, 14, 40, 54, 76, 78, 79], [25, 26, 27, 32, 33, 43, 44, 55, 60, 67, 72, 74, 76, 79, 82, 83, 84], [7, 8, 10, 11, 24, 25, 28, 67, 79], [17, 44, 67, 74, 83], [3, 8, 10, 11, 43, 67, 74, 79], [8, 25, 28, 49, 63, 67, 74, 79, 82], [3, 8, 10, 11, 24, 28, 63, 67, 76, 79], [12, 25, 26, 27, 32, 33, 45, 60, 63, 67, 71, 74, 79, 82, 84], [20, 46, 54, 58, 71, 74, 76], [8, 11, 17, 28, 29, 41, 43, 63, 79], [2, 11, 16, 37, 44, 76, 80], [8, 25, 26, 27, 29, 32, 33, 43, 45, 60, 67, 74, 79, 83, 84], [3, 20, 25, 43, 54, 69, 82], [8, 22, 24, 28, 29, 40, 41, 63, 67, 71, 74, 79], [0, 10, 13, 16, 25, 26, 40, 44, 45, 60, 67, 74, 82], [0, 12, 25, 26, 27, 32, 33, 44, 45, 60, 72, 74, 83, 84], [0, 25, 26, 45, 60, 67, 74, 84], [8, 24, 28, 29, 41, 43, 57, 63, 67, 79], [17, 18, 25, 43, 63, 67, 71, 73, 74, 79], [3, 7, 10, 11, 14, 25, 40, 43, 49, 54, 74, 75, 79, 82], [3, 8, 11, 14, 24, 25, 43, 54, 60, 63, 67, 74, 79, 82], [3, 8, 11, 17, 21, 25, 27, 28, 32, 33, 45, 49, 60, 67, 74, 75, 76, 79, 82, 84], [8, 17, 18, 24, 28, 29, 41, 43, 45, 60, 63, 67, 70, 74, 79, 82], [12, 21, 26, 27, 32, 45, 60, 62, 67, 79, 84], [7, 8, 10, 11, 28, 29, 63, 79, 80], [7, 17, 24, 25, 37, 40, 43, 67, 71, 74, 79], [8, 10, 14, 24, 38, 57, 60, 63, 66, 67, 71, 74, 79, 82], [3, 11, 16, 17, 20, 28, 44], [8, 24, 41, 43, 63, 67, 70, 74, 79], [8, 24, 29, 41, 43, 70], [11, 43, 67, 69, 74, 79], [8, 24, 28, 29, 40, 41, 57, 63, 70, 74, 79], [10, 11, 14, 24, 25, 40, 44, 54, 63, 67, 76, 79], [3, 11, 25, 37, 43, 45, 49, 59, 60, 67, 74, 76, 82, 84], [8, 10, 14, 24, 28, 29, 40, 54, 63, 70, 79], [3, 7, 11, 40, 75, 79], [0, 12, 25, 26, 27, 32, 33, 45, 59, 60, 72, 74, 82, 84], [24, 29, 54, 63, 67, 71, 78, 79], [6, 27, 35, 45, 54, 55, 60], [57, 63, 67, 74, 79], [8, 11, 14, 24, 28, 40, 41, 54, 63, 67, 70, 74, 79], [3, 8, 11, 24, 28, 38, 40, 43, 49, 63, 67, 70, 74, 79], [8, 24, 28, 41, 63, 70, 79], [3, 21, 25, 32, 43, 45, 60, 67, 74, 82, 84], [11, 40, 67, 76, 79], [8, 24, 43, 54, 57, 63, 79], [25, 27, 33, 83, 84], [12, 16, 27, 32, 33, 53, 67, 72, 83, 84], [13, 14, 16, 37, 41, 44, 54, 76, 79], [8, 43, 67, 70, 79], [8, 17, 24, 28, 57, 63, 67, 74, 79], [11, 25, 26, 27, 32, 33, 35, 45, 59, 60, 67, 74, 82, 84], [8, 10, 11, 14, 24, 40, 54, 63, 79], [11, 12, 22, 24, 26, 27, 33, 63, 67, 74, 79, 84], [8, 29, 54, 63, 79], [3, 4, 11, 13, 16, 17, 18, 25, 27, 43, 48, 67, 73, 74, 76, 80, 82], [27, 33, 49, 67, 71, 74, 82], [0, 9, 12, 21, 25, 27, 32, 33, 38, 43, 44, 55, 60, 67, 76, 80, 83, 84], [3, 8, 11, 14, 22, 28, 40, 41, 43, 54, 57, 63, 79], [3, 7, 8, 11, 24, 40, 63, 74, 75, 79], [8, 24, 28, 29, 41, 63, 79], [22, 24, 28, 29, 40, 67, 79], [3, 8, 11, 17, 24, 28, 29, 41, 43, 57, 67, 70, 79], [3, 21, 25, 27, 37, 45, 49, 60, 67, 74, 75, 82, 84], [8, 67, 74, 76, 79, 82], [10, 14, 22, 40, 54, 67, 79, 80], [4, 11, 16, 44, 76, 80], [3, 17, 25, 27, 32, 43, 45, 60, 67, 71, 74, 76, 82, 83, 84], [3, 7, 10, 11, 14, 25, 40, 67, 74, 79, 82], [24, 28, 41, 43, 63, 67, 70, 79], [3, 17, 41, 43, 54, 63, 67, 79], [3, 8, 10, 14, 25, 40, 43, 54, 63, 67, 76, 79], [0, 12, 26, 27, 33, 35, 59, 72, 84], [3, 4, 10, 11, 25, 50, 66, 76], [8, 17, 43, 44, 45, 67, 71, 76, 82], [17, 25, 28, 29, 41, 43, 45, 54, 60, 63, 67, 70, 74, 82], [3, 10, 11, 25, 38, 40, 57, 67, 71, 74, 76, 82], [8, 25, 26, 28, 41, 43, 63, 67, 70, 74, 79], [10, 24, 57, 76, 86], [11, 25, 45, 49, 54, 56, 60, 74, 82], [0, 7, 25, 37, 67, 71, 72, 74, 76, 79], [22, 25, 32, 33, 60, 74, 76, 84], [7, 8, 29, 63, 67, 74, 79], [3, 8, 11, 17, 24, 25, 41, 43, 63, 67, 71, 74, 76, 79, 82], [9, 12, 25, 26, 27, 32, 33, 45, 59, 72], [11, 25, 27, 32, 33, 60, 67, 72, 74, 82], [8, 9, 10, 24, 28, 29, 57, 79], [12, 26, 27, 32, 33, 35, 55, 60, 72, 83, 84], [0, 32, 33, 45, 60, 67, 72, 74, 76, 82, 84], [8, 11, 17, 24, 28, 43, 63, 67, 70, 79], [3, 11, 14, 24, 40, 43, 67, 76, 78, 79], [17, 21, 25, 27, 32, 33, 43, 45, 54, 56, 60, 67, 74, 79, 82, 83, 84], [11, 14, 24, 63, 67, 74, 79], [21, 25, 26, 27, 32, 33, 45, 60, 67, 71, 82, 84], [8, 43, 57, 63, 67, 79], [3, 11, 25, 40, 49, 63, 67, 74, 75, 79, 82], [8, 17, 24, 28, 43, 63, 67, 79], [3, 11, 14, 40, 54, 63, 78, 79], [25, 27, 32, 33, 37, 44, 60, 69, 74, 76, 82, 84], [6, 26, 27, 56, 60, 71, 74, 84], [10, 11, 25, 37, 74, 76, 82], [7, 8, 10, 11, 24, 28, 29, 40, 41, 43, 49, 67, 70, 79], [8, 17, 24, 28, 29, 41, 43, 44, 60, 63, 67, 70, 74, 76, 79, 82], [8, 17, 24, 43, 67, 79], [3, 10, 11, 21, 25, 67, 71, 74, 75, 82], [8, 11, 23, 28, 38, 63], [8, 17, 18, 24, 25, 28, 32, 33, 43, 45, 60, 63, 67, 71, 74, 79, 82], [11, 26, 32, 33, 56, 60, 74, 82], [8, 12, 27, 32, 40, 45, 60, 63, 67, 74, 79, 82, 83, 84], [25, 67, 71, 74, 82, 84], [8, 10, 11, 24, 25, 28, 38, 40, 41, 43, 54, 60, 63, 67, 71, 74, 76, 79, 82], [3, 25, 40, 49, 63, 67, 71, 79, 82], [0, 13, 16, 26, 27, 32, 33, 35, 45, 59, 60, 72, 76, 83, 84], [7, 11, 14, 24, 28, 40, 57, 67, 75, 79], [8, 25, 27, 32, 33, 40, 45, 60, 67, 71, 74, 79, 82, 84], [12, 27, 32, 33, 60, 67, 84], [7, 8, 24, 29, 40, 57, 63, 67, 79], [21, 27, 32, 33, 67, 82, 84], [3, 10, 11, 25, 40, 43, 45, 49, 54, 67, 74, 75, 79, 82], [7, 8, 17, 22, 24, 43, 63, 67, 76, 79, 86], [11, 17, 21, 24, 25, 37, 40, 43, 45, 60, 63, 67, 71, 74, 79, 82], [10, 11, 17, 25, 27, 28, 33, 45, 48, 63, 67, 74], [17, 25, 37, 45, 60, 63, 67, 74, 79, 82], [24, 29, 57, 67, 74, 79], [0, 12, 21, 25, 27, 32, 33, 45, 60, 72, 82, 84], [8, 10, 11, 14, 40, 54, 63, 78, 79], [12, 27, 32, 33, 59, 60, 63, 67, 74, 79, 83, 84], [3, 10, 11, 22, 50, 76, 78, 86], [9, 11, 37, 40, 76, 80], [11, 14, 17, 24, 28, 40, 41, 43, 54, 63, 67, 70, 74, 79], [8, 24, 28, 63, 67, 70, 79], [21, 25, 26, 27, 32, 33, 45, 60, 67, 71, 74, 84], [32, 45, 60, 74, 76, 82], [8, 10, 11, 14, 24, 29, 40, 41, 43, 54, 63, 67, 74, 79], [0, 12, 33, 45, 67, 72, 76, 84], [25, 33, 45, 71, 74, 82], [25, 44, 60, 67, 76, 83], [11, 44, 46, 76, 86], [21, 30, 32, 59, 84, 86], [8, 11, 17, 25, 28, 30, 45, 60, 67, 74, 75, 79], [9, 10, 11, 25, 40, 54, 56], [8, 40, 41, 67, 74, 79], [25, 26, 27, 32, 60, 67, 71, 72, 74, 82], [3, 11, 25, 49, 66, 74, 82], [10, 14, 24, 28, 40, 54, 67, 78, 79], [8, 11, 14, 24, 40, 54, 67, 74, 79], [9, 16, 17, 37, 43, 44, 45, 63, 67, 71, 74, 75, 76, 79, 84], [3, 14, 25, 60, 67, 71, 74, 76, 79, 82], [25, 27, 32, 33, 45, 60, 74, 82, 84], [3, 10, 11, 38, 66], [8, 17, 24, 28, 29, 41, 43, 57, 63, 70, 79], [8, 25, 43, 45, 63, 67, 71, 74, 76, 79, 82], [11, 14, 24, 29, 43, 54, 67, 79], [10, 11, 40, 54, 79], [10, 41, 43, 57, 67, 74, 76], [11, 25, 33, 49, 67, 74, 79, 80, 82], [22, 24, 49, 67, 71, 74, 79], [8, 24, 28, 43, 63], [8, 17, 24, 28, 29, 41, 63, 67, 70, 74, 79], [3, 7, 11, 71, 75, 76, 78, 79], [7, 8, 17, 25, 28, 43, 63, 67, 71, 79], [3, 7, 57, 75, 79], [3, 11, 25, 26, 27, 32, 33, 40, 45, 54, 60, 71, 74, 79, 82, 84], [3, 8, 11, 14, 40, 43, 54, 63, 67, 74, 76, 79], [11, 24, 28, 40, 41, 67, 70, 75], [3, 11, 25, 54, 63, 67, 74, 79], [8, 24, 25, 28, 41, 63, 67, 70, 76, 79], [8, 17, 24, 28, 41, 54, 63, 67, 76, 79], [10, 29, 74, 76, 79], [10, 11, 14, 38, 40, 54, 57, 79], [40, 43, 54, 67, 79, 84], [0, 26, 32, 33, 35, 45, 60, 61, 72, 84], [3, 11, 40, 49, 60, 63, 67, 74, 79, 82], [0, 17, 25, 26, 27, 32, 33, 37, 43, 45, 60, 67, 71, 76, 82, 84], [9, 16, 26, 32, 33, 43, 55, 76, 80, 83, 84], [3, 25, 43, 74, 79, 82], [3, 8, 24, 28, 41, 49, 67, 70, 79], [8, 14, 17, 24, 28, 41, 43, 63, 67, 70], [8, 11, 24, 63, 70, 79], [3, 8, 11, 17, 26, 35, 38, 43, 44, 55, 63, 70, 71, 76, 80, 82, 83]]\n"
     ]
    }
   ],
   "source": [
    "following_true = [0]*len(user_following)\n",
    "for i in range(len(user_following)):\n",
    "    each_user = []\n",
    "    for j in range(len(user_following[i])):\n",
    "        if user_following[i][j] == 1:\n",
    "            each_user.append(j)\n",
    "    following_true[i] = each_user\n",
    "print(following_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followings  5\n",
      "Max number of followings  34\n"
     ]
    }
   ],
   "source": [
    "#following \n",
    "minlen = 10000\n",
    "maxlen = 0\n",
    "for i in range(len(following_true)):\n",
    "    if len(following_true[i]) < minlen:\n",
    "        minlen = len(following_true[i])\n",
    "    if len(following_true[i]) > maxlen:\n",
    "        maxlen = len(following_true[i])\n",
    "print('Min number of followings ',minlen)\n",
    "print('Max number of followings ',maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_amount = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx = [i for i in range(len(user_following))]\n",
    "#test_idx is the number of user for testing\n",
    "test_idx = random.sample(user_idx,test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training  and Testing\n",
    "train_t = [0]*(len(user_following))\n",
    "train_f = [0]*(len(user_following))\n",
    "# Testing \n",
    "test_t = [0]*test_amount\n",
    "test_f = [0]*test_amount\n",
    "test_pos = -1\n",
    "\n",
    "for i in range(len(user_following)):\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "        for j in range(88):\n",
    "            if user_following[i][j] == 1:\n",
    "                t_for_train.append(j)\n",
    "            else:\n",
    "                f_for_train.append(j)\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train\n",
    "        \n",
    "    else: #if in test id, choose 2 true and other \n",
    "        test_pos += 1\n",
    "        temp_t = []\n",
    "        temp_f = []\n",
    "        for j in range(88):\n",
    "            if user_following[i][j] == 1:\n",
    "                temp_t.append(j)\n",
    "            else:\n",
    "                temp_f.append(j)\n",
    "        # random choose 2 true and 8 false for test \n",
    "        t_for_test = random.sample(temp_t,2)\n",
    "        f_for_test  = random.sample(temp_f,8)\n",
    "        test_t[test_pos] = t_for_test\n",
    "        test_f[test_pos] = f_for_test\n",
    "        \n",
    "        #other for training\n",
    "        t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "        f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 1489\n",
      "The length of train_f: 1489\n",
      "The length of test_t: 150\n",
      "The length of test_f: 150\n"
     ]
    }
   ],
   "source": [
    "# train_t[i] user i positive feedback\n",
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_t))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 7, 9, 7, 7, 12, 10, 13, 5, 15, 12, 12, 6, 21, 9, 7, 4, 15, 10, 8, 7, 6, 11, 10, 14, 7, 11, 10, 12, 11, 14, 5, 10, 17, 6, 6, 6, 11, 5, 3, 20, 6, 10, 10, 16, 12, 11, 11, 5, 6, 11, 7, 11, 5, 13, 7, 11, 8, 11, 8, 5, 19, 10, 3, 10, 16, 11, 19, 6, 6, 9, 15, 11, 9, 7, 11, 5, 10, 9, 10, 9, 12, 7, 6, 13, 12, 4, 10, 10, 9, 12, 13, 7, 6, 11, 19, 13, 12, 11, 7, 7, 17, 13, 5, 12, 7, 12, 11, 9, 8, 6, 7, 12, 11, 8, 9, 13, 14, 11, 16, 6, 11, 5, 17, 5, 12, 5, 15, 10, 10, 18, 15, 13, 5, 5, 5, 8, 8, 6, 7, 12, 14, 13, 7, 20, 6, 5, 12, 13, 5, 10, 5, 9, 12, 18, 12, 11, 7, 11, 7, 12, 7, 16, 18, 7, 5, 6, 10, 7, 10, 7, 11, 5, 10, 10, 6, 11, 9, 19, 21, 5, 6, 11, 6, 10, 9, 7, 13, 18, 8, 12, 6, 8, 14, 12, 16, 8, 7, 9, 24, 14, 13, 11, 8, 5, 13, 10, 9, 12, 11, 8, 6, 19, 13, 6, 12, 12, 7, 23, 5, 10, 6, 6, 18, 14, 10, 18, 15, 5, 21, 10, 5, 7, 7, 10, 14, 9, 22, 11, 10, 8, 15, 19, 8, 13, 12, 9, 10, 5, 7, 11, 11, 13, 9, 12, 7, 12, 5, 7, 9, 10, 13, 12, 5, 16, 6, 7, 11, 8, 15, 6, 4, 6, 5, 6, 10, 12, 12, 5, 11, 6, 11, 7, 11, 7, 5, 14, 8, 13, 11, 9, 5, 15, 11, 10, 12, 6, 21, 7, 6, 8, 8, 9, 8, 21, 5, 11, 12, 13, 8, 10, 19, 6, 7, 12, 15, 14, 6, 8, 14, 5, 7, 9, 9, 9, 9, 6, 11, 14, 5, 6, 12, 14, 12, 11, 12, 13, 5, 18, 16, 5, 11, 7, 6, 10, 13, 11, 13, 14, 6, 9, 11, 11, 15, 5, 6, 6, 9, 23, 9, 15, 7, 7, 7, 5, 9, 14, 10, 11, 7, 12, 12, 13, 8, 14, 11, 10, 11, 14, 7, 19, 12, 11, 11, 11, 5, 5, 15, 13, 14, 9, 11, 12, 17, 12, 12, 8, 14, 12, 11, 12, 7, 19, 9, 6, 15, 10, 13, 8, 8, 9, 11, 3, 6, 13, 8, 5, 13, 18, 6, 16, 20, 14, 10, 7, 8, 10, 14, 8, 6, 7, 10, 10, 13, 9, 17, 6, 15, 12, 6, 14, 9, 9, 18, 9, 17, 6, 12, 12, 6, 5, 9, 12, 5, 10, 6, 10, 10, 13, 10, 9, 9, 10, 12, 13, 8, 7, 10, 7, 14, 8, 7, 24, 12, 5, 6, 13, 23, 5, 8, 9, 14, 16, 8, 20, 11, 19, 10, 11, 11, 9, 8, 11, 7, 10, 10, 8, 8, 10, 7, 13, 10, 10, 7, 13, 6, 7, 8, 14, 7, 7, 9, 12, 6, 10, 6, 20, 6, 10, 6, 12, 8, 9, 5, 19, 9, 8, 14, 17, 9, 8, 8, 10, 14, 6, 18, 5, 11, 5, 7, 9, 12, 6, 9, 12, 13, 16, 8, 14, 4, 11, 9, 7, 5, 11, 7, 12, 6, 6, 7, 15, 9, 12, 15, 4, 17, 17, 12, 13, 7, 7, 5, 6, 5, 22, 13, 8, 17, 12, 11, 12, 8, 14, 14, 7, 10, 8, 13, 7, 17, 5, 12, 6, 10, 7, 7, 11, 13, 10, 12, 13, 11, 14, 12, 8, 11, 6, 9, 18, 16, 7, 10, 6, 11, 19, 10, 5, 12, 11, 11, 8, 14, 13, 6, 9, 8, 10, 9, 12, 6, 5, 7, 7, 14, 12, 11, 7, 8, 14, 8, 13, 10, 6, 7, 8, 26, 8, 6, 6, 8, 5, 25, 9, 12, 6, 10, 17, 12, 7, 12, 8, 6, 5, 12, 3, 9, 9, 8, 12, 16, 6, 9, 5, 11, 21, 6, 12, 19, 22, 10, 7, 6, 15, 10, 13, 6, 9, 13, 14, 13, 7, 6, 5, 14, 11, 7, 14, 11, 8, 15, 6, 5, 13, 4, 17, 8, 18, 18, 8, 12, 18, 15, 17, 7, 6, 8, 13, 5, 4, 10, 12, 6, 10, 8, 9, 12, 11, 8, 14, 6, 13, 6, 5, 9, 11, 13, 6, 8, 18, 13, 9, 16, 8, 6, 15, 14, 18, 6, 15, 6, 9, 7, 5, 16, 10, 11, 13, 10, 10, 10, 11, 12, 9, 13, 11, 7, 12, 3, 15, 8, 6, 10, 8, 11, 9, 13, 13, 9, 13, 5, 8, 10, 20, 11, 12, 13, 11, 10, 17, 7, 4, 15, 6, 11, 5, 9, 5, 7, 11, 9, 6, 15, 8, 10, 6, 9, 10, 11, 9, 8, 8, 14, 13, 10, 6, 8, 17, 11, 8, 5, 7, 11, 7, 11, 14, 11, 10, 12, 19, 12, 7, 15, 3, 13, 6, 10, 6, 11, 8, 5, 11, 10, 5, 15, 6, 17, 5, 11, 8, 5, 13, 5, 7, 7, 8, 6, 13, 7, 13, 9, 14, 6, 10, 7, 10, 10, 13, 12, 16, 9, 20, 13, 8, 10, 6, 3, 13, 10, 8, 13, 11, 12, 9, 13, 9, 6, 9, 10, 10, 9, 5, 7, 14, 7, 8, 7, 9, 17, 10, 11, 4, 8, 5, 10, 9, 18, 11, 12, 13, 8, 9, 15, 9, 6, 12, 6, 14, 9, 10, 9, 10, 9, 11, 13, 6, 5, 6, 5, 12, 11, 9, 8, 10, 8, 12, 5, 10, 24, 14, 15, 14, 9, 7, 15, 13, 16, 5, 7, 7, 7, 5, 3, 9, 15, 7, 13, 5, 8, 7, 11, 8, 8, 9, 9, 18, 5, 8, 10, 13, 10, 8, 13, 8, 5, 12, 9, 8, 5, 8, 9, 9, 13, 6, 10, 7, 12, 17, 9, 11, 10, 12, 18, 11, 5, 7, 9, 5, 14, 11, 10, 8, 7, 13, 6, 15, 12, 5, 5, 6, 11, 12, 12, 7, 12, 9, 3, 4, 10, 13, 9, 10, 6, 10, 7, 11, 8, 8, 10, 4, 14, 16, 6, 12, 10, 21, 6, 10, 7, 11, 10, 11, 10, 14, 8, 5, 12, 12, 17, 19, 14, 6, 24, 21, 16, 6, 8, 10, 11, 7, 11, 10, 19, 12, 8, 17, 16, 8, 12, 12, 5, 10, 8, 15, 9, 11, 16, 10, 7, 8, 9, 6, 5, 11, 9, 9, 17, 14, 7, 5, 5, 8, 34, 5, 6, 11, 6, 15, 6, 7, 16, 6, 12, 8, 7, 8, 8, 3, 13, 17, 6, 7, 7, 13, 10, 5, 9, 7, 11, 5, 16, 13, 5, 16, 3, 10, 14, 11, 6, 12, 5, 10, 9, 10, 11, 7, 8, 10, 20, 8, 15, 13, 9, 6, 6, 5, 10, 12, 9, 19, 15, 14, 11, 10, 10, 10, 9, 14, 7, 9, 13, 13, 12, 14, 12, 8, 12, 9, 12, 9, 9, 7, 6, 6, 10, 5, 11, 7, 6, 7, 5, 10, 11, 13, 5, 11, 23, 8, 12, 10, 28, 5, 7, 5, 17, 11, 10, 13, 7, 12, 9, 7, 10, 9, 8, 6, 7, 9, 23, 8, 5, 6, 14, 21, 8, 15, 5, 11, 10, 14, 10, 17, 8, 10, 7, 8, 14, 7, 8, 17, 5, 26, 5, 6, 5, 6, 11, 14, 14, 16, 19, 9, 9, 6, 5, 15, 8, 6, 11, 12, 10, 10, 12, 25, 9, 7, 11, 16, 8, 5, 8, 14, 10, 5, 10, 12, 14, 9, 9, 8, 5, 9, 12, 8, 6, 7, 14, 10, 11, 11, 6, 14, 14, 11, 16, 7, 4, 10, 7, 19, 10, 11, 16, 16, 14, 9, 7, 16, 7, 9, 14, 12, 14, 8, 8, 7, 9, 13, 12, 9, 7, 17, 9, 5, 8, 9, 10, 15, 7, 7, 7, 15, 7, 12, 13, 14, 6, 10, 10, 14, 14, 20, 16, 11, 9, 9, 14, 7, 7, 6, 6, 11, 12, 14, 11, 4, 14, 8, 7, 5, 13, 14, 7, 11, 3, 7, 5, 10, 9, 5, 9, 14, 9, 12, 5, 17, 7, 18, 13, 10, 7, 7, 11, 11, 6, 8, 6, 15, 11, 8, 8, 12, 7, 8, 9, 14, 12, 11, 5, 9, 10, 8, 7, 15, 10, 10, 8, 11, 11, 10, 10, 17, 7, 12, 6, 11, 8, 8, 10, 8, 7, 14, 16, 6, 10, 6, 17, 8, 14, 6, 17, 9, 15, 10, 14, 7, 9, 7, 14, 11, 16, 12, 10, 6, 12, 9, 12, 8, 6, 14, 7, 12, 6, 12, 8, 6, 6, 5, 6, 12, 7, 6, 10, 7, 9, 9, 15, 10, 9, 5, 9, 11, 8, 3, 5, 9, 5, 5, 11, 8, 10, 5, 16, 12, 8, 8, 10, 10, 5, 6, 6, 10, 10, 16, 9, 6, 7, 10, 4, 17]\n"
     ]
    }
   ],
   "source": [
    "user_aux_size = [len(train_t[i]) for i in range(len(train_t))]\n",
    "print(user_aux_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation  Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "n: the number of users\n",
    "m: the number of YouTubers\n",
    "k: latent dims\n",
    "l: feature dims\n",
    "\"\"\"\n",
    "n = 1489 \n",
    "m = 88  \n",
    "k = 128\n",
    "l = 64\n",
    "\n",
    "user = tf.placeholder(tf.int32,shape=(1,))\n",
    "i = tf.placeholder(tf.int32, shape=(1,))\n",
    "j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "#auxliary \n",
    "xf = tf.placeholder(tf.float32, shape=(None,l))\n",
    "l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "r = tf.placeholder(tf.float32,shape=(None,))\n",
    "\n",
    "\n",
    "image_i = tf.placeholder(tf.float32, shape=(1,l))\n",
    "image_j = tf.placeholder(tf.float32, shape=(1,l))\n",
    "\n",
    "with tf.variable_scope(\"item_level\"):\n",
    "    user_latent = tf.get_variable(\"user_latent\", [n, k],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    item_latent = tf.get_variable(\"item_latent\", [m, k],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3)) \n",
    "    aux_item = tf.get_variable(\"aux_item\", [m, k],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    W1 = tf.get_variable(\"W1\", [n, k],\n",
    "                                      initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wu = tf.get_variable(\"Wu\", [k,k],\n",
    "                                      initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wy = tf.get_variable(\"Wy\", [m,k,k],\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wa = tf.get_variable(\"Wa\", [k,k],\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wv = tf.get_variable(\"Wv\", [k,l],\n",
    "                                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    \n",
    "\n",
    "    aux_new = tf.get_variable(\"aux_new\", [1,k], initializer=tf.constant_initializer(0.0))\n",
    "    ########## Error part, how to get auxisize dynamically\n",
    "    ####aux_size= tf.get_variable(name='aux_size', initializer=l_id.get_shape().as_list()[-1])\n",
    "    \n",
    "with tf.variable_scope('feature_level'):\n",
    "    Beta = tf.get_variable(\"beta\", [n,l],\n",
    "                             # initializer=tf.contrib.layers.xavier_initializer())\n",
    "                                     initializer=tf.random_normal_initializer(0.00001,0.000001,seed=10))\n",
    "\n",
    "#lookup the latent factors by user and id\n",
    "u = tf.nn.embedding_lookup(user_latent, user) #(1*k) user latent factor\n",
    "vi = tf.nn.embedding_lookup(item_latent, i) \n",
    "vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "w1 = tf.nn.embedding_lookup(W1, user) #(1*k)\n",
    "wu = Wu\n",
    "#wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user)) #(k*k)\n",
    "wy = tf.squeeze(tf.nn.embedding_lookup(Wy, i)) #(k*k)\n",
    "wa = Wa\n",
    "#wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user)) #(k*k)\n",
    "wv = Wv\n",
    "#wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user)) #(k,l)\n",
    "\n",
    "beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-40b4af78ef7a>:77: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "a_list=tf.Variable([])\n",
    "q = tf.constant(0)\n",
    "def att_cond(q,a_list):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "def att_body(q,a_list):\n",
    "    xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "    \n",
    "    a_list = tf.concat([a_list,[(tf.matmul( w1, tf.nn.relu( tf.matmul(wu, u, transpose_b=True) +\n",
    "        tf.matmul(wy, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "        tf.matmul(wa, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "        tf.matmul(wv, xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "    q += 1\n",
    "    return q,  a_list\n",
    "\n",
    "_, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "test = tf.matmul( w1, tf.nn.relu( tf.matmul(wu, u, transpose_b=True) +\n",
    "        tf.matmul(wy, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[0]),0), transpose_b=True) +\n",
    "        tf.matmul(wa, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[0]),0), transpose_b=True) +\n",
    "        tf.matmul(wv, tf.expand_dims(xf[0],0), transpose_b=True)))\n",
    "\"\"\"\n",
    "for q in range(3): #l_id YouTuber  \n",
    "    xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "    a_list.append((tf.matmul( w1, tf.nn.relu( tf.matmul(wu, u, transpose_b=True) +\n",
    "        tf.matmul(wy, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "        tf.matmul(wa, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "        tf.matmul(wv, xfi, transpose_b=True)))[0][0])*r[q])\n",
    "\"\"\"\n",
    "a_list_soft=tf.nn.softmax(a_list)\n",
    "\n",
    "\n",
    "aux_np = tf.expand_dims(tf.zeros(128),0) #dimension (1,32)\n",
    "q = tf.constant(0)\n",
    "def sum_att_cond(q,aux_np):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def sum_att_body(q,aux_np):\n",
    "    #aux_np+=a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)\n",
    "    aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)])  # [[7, 16], [10, 25]]\n",
    "    q += 1\n",
    "    return q, aux_np\n",
    "\n",
    "_,aux_np = tf.while_loop(sum_att_cond,sum_att_body,[q,aux_np])\n",
    "\n",
    "\"\"\"\n",
    "for q in range(3): #qauxliary item\n",
    "    aux_np+=a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "aux_np+=u #user_latent factor + sum (alpha*auxilary)\n",
    "aux_new=tf.assign(aux_new,aux_np) #aux_new  aux_np\n",
    "\n",
    "#\n",
    "xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,image_i, transpose_b=True)\n",
    "xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,image_j, transpose_b=True)\n",
    "\n",
    "xuij = xui- xuj\n",
    "\n",
    "l2_norm = tf.add_n([\n",
    "            0.001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "            0.001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "            0.001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "  \n",
    "            0.001 * tf.reduce_sum(tf.multiply(w1, w1)),\n",
    "            0.001 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "            0.001 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "            0.001 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "            0.001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "            \n",
    "            0.1 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "            \n",
    "          ])\n",
    "\n",
    "loss = l2_norm -tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "auc = tf.reduce_mean(tf.to_float(xuij > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.38206159]]\n",
      "train_auc:------------------- 0.9478372093023256\n",
      "time: 1437.8446865081787  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.28402699]]\n",
      "train_auc:------------------- 0.9625382059800665\n",
      "time: 2874.8923552036285  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.27727886]]\n",
      "train_auc:------------------- 0.9660332225913622\n",
      "time: 4305.701296329498  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.27628198]]\n",
      "train_auc:------------------- 0.9675747508305648\n",
      "time: 5737.417177200317  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.27594401]]\n",
      "train_auc:------------------- 0.967843853820598\n",
      "time: 7167.784746646881  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.27562736]]\n",
      "train_auc:------------------- 0.9680797342192691\n",
      "time: 8600.809064865112  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.27545852]]\n",
      "train_auc:------------------- 0.9685448504983388\n",
      "time: 10033.134835243225  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.27549294]]\n",
      "train_auc:------------------- 0.9681926910299004\n",
      "time: 11464.157730102539  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.27507872]]\n",
      "train_auc:------------------- 0.9688637873754152\n",
      "time: 12896.273918867111  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.2751766]]\n",
      "train_auc:------------------- 0.968843853820598\n",
      "time: 14326.048789739609  sec\n",
      "Total cost  14326.064411878586  sec\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "loss_acc_list = []\n",
    "t0=time.time()\n",
    "\n",
    "#use_true=init_list_of_objects(136)\n",
    "#use_test=init_list_of_objects(136)\n",
    "\n",
    "train_pair_t=[] #positive feedback\n",
    "train_pair_f=[] #negative feedback\n",
    "train_yes_id=[] \n",
    "for q in range(10):\n",
    "    print('Iteraction:',q)\n",
    "    train_auc=0\n",
    "    total_loss=0\n",
    "    xuij_auc=0\n",
    "    length = 0\n",
    "    for z in range(1489):\n",
    "        \"\"\"\n",
    "        yes YouTuber feature (for auxilary)\n",
    "        yesr userYouTuber(user_category  YouTuber_category)\n",
    "        r_3 user YouTuber(max)\n",
    "        \"\"\"\n",
    "        yes=[]\n",
    "        yesr=[]\n",
    "        r_3=np.zeros(len(train_t[z])) \n",
    "        \n",
    "        #3\n",
    "        sample=random.sample(train_t[z],len(train_t[z])) #3sample true's YouTuber\n",
    "        train_yes_id.append(sample) #sample\n",
    "        \n",
    "        for k in range(len(sample)):\n",
    "            yes.append(image_2048[sample[k]])\n",
    "            yesr.append(YouTuber_category[sample[k]]*user_category_norm[z])\n",
    "            #print('YouTuber_category ', YouTuber_category[sample[k]])\n",
    "            #print('User_category ',user_category_norm[z])\n",
    "        for k in range(len(sample)):\n",
    "            r_3[k]=max(yesr[k])\n",
    "        #print('r_3:',r_3)\n",
    "        \n",
    "        yes=np.array(yes)\n",
    "        #print('user shape should be ',np.array([z]).shape)\n",
    "        #print('xf shape should be ',yes.shape)\n",
    "        #print('r shape should be ',np.array(r_3).shape)\n",
    "        #print('l_id shape should be ',np.array(sample).shape)\n",
    "        \n",
    "        #not_used_list = list(set(train_t[z]).difference(set(sample)))\n",
    "        \n",
    "        train_t_sample = random.sample(train_t[z],len(train_t[z]))\n",
    "        #print('number of positive feedback', len(train_t[z]))\n",
    "        for ta in train_t_sample:\n",
    "            #ta=random.choice(train_t[z]) #ta is true positve photo\n",
    "            train_pair_t.append(ta)\n",
    "            image_1=np.expand_dims(image_2048[ta],0) #(1,2048)\n",
    "            #print('Image_1 shape ',image_1.shape)\n",
    "            train_f_sample = random.sample(train_f[z],20)\n",
    "            for b in train_f_sample:\n",
    "                #print('likes:',ta,';Not likes:',b)\n",
    "                #b=random.choice(train_f[z])  #b is no feedback photo\n",
    "                train_pair_f.append(b)\n",
    "                image_2=np.expand_dims(image_2048[b],0) #(1,2048)\n",
    "                #print('Image_2 shape',image_2.shape)\n",
    "            \n",
    "                #use_test[z].append(b)\n",
    "                _a_list,r3,_auc, _loss,_=sess.run([a_list,a_list_soft,auc,loss,train_op], feed_dict={user: [z],\n",
    "                                        i: [ta], j: [b], xf: yes , l_id:sample, l_id_len:[len(sample)],r:r_3,\n",
    "                                        image_i:image_1,image_j:image_2})\n",
    "                #print(XUIJ)\n",
    "                #print('loss=',_loss)\n",
    "                #print('auc=',_auc)\n",
    "                #print(z,ta,b)\n",
    "                #print('alpha list after softmax:',r3)\n",
    "                #print('alpha list before softmax:',_a_list)\n",
    "                train_auc+=_auc\n",
    "                total_loss+=_loss\n",
    "                length += 1\n",
    "            #now1+=1\n",
    "    \n",
    "    #print('mine:',xuij_auc/136)    \n",
    "    #print('a_list_soft:',r3)\n",
    "    print(\"total_loss:-----------------\", total_loss/length)\n",
    "    print(\"train_auc:-------------------\", train_auc/length)\n",
    "    loss_acc_list.append([total_loss/length,train_auc/length,time.time()-t0])\n",
    "    print('time:',time.time()-t0,' sec')\n",
    "print('Total cost ',time.time()-t0,' sec')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "loss= [[0.38206159]]\n",
      "acc= 0.9478372093023256\n",
      "time= 1437.8446865081787\n",
      "Iteration: 1\n",
      "loss= [[0.28402699]]\n",
      "acc= 0.9625382059800665\n",
      "time= 2874.8923552036285\n",
      "Iteration: 2\n",
      "loss= [[0.27727886]]\n",
      "acc= 0.9660332225913622\n",
      "time= 4305.701296329498\n",
      "Iteration: 3\n",
      "loss= [[0.27628198]]\n",
      "acc= 0.9675747508305648\n",
      "time= 5737.417177200317\n",
      "Iteration: 4\n",
      "loss= [[0.27594401]]\n",
      "acc= 0.967843853820598\n",
      "time= 7167.784746646881\n",
      "Iteration: 5\n",
      "loss= [[0.27562736]]\n",
      "acc= 0.9680797342192691\n",
      "time= 8600.809064865112\n",
      "Iteration: 6\n",
      "loss= [[0.27545852]]\n",
      "acc= 0.9685448504983388\n",
      "time= 10033.134835243225\n",
      "Iteration: 7\n",
      "loss= [[0.27549294]]\n",
      "acc= 0.9681926910299004\n",
      "time= 11464.157730102539\n",
      "Iteration: 8\n",
      "loss= [[0.27507872]]\n",
      "acc= 0.9688637873754152\n",
      "time= 12896.273918867111\n",
      "Iteration: 9\n",
      "loss= [[0.2751766]]\n",
      "acc= 0.968843853820598\n",
      "time= 14326.048789739609\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(loss_acc_list)):\n",
    "    print('Iteration:',i)\n",
    "    print('loss=',loss_acc_list[i][0])\n",
    "    print('acc=',loss_acc_list[i][1])\n",
    "    print('time=',loss_acc_list[i][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent factor and Each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, Y, A, A1, Au, Ay, Aa, Av,B =sess.run([user_latent, item_latent, aux_item, W1, Wu, Wy, Wa, Wv,Beta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User latent shape:  (1489, 128)\n",
      "photo latent shape:  (88, 128)\n",
      "Auxilary latent shape:  (88, 128)\n",
      "W1 weight shape:  (1489, 128)\n",
      "Wu weight shape: (128, 128)\n",
      "Wy weight shape: (88, 128, 128)\n",
      "Wa weight shape: (128, 128)\n",
      "Wv weight shape: (128, 64)\n",
      "Beta shape: (1489, 64)\n"
     ]
    }
   ],
   "source": [
    "print('User latent shape: ',U.shape)\n",
    "print('photo latent shape: ', Y.shape)\n",
    "print('Auxilary latent shape: ',A.shape)\n",
    "print('W1 weight shape: ',A1.shape)\n",
    "print('Wu weight shape:',Au.shape)\n",
    "print('Wy weight shape:', Ay.shape)\n",
    "print('Wa weight shape:',Aa.shape)\n",
    "print('Wv weight shape:',Av.shape)\n",
    "print('Beta shape:',B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 200\n",
      "softmax alpha-------------- [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "1 1086\n",
      "softmax alpha-------------- [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "2 664\n",
      "softmax alpha-------------- [0.33333333 0.33333333 0.33333333]\n",
      "3 996\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "4 621\n",
      "softmax alpha-------------- [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "5 1127\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "6 768\n",
      "softmax alpha-------------- [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "7 897\n",
      "softmax alpha-------------- [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "8 16\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "9 353\n",
      "softmax alpha-------------- [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "10 543\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "11 578\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "12 1487\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "13 1136\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "14 222\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "15 516\n",
      "softmax alpha-------------- [0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "16 115\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "17 1261\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "18 690\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "19 1187\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "20 549\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "21 349\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "22 434\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "23 39\n",
      "softmax alpha-------------- [0.33333333 0.33333333 0.33333333]\n",
      "24 563\n",
      "softmax alpha-------------- [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "25 393\n",
      "softmax alpha-------------- [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "26 564\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "27 403\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "28 1419\n",
      "softmax alpha-------------- [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "29 1079\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "30 1123\n",
      "softmax alpha-------------- [0.33333334 0.33333333 0.33333333]\n",
      "31 1371\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "32 559\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "33 959\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "34 972\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "35 1459\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "36 356\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "37 122\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "38 905\n",
      "softmax alpha-------------- [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "39 443\n",
      "softmax alpha-------------- [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "40 109\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "41 1039\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "42 580\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "43 1171\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "44 435\n",
      "softmax alpha-------------- [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "45 900\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "46 588\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "47 1137\n",
      "softmax alpha-------------- [0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "48 210\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "49 1478\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "50 1285\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "51 373\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "52 58\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "53 1334\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "54 593\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "55 987\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "56 276\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "57 634\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "58 567\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "59 331\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "60 1016\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "61 1483\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "62 727\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "63 954\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "64 1076\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "65 1485\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "66 463\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "67 21\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "68 505\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "69 1442\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "70 1106\n",
      "softmax alpha-------------- [0.33333333 0.33333333 0.33333333]\n",
      "71 1028\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "72 958\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "73 1030\n",
      "softmax alpha-------------- [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "74 78\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "75 1298\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "76 605\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 749\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "78 82\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "79 475\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "80 975\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "81 354\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "82 271\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "83 1170\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "84 300\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "85 357\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "86 875\n",
      "softmax alpha-------------- [0.33333333 0.33333333 0.33333333]\n",
      "87 1325\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "88 415\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "89 1463\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "90 928\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "91 76\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "92 1219\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "93 767\n",
      "softmax alpha-------------- [0.33333333 0.33333333 0.33333333]\n",
      "94 1125\n",
      "softmax alpha-------------- [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "95 798\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "96 1051\n",
      "softmax alpha-------------- [0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667\n",
      " 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667\n",
      " 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667\n",
      " 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667]\n",
      "97 1058\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "98 862\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "99 412\n",
      "softmax alpha-------------- [0.33333333 0.33333333 0.33333333]\n",
      "100 1462\n",
      "softmax alpha-------------- [0.33333333 0.33333333 0.33333333]\n",
      "101 93\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "102 1318\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "103 1114\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "104 820\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "105 703\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "106 599\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "107 279\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "108 718\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "109 1465\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "110 86\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "111 1337\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "112 1381\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "113 1149\n",
      "softmax alpha-------------- [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "114 577\n",
      "softmax alpha-------------- [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "115 1059\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "116 941\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "117 63\n",
      "softmax alpha-------------- [0.33333333 0.33333333 0.33333333]\n",
      "118 1242\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "119 1297\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "120 990\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "121 688\n",
      "softmax alpha-------------- [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "122 654\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "123 636\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "124 1082\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "125 722\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "126 986\n",
      "softmax alpha-------------- [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "127 1353\n",
      "softmax alpha-------------- [0.33333333 0.33333333 0.33333333]\n",
      "128 1407\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "129 907\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "130 1015\n",
      "softmax alpha-------------- [0.33333333 0.33333333 0.33333333]\n",
      "131 790\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "132 709\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "133 401\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "134 663\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "135 1344\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "136 1138\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "137 149\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "138 153\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "139 951\n",
      "softmax alpha-------------- [0.33333333 0.33333333 0.33333333]\n",
      "140 786\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "141 301\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "142 310\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "143 949\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "144 289\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "145 851\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "146 1372\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "147 965\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "148 832\n",
      "softmax alpha-------------- [0.33333333 0.33333334 0.33333333]\n",
      "149 542\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "[-1.28518535 -1.42958905 -1.44349596  0.64587312 -1.42611684 -1.4565458\n",
      " -1.31664061  0.22774105  2.04544175 -1.37288459  0.29655305  1.54046664\n",
      " -1.52083246 -1.45039673  0.70162166 -1.41985782 -1.33712127  0.84463127\n",
      " -0.99865975 -1.29593139 -1.39023094 -1.26596257 -0.97236702 -1.3200053\n",
      "  1.62201902  0.07379399 -1.16381495 -1.15426773  1.84667575  0.66933441\n",
      " -1.26536579 -1.25676526 -1.01329743 -1.06114982 -1.30504025 -1.41040356\n",
      " -1.36248138 -1.25395728 -0.4480392  -1.46543637  1.03440339  1.37702545\n",
      " -1.41235719  1.8150036  -1.03592993 -0.42746201 -1.39040213 -1.35594588\n",
      " -1.27726593 -0.40531763 -1.31969109 -1.29712075 -1.42407975 -1.35481732\n",
      "  0.94448978 -1.34702584 -1.22719881  0.19570895 -1.29045211 -1.46662992\n",
      " -0.59135541 -1.30371853 -1.28547759  1.67957677 -1.40240795 -1.30331813\n",
      " -1.3320594   1.41164037 -1.30519235 -1.37601157  0.96242636 -0.22298307\n",
      " -1.50758485 -1.15738849  0.54423877 -0.44248253  0.03219538 -1.364646\n",
      " -0.7776474   2.1473496  -1.16517515 -1.30756974 -0.14655548 -1.25545097\n",
      " -0.99823409 -1.44936909 -1.3126029  -1.32772153]\n"
     ]
    }
   ],
   "source": [
    "result=np.zeros((test_amount,88))\n",
    "RS=np.zeros((test_amount,88))\n",
    "#test_idx --> Test  index\n",
    "\n",
    "test_yes_id=[]\n",
    "for s in range(test_amount):\n",
    "    print(s,test_idx[s])\n",
    "\n",
    "    yes=[]\n",
    "    sample=random.sample(train_t[test_idx[s]],len(train_t[test_idx[s]])) #training part positive feedback YouTuber Auxilary\n",
    "    #sample=result_yes_id[now]\n",
    "    test_yes_id.append(sample)\n",
    "    alpha=np.zeros([len(sample)])\n",
    "    \n",
    "    for a in range(len(sample)):\n",
    "        r =np.max(YouTuber_category[sample[a]]*user_category_norm[test_idx[s]]) #sample a category vec *user_category vec\n",
    "        #print(test_idx[s])\n",
    "        #print(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0)))\n",
    "        alpha[a]=np.dot(A1[test_idx[s]],(relu(np.dot(Au,np.expand_dims(U[test_idx[s]],0).T)+np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T)+np.dot(Aa,\n",
    "                            np.expand_dims(A[sample[a]],0).T)+ np.dot(Av,np.expand_dims(image_2048[sample[a]],0).T))))*r\n",
    "    mul=np.zeros((1,128))\n",
    "    #print('alpha------------',alpha)\n",
    "    print('softmax alpha--------------',softmax(alpha))\n",
    "    for i in range(len(sample)):\n",
    "        mul+=softmax(alpha)[i]*A[sample[i]] #attention alpha*Ai part \n",
    "    new_mul=mul+U[test_idx[s]]  #(U+auxilary)\n",
    "    for k in range(88):\n",
    "        result[s][k]=np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "        RS[s][k] = np.dot(new_mul,Y[k].T)+np.dot(B[test_idx[s]], image_2048[k].T)\n",
    "print(RS[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "testRS = np.zeros((test_amount,10)) #shape 200*10\n",
    "\n",
    "#test_t true\n",
    "#test_f false\n",
    "        \n",
    "for z in range(test_amount):\n",
    "    user_id = test_idx[z]\n",
    "    #positive target YouTuber list\n",
    "    youtube_t = test_t[z] \n",
    "    #not target YouTuber list\n",
    "    youtube_f = test_f[z]\n",
    "    \n",
    "    #targetRS\n",
    "    for i in range(len(youtube_t)):\n",
    "        testRS[z][i] = RS[z][youtube_t[i]]\n",
    "    for i in range(len(youtube_f)):\n",
    "        testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.17715875, -1.63641072, -1.14775303, -1.32032336, -1.39914663,\n",
       "       -1.03070847, -0.7375161 , -1.16313134,  2.11365765, -1.05698223])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRS[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN(sortlist,n):\n",
    "    topList = []\n",
    "    for i in range(n):\n",
    "        topList.append(sortlist.index(max(sortlist)))\n",
    "        #print(max(sortlist))\n",
    "        #print(sortlist.index(max(sortlist)))\n",
    "        sortlist[sortlist.index(max(sortlist))] = -1000000000\n",
    "    return topList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.29576133  0.13842441 -1.19171072 -0.98273902 -0.56716647  0.62553193\n",
      "  0.60697788 -1.58840041  0.30059072  0.87074044]\n",
      "[-1.03981251 -1.13951592  1.05676419 -1.39606685  0.04803896 -1.04556422\n",
      "  0.85760066 -1.12561109 -0.79364071 -1.14592084]\n",
      "[-1.17715875 -1.63641072 -1.14775303 -1.32032336 -1.39914663 -1.03070847\n",
      " -0.7375161  -1.16313134  2.11365765 -1.05698223]\n",
      "[ 0.69172087 -0.58783957 -1.57980342  0.33066218 -0.09916076  0.30109066\n",
      " -1.51337096  0.97485396  0.00554863 -1.74285961]\n",
      "[ 0.28015029  0.56188546 -0.66813804 -0.50672555 -1.0133413  -1.24134201\n",
      "  0.23716289  0.66290689 -1.16766556  1.34945722]\n",
      "[-1.49841606  0.52706248  0.3889642  -1.74082382 -0.23461045 -1.58630319\n",
      " -1.58931621 -1.22265928 -1.50652543 -1.64004763]\n",
      "[ 0.27246899  0.58528437 -0.69474562 -0.1856025  -0.33279677 -0.0441427\n",
      "  0.59050958 -0.96739257  0.38027705  0.08341256]\n",
      "[-0.64909497 -0.7604828   1.62903174 -1.09279772 -1.05444281 -1.40618172\n",
      " -1.02335052 -1.20313162 -1.54150594 -1.14837105]\n",
      "[ 1.83228302  2.34540596 -1.41778596  0.78292118 -1.23785142 -1.26742378\n",
      " -1.20824316 -1.12099163  0.99073673  2.3614504 ]\n",
      "[ 0.54470254  0.41334205 -1.21523164  1.3330421  -0.32123395  0.21374027\n",
      " -1.25137353 -0.93296605 -1.35622691 -1.00964396]\n",
      "[-0.59348395 -0.06349056 -0.99617591  1.53842672  1.8543263   1.72790258\n",
      " -0.83336947  0.40852347 -0.88042724 -0.8465465 ]\n",
      "[ 0.9088807   1.75977105 -1.67774743  1.72423784  0.73533901  0.95793584\n",
      " -1.14554794 -1.27966943 -0.77725785 -0.59159153]\n",
      "[ 0.23666542 -0.09269557 -1.50719955  2.50471192  0.26812778  0.98273848\n",
      " -0.92168737 -1.72492278  2.34735133 -1.41365373]\n",
      "[-0.58370873 -1.3179569   1.10226182  0.46304332 -0.69414344 -0.05794547\n",
      " -0.03025136 -1.36704523 -1.46610864 -1.19029612]\n",
      "[-0.85669005 -0.26669561  1.6073762  -1.91895411  1.81129728 -1.97694758\n",
      "  1.17098935 -1.96775229 -1.85626752  0.30709455]\n",
      "[ 1.64000969  1.45792391 -1.59067277 -0.51787321  1.1924953  -1.38115255\n",
      "  0.70145499 -1.47812422 -0.89461778 -1.10395073]\n",
      "[ 0.92371744  1.12290432 -0.47204693 -0.67492726 -1.00370628 -0.50802594\n",
      " -0.88101686 -0.44097656  0.24787053 -0.31554015]\n",
      "[ 1.59392895  1.63917818  0.68954237 -1.0500919  -0.34536839 -0.96319068\n",
      "  0.2469854   1.31835812 -1.05730779 -1.10630373]\n",
      "[ 0.90338367  1.48034063 -0.61848114  0.60911255 -0.49136569 -1.44715607\n",
      " -0.84892399  0.25581897 -1.5634302  -0.46546638]\n",
      "[ 0.47712227  0.64997355 -0.48672883 -1.04423058 -0.80947345 -1.03875593\n",
      " -1.01266887 -0.86349109  0.62335383 -0.98795   ]\n",
      "[-0.91922398  1.57584552 -2.00698535 -2.02155404 -1.97604286  0.16312328\n",
      "  0.30863342 -1.83443852 -1.96799421 -1.39489589]\n",
      "[ 1.14756216  0.32918032 -0.05668591 -0.06579585 -1.34055533 -1.62406084\n",
      " -0.65593676  1.08292564 -0.72881372 -1.76537003]\n",
      "[ 0.27194234 -0.06116308 -0.94552602  0.29885904 -0.53460902 -0.54605308\n",
      " -0.6743036  -0.84228592 -0.66387059 -1.01068366]\n",
      "[-0.2791548  -1.30367615 -1.35936428 -1.12765458 -1.57020088 -1.42040301\n",
      "  0.70181219  0.73068525 -0.45437049 -0.21528975]\n",
      "[ 0.45598599  1.65693697 -1.65033636 -1.63801062 -1.11867484 -0.39708125\n",
      " -1.69809316 -0.0381528  -1.31299783 -1.63787663]\n",
      "[ 1.1638918  -1.05446153 -1.46667094 -0.71778921 -1.53380261 -1.40508429\n",
      " -1.70961908 -1.67904881 -0.09652012  0.4776285 ]\n",
      "[-0.29683258  2.48461348 -1.21663695 -1.02385688 -1.23848529 -1.29625438\n",
      "  1.82257659 -1.37347052 -1.25081267  2.33099524]\n",
      "[-0.22226459  2.22979779 -1.43322069 -1.4659964  -1.01219557 -1.4121445\n",
      "  2.29082712 -1.30482768 -1.34950669 -1.48467111]\n",
      "[ 1.50653173  0.8543895  -0.669393   -1.46709074 -0.42795718 -1.20166705\n",
      "  1.36561424 -1.2364852  -1.49860286  1.56534617]\n",
      "[-0.42602174  0.10255667  1.77126552 -1.27061663 -1.16854509 -0.97575372\n",
      " -0.65635653 -1.15084592 -0.95937436  1.28051917]\n",
      "[ 1.41025654 -1.13786172 -1.92721286 -1.84411218 -1.73323381  0.63044349\n",
      " -1.8423859  -1.7586413  -1.67038629  0.34634953]\n",
      "[ 1.7707304   0.89016113 -1.28357544 -1.25539048 -1.26280896 -1.45362048\n",
      " -1.25419573 -1.54949918 -0.09328108 -0.53471723]\n",
      "[-0.4516538   0.74643945 -0.70465875 -0.67378019 -0.91649392 -0.79558067\n",
      " -0.84874633 -0.86564021 -0.95625396 -1.14121754]\n",
      "[ 1.70086596  0.01252626 -1.68481403 -1.48796706 -0.96412097  0.89958053\n",
      " -1.82427516  0.43134791 -1.74945624 -1.29041047]\n",
      "[ 0.10309066 -0.82544666 -1.27447334 -1.66394176  1.41020729 -1.5088548\n",
      " -0.88335217 -1.16171404 -0.34068598 -1.78126486]\n",
      "[-0.17016918  1.35999859 -1.20530545 -1.24771442 -0.70837791 -1.48384905\n",
      "  0.12785405 -1.02272043 -0.67303946 -1.05195378]\n",
      "[-1.27432337 -1.60533976 -0.87660994  1.52314858 -1.40504245  0.91943166\n",
      "  1.15266611  0.49589798  1.36055493 -1.23325379]\n",
      "[-0.75852528 -0.18930897 -2.07044459 -1.88338982 -0.62770914 -0.84650419\n",
      " -2.10273297 -1.15719468 -1.91545957 -2.05369679]\n",
      "[ 0.21222036  0.29792623 -0.74075562 -1.33607658 -0.96433346 -0.38240605\n",
      " -0.60969883 -1.05125415 -1.9530602  -0.83396139]\n",
      "[ 0.74346653  0.41004136 -0.50099292 -1.06561957 -1.25984602 -1.10544537\n",
      " -1.3248726  -0.75989324 -0.49743729 -0.99084929]\n",
      "[-0.06906762  0.69200222 -0.24628735  0.98460837 -1.46762646 -1.28854843\n",
      " -1.42526256 -1.55894076 -1.15946288 -1.38023765]\n",
      "[ 1.26197733 -1.28843077  1.32576966 -1.19137273 -1.57579437 -1.63024454\n",
      " -1.7675469  -1.57272676 -1.58394579  0.68589941]\n",
      "[-0.21525562 -0.30430291 -1.46863682 -1.56208779  0.33528318 -1.52584612\n",
      " -1.01915495 -1.23733525  1.29523061 -1.23343537]\n",
      "[ 0.80769479  1.04320382 -0.60883935 -0.67599408 -0.6894336  -0.64343055\n",
      " -0.78324203 -0.85181246 -1.02948129  0.20812938]\n",
      "[-0.38147272  1.10336463 -0.78831155  0.77611739 -0.81495737  0.34902259\n",
      " -1.13595751 -1.17249604 -0.25951353 -0.8012326 ]\n",
      "[ 0.10580519  0.22873907 -0.72971092 -1.1853227  -1.5124404   0.27819258\n",
      " -1.06226429 -1.07743451 -1.06579189  0.36225172]\n",
      "[ 1.01681102  1.96288301  0.00922839 -1.7022051  -1.7494914   0.51777137\n",
      "  0.01404403  0.98546212 -1.70428022  0.07515862]\n",
      "[ 0.75119885  0.98623041 -1.40164394  0.66858459  1.03398128  0.53490734\n",
      " -0.83732482 -0.72492447 -1.08018181 -0.83760388]\n",
      "[-0.40002664 -0.53710468  0.12908161 -0.99660102 -0.94339024 -0.83576969\n",
      "  0.00910008 -0.2106338  -0.99427752 -1.41918742]\n",
      "[ 1.10178218  0.83113002 -1.36619562 -0.01842918 -1.49280469 -1.46030234\n",
      "  1.42175757 -1.4526337  -0.77827865 -1.07516258]\n",
      "[-1.42685111 -1.16023957 -1.32920292  0.94220028  0.82464164 -1.2889119\n",
      " -1.32025867  0.96432233 -1.1859434  -1.15369839]\n",
      "[-0.21139552 -1.35683641 -1.52832542 -1.49072106 -1.54263288 -1.29867878\n",
      " -1.52637374  1.81956954 -1.73035437 -1.2563253 ]\n",
      "[-0.03802282  0.92543838 -0.97101187 -1.19228925 -0.89063097 -0.90336883\n",
      " -0.78723908 -1.01998266 -1.04826744 -1.75509783]\n",
      "[ 1.65332159 -1.35834774  0.11474688 -1.18054115 -1.32168232 -1.35384656\n",
      "  0.57326887 -1.68818053 -0.55832154  0.44201524]\n",
      "[-0.79641677 -0.60574238 -0.7220677  -0.38638869  0.54128213  0.29725587\n",
      " -0.42337248  0.02301748 -0.52047815 -1.7001816 ]\n",
      "[ 0.54225833  1.6254136  -1.55075452 -1.34069587 -1.19156869 -0.93747985\n",
      " -1.31307399 -1.25657907 -1.14486549 -0.751165  ]\n",
      "[-0.49001066 -0.60711357 -0.08643389 -0.59356104 -1.7497001  -0.36072657\n",
      " -1.52305025 -1.58736111 -1.73655895 -1.65410185]\n",
      "[-0.72006582  0.36544275 -0.58718383  0.12806218 -0.90848274  0.97355924\n",
      "  1.10536729  0.30382274 -0.7963289  -0.96466013]\n",
      "[-0.57351341 -0.25082523 -0.423559    0.82373834  1.76409419 -0.78402867\n",
      " -0.53024277 -0.20799266 -0.47649425 -0.55568544]\n",
      "[-1.20739131 -0.72192629 -0.97658739  1.24473044 -1.31828746  1.17684562\n",
      " -0.8629187  -0.9310446  -1.13956157 -0.69748895]\n",
      "[ 0.00401889 -1.43615212  0.62140614 -1.27605362 -1.79682365 -1.48885569\n",
      " -1.63747058 -1.16834109 -1.7152746  -1.63721016]\n",
      "[ 1.27561733  0.77824187 -0.58917142  0.46029083 -0.37342786  0.01329648\n",
      " -0.6692579  -0.67753308 -0.14361255  0.32051038]\n",
      "[ 0.78266814  0.52170834 -1.72223621 -0.30202292  1.42828821 -0.22656229\n",
      " -1.79939522 -1.16917159 -1.84664479  1.04241863]\n",
      "[-0.15015596 -0.2570228  -0.67069017 -0.87972408  0.52054188 -1.13192212\n",
      "  0.51505337  0.71328011 -0.66948336 -0.56767221]\n",
      "[ 1.00369639  0.30971517 -0.59449221 -1.65108801 -1.57342187 -1.12843548\n",
      "  0.80486195 -1.54272095 -1.4030948  -0.27575287]\n",
      "[ 1.70122101  1.18783774 -1.51635289  0.92275209 -1.63310913 -1.44679214\n",
      " -0.40323462  2.02017871 -1.45366148 -1.49184095]\n",
      "[ 1.45409011  0.6979597  -1.50151727  0.1072791   0.49567463 -1.49525372\n",
      " -1.43694076 -1.3685466  -0.69555354 -1.74480705]\n",
      "[-0.38329978 -1.30455029 -1.15024776  0.9322922  -1.13220022 -0.97878758\n",
      " -1.31527316 -1.09034983 -1.24065901  0.81674726]\n",
      "[-0.83655289 -0.26281163  0.12768301 -0.70009896 -0.34399508 -0.47576146\n",
      " -0.34040489  0.17191707 -0.63759439  1.92927847]\n",
      "[-0.18748253  0.54342333 -1.39245084  1.0487072  -0.32246688 -1.62094965\n",
      " -1.41110347  1.4118718  -1.53506146 -1.31907035]\n",
      "[ 0.25911562  0.66140775 -0.62256065 -0.86233677 -0.48233088 -0.53867593\n",
      " -0.66033074 -0.71109195 -0.78455871 -0.70229872]\n",
      "[ 0.21782541  0.51394974 -0.73203426 -0.55943244 -0.5014627  -0.58248405\n",
      " -0.78587947 -0.51655569 -0.65284651 -0.61953938]\n",
      "[ 1.89146573  2.02833282 -1.37013838 -1.4521433  -1.42969837 -1.45081049\n",
      " -0.97008144 -1.45624293 -1.14150867 -1.15050043]\n",
      "[ 1.41126014  0.51894911  1.15221854 -0.64414163 -1.47495416 -1.54441421\n",
      " -1.2058595  -1.57937238  0.86230415 -1.50219551]\n",
      "[ 0.87678823 -0.18719405 -0.83868304  0.77006547 -0.76479783 -1.17608456\n",
      " -1.04466971  0.48362874 -1.55770571  1.49282918]\n",
      "[-0.84749039  1.40172136 -1.38826784 -1.57452966 -1.5819878  -1.36959701\n",
      " -1.18236748  1.66126496  0.06153788  0.05716013]\n",
      "[ 0.07921161  1.75292237 -1.35815977 -0.81973217 -1.430535    0.75449705\n",
      " -1.30288531 -0.25982708 -1.28570928 -1.49356393]\n",
      "[ 2.07280803  0.69967598 -1.47301396 -1.79737981 -1.68724828  0.71336506\n",
      " -1.74735455 -0.02788943 -1.78075739 -1.77430789]\n",
      "[ 0.96933501  0.20728621  0.96825034  0.90675008 -1.68361276 -1.57271056\n",
      " -1.68279115 -1.66061173 -1.60941839 -0.92406915]\n",
      "[ 0.25302521 -0.16316544 -1.11013651 -1.22044398 -1.13172707 -1.61062002\n",
      " -0.69686624 -0.1378181   0.01660515 -1.64341144]\n",
      "[ 1.73056262  1.53050069 -1.17050035 -1.28782726 -1.50219285 -1.43143664\n",
      " -1.6563499   0.63869249 -0.37963774 -0.58230431]\n",
      "[-0.6286266   0.51256917 -1.12889856 -0.43497652 -1.08710508 -0.56204397\n",
      "  0.76075043 -1.31631667 -1.26051915  1.0540589 ]\n",
      "[-1.37959234 -1.12345008  1.3603026   0.39456571 -1.16243158 -1.11090297\n",
      " -1.21050311 -1.12968173  0.64341985  0.799989  ]\n",
      "[-0.32855489 -1.10918934 -1.26457902  1.60894268 -1.22181056 -0.79565802\n",
      " -0.89542496 -0.95458262 -0.77633597 -0.97905993]\n",
      "[-0.20334156 -0.59545116 -0.66880659 -0.32624691 -0.32788206 -0.8087929\n",
      " -0.46552382  1.03593599 -0.8204025  -0.27145698]\n",
      "[ 0.9862952   0.33529014 -1.24990199 -1.45692222 -1.32149022 -1.6677302\n",
      " -1.49443472  0.70167764 -1.63384473 -1.34127071]\n",
      "[ 0.14021607  1.71865574 -1.17664899 -1.14214635 -1.24332015 -1.27646246\n",
      " -1.11478151 -1.1963665  -1.22747594 -1.39097179]\n",
      "[ 1.54813732  1.54933673  2.09503689 -1.31543023 -1.20482814 -0.44152129\n",
      " -0.24881808 -1.05646727  0.08534399 -1.38583602]\n",
      "[ 2.36683422  2.40151531  0.55919744  0.27511622 -0.52194285  1.09417489\n",
      " -0.52601015 -0.79493659 -0.54471646 -1.60431466]\n",
      "[ 0.7561263   0.83887694 -1.14191775  1.83214941 -0.328775   -0.93114053\n",
      " -1.21994096 -1.19617977 -0.88017151 -1.24478284]\n",
      "[ 1.29522348  0.79936605 -0.32681984 -1.46463465  0.97398166 -1.38793407\n",
      " -0.59880599  0.0724813  -1.75086633 -1.300838  ]\n",
      "[ 1.66466067  0.36968571  0.04117853  0.43240319  0.43033439 -1.27547644\n",
      " -0.83172482 -1.54188599 -1.0571277  -1.08982928]\n",
      "[ 2.0131552  -0.28997791 -1.17788244 -1.55187621  0.69739846  1.91856999\n",
      " -1.61054589  0.03676904 -1.47997186 -1.63457015]\n",
      "[ 0.07548847 -0.56387199  0.32436134 -0.94734479 -0.04679519 -0.01581802\n",
      " -0.004177   -0.03393071  0.4281747  -1.06132083]\n",
      "[ 1.57522872 -0.515051   -1.39141689 -0.24411383 -1.44443274 -1.57347362\n",
      " -1.17025556 -1.29574734 -1.2129346  -0.6001888 ]\n",
      "[ 1.75847396  1.49401413 -0.82642123 -0.86895292 -1.51545149 -1.5790473\n",
      " -1.69996658 -1.5052023  -1.51977524 -1.54535255]\n",
      "[ 1.24788499  1.02442043 -1.85719223 -1.35080826 -0.74387906 -1.83624846\n",
      " -1.39996399 -1.36421461 -1.38178952 -1.03269406]\n",
      "[-0.8878078  -1.74487712 -1.92422623 -0.62136139  0.03730619 -1.96174189\n",
      " -1.91440863 -2.02592066  0.44834284 -2.0133902 ]\n",
      "[ 1.61279235  1.25737582 -0.65025989 -1.79333894 -1.49413947 -1.62955597\n",
      " -1.51918187 -1.89573673 -1.28300001  1.42227427]\n",
      "[ 0.31018718  0.36284991 -1.42699128 -1.08816035  0.41825973 -1.45809666\n",
      " -1.65500203  1.84376771 -1.34596012 -1.46649941]\n",
      "[ 1.29943433  1.30369488 -1.65623659 -1.44860122  0.77306066  1.96528762\n",
      " -1.58989839 -1.77358869 -1.03858681 -0.44664363]\n",
      "[ 0.91962233  2.12508697 -1.87163065 -0.3195614  -2.08033138 -0.77208854\n",
      "  0.89130506 -0.04846903 -1.85264227 -1.92213054]\n",
      "[ 2.12725158  0.77571891  0.21389185  0.8614137  -1.06683887 -1.370194\n",
      " -1.24222114 -1.4483548  -1.10230338  2.10570405]\n",
      "[ 1.62380901  2.02762608 -1.55532053 -1.73330398 -1.56154447 -1.38420432\n",
      " -1.69591251 -1.67744947 -1.75888105 -1.74298481]\n",
      "[ 0.63135019  1.37202959 -1.61527363 -1.36770805 -1.40515393 -1.68451473\n",
      " -1.63968124 -1.44845529 -1.5614535  -0.12998956]\n",
      "[-0.75363941  0.08054407 -1.47929159 -1.49361294 -0.81101135 -1.53228832\n",
      " -0.16251005 -1.24099239 -1.44603687 -1.29166766]\n",
      "[ 0.06984905 -0.5063047  -1.04349703 -1.21135519 -0.52648746 -0.77348653\n",
      "  0.95764485 -0.11405186 -0.40531567  0.49613374]\n",
      "[-0.64392366 -0.33764889 -0.99499386 -0.49509862 -0.97823985  0.52412916\n",
      "  0.47387745  1.23913713 -0.67753691 -0.7694587 ]\n",
      "[ 0.94306076  0.51272523 -1.14364346 -0.84562645 -1.33203289 -0.92389264\n",
      " -1.26079591  0.5012531  -0.75117066  0.22508004]\n",
      "[-0.20510334 -1.11700344 -1.73557646 -1.15245865 -1.63681264 -1.77552817\n",
      " -1.38559092 -1.6697565  -1.05665285 -1.68393219]\n",
      "[ 1.23357691  2.0004623   0.39483952 -2.07335342  0.23562188 -0.61888919\n",
      " -1.64382462 -1.87742282 -2.14445359 -0.90112847]\n",
      "[-0.61678476 -0.21176223 -1.61883819 -1.49554183  1.33372412 -1.63420984\n",
      "  0.6824344  -1.36002426  0.43268586 -1.51511595]\n",
      "[-0.73323727  0.21778481 -0.45242128 -0.70073603 -0.93183493  1.63892798\n",
      " -0.61974321 -1.20760517  1.13958089  0.42651559]\n",
      "[-0.01761826  0.51815339 -1.07644078  0.0727796  -1.45541514  0.75406325\n",
      " -1.31661545 -1.38902157  1.5276187  -1.3382259 ]\n",
      "[-0.14190922  0.8418467  -0.68815782 -0.98983383 -0.83590426 -1.05638804\n",
      " -0.3749403  -1.44677457 -1.14083573  0.65775835]\n",
      "[ 0.81817395  1.90452362  0.84722232 -1.3128908  -1.36465726 -0.44940597\n",
      " -1.41624556  1.62328764 -1.48441074 -1.30677058]\n",
      "[ 0.06784065  0.296646   -1.44573225 -1.45505783 -0.99466179 -1.07293815\n",
      "  0.88715763 -1.35073158 -0.08541652  0.08169282]\n",
      "[ 2.62689563  0.77945258 -1.22499137  0.10089063 -1.15864742 -1.27494569\n",
      " -0.70131857 -1.07737661 -1.16428827 -0.47738911]\n",
      "[ 0.44360372  1.36549167 -1.34204374 -0.47390852 -1.26517206 -1.13481079\n",
      " -1.07689518 -0.99786167 -1.68328242 -1.33235504]\n",
      "[ 1.79296334  1.58709209  0.61072767 -1.1860101  -1.4557021  -1.12491734\n",
      " -1.09290099 -1.6307503  -1.20571357 -1.09811573]\n",
      "[ 1.56718152 -1.07015991 -1.44361375 -1.63619917 -0.31298474 -1.51196987\n",
      " -1.55066193 -1.30030062 -1.63916731 -0.80489907]\n",
      "[ 0.95217978  1.07254984 -1.19148236 -1.17351944 -1.52325064  0.80436614\n",
      " -1.41076343 -1.2694441  -1.17365438 -1.38497032]\n",
      "[ 0.58188523 -0.00907169 -0.10455839 -0.56986523 -1.27227962 -0.78691086\n",
      " -1.1048889  -1.20327855 -0.6064991  -1.16385993]\n",
      "[-0.58842994  0.21445897 -1.25752683 -0.66348365 -1.42302007 -0.97814029\n",
      " -1.27088666 -0.6908717   1.52643161  0.77263312]\n",
      "[-1.5862854  -0.57723061 -1.55047454 -0.5138307  -1.55890263 -1.55027273\n",
      "  0.95332895  0.28084706 -0.16666029 -1.384029  ]\n",
      "[ 0.57450455  0.35512962 -1.63640005  0.04143111 -1.3501933  -1.41533311\n",
      " -1.11309767 -1.5572481   0.93464915 -1.20726532]\n",
      "[-0.54653213  0.80157607 -0.48168283  1.29306401 -1.06524384  0.20104451\n",
      " -0.46345548  1.82211273 -0.86977543  1.3640231 ]\n",
      "[-0.98630126  0.18431279 -1.41331124 -1.26795018 -1.69919622 -1.46464017\n",
      " -0.95587509  1.11529861 -1.51426316  0.38700195]\n",
      "[ 0.8292363  -0.64802976 -0.95313649  0.12685493 -0.9623626  -1.35361057\n",
      "  0.5159319  -0.50996532 -0.91641846 -0.57511516]\n",
      "[ 1.17754017  1.65608994  0.06967734 -1.20231729 -1.17310999 -1.03673289\n",
      " -1.24193801 -1.74611002 -0.6684098   0.38197081]\n",
      "[ 0.79128601  0.62373657 -1.49453083 -1.03387124 -1.8317598   1.1671994\n",
      " -1.54696781 -1.08402219 -1.52340635 -1.54915501]\n",
      "[ 0.90599458  1.21087057 -1.21219739 -1.36827706  0.05018211 -0.99923988\n",
      " -0.42239756 -1.55000124 -1.22806621 -1.44325732]\n",
      "[-0.31605455  0.32787979 -0.7012791  -0.80181921 -1.01123075 -0.56619184\n",
      " -0.36440092 -0.79647738  0.79807452 -0.98103576]\n",
      "[-0.47600221  0.49018279 -0.41997462 -0.51190136 -0.86622959  0.04896119\n",
      "  0.5797265  -0.03893538 -0.81194807 -0.4952034 ]\n",
      "[-0.33931862  0.84664418 -0.90664959  0.04571644 -1.24522805  0.52975824\n",
      "  0.14686947  0.60735055 -1.60383954 -1.16020257]\n",
      "[ 1.96034512  2.63231887 -1.53289705 -1.58032603 -1.59358927  1.06613084\n",
      " -1.48704518  0.68673082  0.31200135 -0.10938925]\n",
      "[ 0.89770111  1.87333717 -1.08817117 -0.68560698 -0.89869108 -1.31710612\n",
      " -1.30366666 -1.42875193 -0.58087216 -1.15750089]\n",
      "[ 1.20946764  0.76835501 -1.98160067 -1.63910075 -0.1705306  -1.4868973\n",
      " -1.73102129 -1.76930784 -2.08881966 -1.74746826]\n",
      "[-0.26078251  0.060792   -1.31990101 -1.30808507 -1.4993191   1.35044142\n",
      " -1.33881615 -1.52012259 -0.38601721 -1.64776873]\n",
      "[-0.09936586  1.46638492 -0.83067714 -1.5963309  -1.93052093  0.14488207\n",
      " -1.73659247 -2.1948576  -2.03469055 -2.12634936]\n",
      "[ 0.70477701  0.12148703 -1.33493044 -0.43029607 -1.09991262 -0.62547638\n",
      " -1.00754514 -1.22614932 -1.2514459  -1.38471968]\n",
      "[ 1.43501138  0.68437512 -1.56539051 -1.52806787 -0.78804856 -1.62206394\n",
      " -1.52731268 -1.05129153 -1.37216156 -1.52894877]\n",
      "[ 0.07541106  0.45713121 -0.81988105 -1.17565514 -1.16555963  0.60086176\n",
      "  1.89497967  0.98530313 -1.31956648 -1.09798589]\n",
      "[-0.7291691  -0.34645029  1.18666747  1.25761959 -0.73210688  0.91573902\n",
      " -0.70912739 -0.49091365 -0.38827802 -0.66188511]\n",
      "[ 0.01733729  0.87209001 -1.28020239 -1.43935145 -1.09643763 -1.52481864\n",
      "  1.02976701 -1.32840805  2.0638738  -1.40835463]\n",
      "[-1.54837622  2.0898042  -0.00452705 -1.62708085  0.51228968 -0.85571586\n",
      " -1.46232123 -0.85241911 -1.86581163  0.8356583 ]\n",
      "[-0.12128254 -1.20465351 -0.71408922 -1.10501894 -1.021305   -1.23186874\n",
      " -0.10007789 -1.34816328 -1.22639561 -0.80455115]\n",
      "[-0.40277161 -1.32028116 -1.60319926 -0.97548622 -1.50165759  0.6224323\n",
      " -1.42128668 -1.45602877 -1.0785407  -1.60079722]\n",
      "[ 1.12334857  1.06147236 -0.29316094  0.31290324 -0.56113821 -0.29716035\n",
      " -0.04367781 -0.79589494 -0.52449742 -0.87916317]\n",
      "[ 2.1473496   0.96242636 -1.26536579 -0.4480392  -1.30371853 -1.35481732\n",
      " -1.22719881 -0.99865975  1.03440339 -1.30331813]\n"
     ]
    }
   ],
   "source": [
    "for row in testRS:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9]\n",
      "[2, 6]\n",
      "[8, 6]\n",
      "[7, 0]\n",
      "[9, 7]\n",
      "[1, 2]\n",
      "[6, 1]\n",
      "[2, 0]\n",
      "[9, 1]\n",
      "[3, 0]\n",
      "[4, 5]\n",
      "[1, 3]\n",
      "[3, 8]\n",
      "[2, 3]\n",
      "[4, 2]\n",
      "[0, 1]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[1, 8]\n",
      "[1, 6]\n",
      "[0, 7]\n",
      "[3, 0]\n",
      "[7, 6]\n",
      "[1, 0]\n",
      "[0, 9]\n",
      "[1, 9]\n",
      "[6, 1]\n",
      "[9, 0]\n",
      "[2, 9]\n",
      "[0, 5]\n",
      "[0, 1]\n",
      "[1, 0]\n",
      "[0, 5]\n",
      "[4, 0]\n",
      "[1, 6]\n",
      "[3, 8]\n",
      "[1, 4]\n",
      "[1, 0]\n",
      "[0, 1]\n",
      "[3, 1]\n",
      "[2, 0]\n",
      "[8, 4]\n",
      "[1, 0]\n",
      "[1, 3]\n",
      "[9, 5]\n",
      "[1, 0]\n",
      "[4, 1]\n",
      "[2, 6]\n",
      "[6, 0]\n",
      "[7, 3]\n",
      "[7, 0]\n",
      "[1, 0]\n",
      "[0, 6]\n",
      "[4, 5]\n",
      "[1, 0]\n",
      "[2, 5]\n",
      "[6, 5]\n",
      "[4, 3]\n",
      "[3, 5]\n",
      "[2, 0]\n",
      "[0, 1]\n",
      "[4, 9]\n",
      "[7, 4]\n",
      "[0, 6]\n",
      "[7, 0]\n",
      "[0, 1]\n",
      "[3, 9]\n",
      "[9, 7]\n",
      "[7, 3]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[0, 2]\n",
      "[9, 0]\n",
      "[7, 1]\n",
      "[1, 5]\n",
      "[0, 5]\n",
      "[0, 2]\n",
      "[0, 8]\n",
      "[0, 1]\n",
      "[9, 6]\n",
      "[2, 9]\n",
      "[3, 0]\n",
      "[7, 0]\n",
      "[0, 7]\n",
      "[1, 0]\n",
      "[2, 1]\n",
      "[1, 0]\n",
      "[3, 1]\n",
      "[0, 4]\n",
      "[0, 3]\n",
      "[0, 5]\n",
      "[8, 2]\n",
      "[0, 3]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[8, 4]\n",
      "[0, 9]\n",
      "[7, 4]\n",
      "[5, 1]\n",
      "[1, 0]\n",
      "[0, 9]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[1, 6]\n",
      "[6, 9]\n",
      "[7, 5]\n",
      "[0, 1]\n",
      "[0, 8]\n",
      "[1, 0]\n",
      "[4, 6]\n",
      "[5, 8]\n",
      "[8, 5]\n",
      "[1, 9]\n",
      "[1, 7]\n",
      "[6, 1]\n",
      "[0, 1]\n",
      "[1, 0]\n",
      "[0, 1]\n",
      "[0, 4]\n",
      "[1, 0]\n",
      "[0, 1]\n",
      "[8, 9]\n",
      "[6, 7]\n",
      "[8, 0]\n",
      "[7, 9]\n",
      "[7, 9]\n",
      "[0, 6]\n",
      "[1, 0]\n",
      "[5, 0]\n",
      "[1, 0]\n",
      "[8, 1]\n",
      "[6, 1]\n",
      "[1, 7]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[0, 1]\n",
      "[5, 1]\n",
      "[1, 5]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[6, 7]\n",
      "[3, 2]\n",
      "[8, 6]\n",
      "[1, 9]\n",
      "[6, 0]\n",
      "[5, 0]\n",
      "[0, 1]\n",
      "[0, 8]\n",
      "avg_accuarcy for count_0: 0.5\n"
     ]
    }
   ],
   "source": [
    "count_0_all = []\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),2)\n",
    "    count_0_all.append(top_0)\n",
    "    print(top_0)\n",
    "\n",
    "acc_0 = 0\n",
    "total = len(count_0_all)*len(count_0_all[0])\n",
    "#print(total) #(200*2)\n",
    "for i in range(len(count_0_all)):\n",
    "    for j in range(len(count_0_all[i])):\n",
    "        if count_0_all[i][j] < 2: #01 (target)\n",
    "            acc_0 += 1\n",
    "#print(acc_0)\n",
    "avg_acc = acc_0/total\n",
    "print('avg_accuarcy for count_0:',avg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[2]\n",
      "[8]\n",
      "[7]\n",
      "[9]\n",
      "[1]\n",
      "[6]\n",
      "[2]\n",
      "[9]\n",
      "[3]\n",
      "[4]\n",
      "[1]\n",
      "[3]\n",
      "[2]\n",
      "[4]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[3]\n",
      "[7]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[6]\n",
      "[9]\n",
      "[2]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[4]\n",
      "[1]\n",
      "[3]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[3]\n",
      "[2]\n",
      "[8]\n",
      "[1]\n",
      "[1]\n",
      "[9]\n",
      "[1]\n",
      "[4]\n",
      "[2]\n",
      "[6]\n",
      "[7]\n",
      "[7]\n",
      "[1]\n",
      "[0]\n",
      "[4]\n",
      "[1]\n",
      "[2]\n",
      "[6]\n",
      "[4]\n",
      "[3]\n",
      "[2]\n",
      "[0]\n",
      "[4]\n",
      "[7]\n",
      "[0]\n",
      "[7]\n",
      "[0]\n",
      "[3]\n",
      "[9]\n",
      "[7]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[9]\n",
      "[7]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[9]\n",
      "[2]\n",
      "[3]\n",
      "[7]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[1]\n",
      "[3]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[8]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[8]\n",
      "[0]\n",
      "[7]\n",
      "[5]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[6]\n",
      "[7]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[4]\n",
      "[5]\n",
      "[8]\n",
      "[1]\n",
      "[1]\n",
      "[6]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[8]\n",
      "[6]\n",
      "[8]\n",
      "[7]\n",
      "[7]\n",
      "[0]\n",
      "[1]\n",
      "[5]\n",
      "[1]\n",
      "[8]\n",
      "[6]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[5]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[6]\n",
      "[3]\n",
      "[8]\n",
      "[1]\n",
      "[6]\n",
      "[5]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "target = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),1)\n",
    "    count_0_all.append(top_0)\n",
    "    print(top_0)\n",
    "    if top_0[0] == 1 or top_0[0] == 0:\n",
    "        target += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.52 recall  0.26\n"
     ]
    }
   ],
   "source": [
    "top1_prec = target/len(testRS)\n",
    "top1_recall = target/(len(testRS)*2)\n",
    "print('prec ',top1_prec,'recall ',top1_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9]\n",
      "[2, 6]\n",
      "[8, 6]\n",
      "[7, 0]\n",
      "[9, 7]\n",
      "[1, 2]\n",
      "[6, 1]\n",
      "[2, 0]\n",
      "[9, 1]\n",
      "[3, 0]\n",
      "[4, 5]\n",
      "[1, 3]\n",
      "[3, 8]\n",
      "[2, 3]\n",
      "[4, 2]\n",
      "[0, 1]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[1, 8]\n",
      "[1, 6]\n",
      "[0, 7]\n",
      "[3, 0]\n",
      "[7, 6]\n",
      "[1, 0]\n",
      "[0, 9]\n",
      "[1, 9]\n",
      "[6, 1]\n",
      "[9, 0]\n",
      "[2, 9]\n",
      "[0, 5]\n",
      "[0, 1]\n",
      "[1, 0]\n",
      "[0, 5]\n",
      "[4, 0]\n",
      "[1, 6]\n",
      "[3, 8]\n",
      "[1, 4]\n",
      "[1, 0]\n",
      "[0, 1]\n",
      "[3, 1]\n",
      "[2, 0]\n",
      "[8, 4]\n",
      "[1, 0]\n",
      "[1, 3]\n",
      "[9, 5]\n",
      "[1, 0]\n",
      "[4, 1]\n",
      "[2, 6]\n",
      "[6, 0]\n",
      "[7, 3]\n",
      "[7, 0]\n",
      "[1, 0]\n",
      "[0, 6]\n",
      "[4, 5]\n",
      "[1, 0]\n",
      "[2, 5]\n",
      "[6, 5]\n",
      "[4, 3]\n",
      "[3, 5]\n",
      "[2, 0]\n",
      "[0, 1]\n",
      "[4, 9]\n",
      "[7, 4]\n",
      "[0, 6]\n",
      "[7, 0]\n",
      "[0, 1]\n",
      "[3, 9]\n",
      "[9, 7]\n",
      "[7, 3]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[0, 2]\n",
      "[9, 0]\n",
      "[7, 1]\n",
      "[1, 5]\n",
      "[0, 5]\n",
      "[0, 2]\n",
      "[0, 8]\n",
      "[0, 1]\n",
      "[9, 6]\n",
      "[2, 9]\n",
      "[3, 0]\n",
      "[7, 0]\n",
      "[0, 7]\n",
      "[1, 0]\n",
      "[2, 1]\n",
      "[1, 0]\n",
      "[3, 1]\n",
      "[0, 4]\n",
      "[0, 3]\n",
      "[0, 5]\n",
      "[8, 2]\n",
      "[0, 3]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[8, 4]\n",
      "[0, 9]\n",
      "[7, 4]\n",
      "[5, 1]\n",
      "[1, 0]\n",
      "[0, 9]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[1, 6]\n",
      "[6, 9]\n",
      "[7, 5]\n",
      "[0, 1]\n",
      "[0, 8]\n",
      "[1, 0]\n",
      "[4, 6]\n",
      "[5, 8]\n",
      "[8, 5]\n",
      "[1, 9]\n",
      "[1, 7]\n",
      "[6, 1]\n",
      "[0, 1]\n",
      "[1, 0]\n",
      "[0, 1]\n",
      "[0, 4]\n",
      "[1, 0]\n",
      "[0, 1]\n",
      "[8, 9]\n",
      "[6, 7]\n",
      "[8, 0]\n",
      "[7, 9]\n",
      "[7, 9]\n",
      "[0, 6]\n",
      "[1, 0]\n",
      "[5, 0]\n",
      "[1, 0]\n",
      "[8, 1]\n",
      "[6, 1]\n",
      "[1, 7]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[0, 1]\n",
      "[5, 1]\n",
      "[1, 5]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[6, 7]\n",
      "[3, 2]\n",
      "[8, 6]\n",
      "[1, 9]\n",
      "[6, 0]\n",
      "[5, 0]\n",
      "[0, 1]\n",
      "[0, 8]\n"
     ]
    }
   ],
   "source": [
    "target = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),2)\n",
    "    count_0_all.append(top_0)\n",
    "    print(top_0)\n",
    "    for j in range(len(top_0)):\n",
    "        if top_0[j] == 1 or top_0[j] == 0:\n",
    "            target += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.5 recall  0.5\n"
     ]
    }
   ],
   "source": [
    "top2_prec = target/(len(testRS)*2)\n",
    "top2_recall = target/(len(testRS)*2)\n",
    "print('prec ',top2_prec,'recall ',top2_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9, 5]\n",
      "[2, 6, 4]\n",
      "[8, 6, 5]\n",
      "[7, 0, 3]\n",
      "[9, 7, 1]\n",
      "[1, 2, 4]\n",
      "[6, 1, 8]\n",
      "[2, 0, 1]\n",
      "[9, 1, 0]\n",
      "[3, 0, 1]\n",
      "[4, 5, 3]\n",
      "[1, 3, 5]\n",
      "[3, 8, 5]\n",
      "[2, 3, 6]\n",
      "[4, 2, 6]\n",
      "[0, 1, 4]\n",
      "[1, 0, 8]\n",
      "[1, 0, 7]\n",
      "[1, 0, 3]\n",
      "[1, 8, 0]\n",
      "[1, 6, 5]\n",
      "[0, 7, 1]\n",
      "[3, 0, 1]\n",
      "[7, 6, 9]\n",
      "[1, 0, 7]\n",
      "[0, 9, 8]\n",
      "[1, 9, 6]\n",
      "[6, 1, 0]\n",
      "[9, 0, 6]\n",
      "[2, 9, 1]\n",
      "[0, 5, 9]\n",
      "[0, 1, 8]\n",
      "[1, 0, 3]\n",
      "[0, 5, 7]\n",
      "[4, 0, 8]\n",
      "[1, 6, 0]\n",
      "[3, 8, 6]\n",
      "[1, 4, 0]\n",
      "[1, 0, 5]\n",
      "[0, 1, 8]\n",
      "[3, 1, 0]\n",
      "[2, 0, 9]\n",
      "[8, 4, 0]\n",
      "[1, 0, 9]\n",
      "[1, 3, 5]\n",
      "[9, 5, 1]\n",
      "[1, 0, 7]\n",
      "[4, 1, 0]\n",
      "[2, 6, 7]\n",
      "[6, 0, 1]\n",
      "[7, 3, 4]\n",
      "[7, 0, 9]\n",
      "[1, 0, 6]\n",
      "[0, 6, 9]\n",
      "[4, 5, 7]\n",
      "[1, 0, 9]\n",
      "[2, 5, 0]\n",
      "[6, 5, 1]\n",
      "[4, 3, 7]\n",
      "[3, 5, 9]\n",
      "[2, 0, 7]\n",
      "[0, 1, 3]\n",
      "[4, 9, 0]\n",
      "[7, 4, 6]\n",
      "[0, 6, 1]\n",
      "[7, 0, 1]\n",
      "[0, 1, 4]\n",
      "[3, 9, 0]\n",
      "[9, 7, 2]\n",
      "[7, 3, 1]\n",
      "[1, 0, 4]\n",
      "[1, 0, 4]\n",
      "[1, 0, 6]\n",
      "[0, 2, 8]\n",
      "[9, 0, 3]\n",
      "[7, 1, 8]\n",
      "[1, 5, 0]\n",
      "[0, 5, 1]\n",
      "[0, 2, 3]\n",
      "[0, 8, 7]\n",
      "[0, 1, 7]\n",
      "[9, 6, 1]\n",
      "[2, 9, 8]\n",
      "[3, 0, 8]\n",
      "[7, 0, 9]\n",
      "[0, 7, 1]\n",
      "[1, 0, 6]\n",
      "[2, 1, 0]\n",
      "[1, 0, 5]\n",
      "[3, 1, 0]\n",
      "[0, 4, 1]\n",
      "[0, 3, 4]\n",
      "[0, 5, 4]\n",
      "[8, 2, 0]\n",
      "[0, 3, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 4]\n",
      "[8, 4, 3]\n",
      "[0, 9, 1]\n",
      "[7, 4, 1]\n",
      "[5, 1, 0]\n",
      "[1, 0, 6]\n",
      "[0, 9, 3]\n",
      "[1, 0, 5]\n",
      "[1, 0, 9]\n",
      "[1, 6, 0]\n",
      "[6, 9, 0]\n",
      "[7, 5, 6]\n",
      "[0, 1, 7]\n",
      "[0, 8, 1]\n",
      "[1, 0, 2]\n",
      "[4, 6, 8]\n",
      "[5, 8, 9]\n",
      "[8, 5, 1]\n",
      "[1, 9, 0]\n",
      "[1, 7, 2]\n",
      "[6, 1, 9]\n",
      "[0, 1, 3]\n",
      "[1, 0, 3]\n",
      "[0, 1, 2]\n",
      "[0, 4, 9]\n",
      "[1, 0, 5]\n",
      "[0, 1, 2]\n",
      "[8, 9, 1]\n",
      "[6, 7, 8]\n",
      "[8, 0, 1]\n",
      "[7, 9, 3]\n",
      "[7, 9, 1]\n",
      "[0, 6, 3]\n",
      "[1, 0, 9]\n",
      "[5, 0, 1]\n",
      "[1, 0, 4]\n",
      "[8, 1, 0]\n",
      "[6, 1, 5]\n",
      "[1, 7, 5]\n",
      "[1, 0, 5]\n",
      "[1, 0, 8]\n",
      "[0, 1, 4]\n",
      "[5, 1, 0]\n",
      "[1, 5, 0]\n",
      "[0, 1, 3]\n",
      "[0, 1, 4]\n",
      "[6, 7, 5]\n",
      "[3, 2, 5]\n",
      "[8, 6, 1]\n",
      "[1, 9, 4]\n",
      "[6, 0, 2]\n",
      "[5, 0, 3]\n",
      "[0, 1, 3]\n",
      "[0, 8, 1]\n"
     ]
    }
   ],
   "source": [
    "target = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),3)\n",
    "    count_0_all.append(top_0)\n",
    "    print(top_0)\n",
    "    for j in range(len(top_0)):\n",
    "        if top_0[j] == 1 or top_0[j] == 0:\n",
    "            target += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.44222222222222224 recall  0.6633333333333333\n"
     ]
    }
   ],
   "source": [
    "top3_prec = target/(len(testRS)*3)\n",
    "top3_recall = target/(len(testRS)*2)\n",
    "print('prec ',top3_prec,'recall ',top3_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
