{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing data positive feedback dynamic (20%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_following = np.load('../Data/npy/user_following_1489.npy')\n",
    "image_2048 = np.load('../Data/npy/Image_2048D.npy')\n",
    "user_category = np.load('../Data/npy/user_category_1489.npy')\n",
    "YouTuber_category = np.load('../Data/npy/YouTuber_category_0.7.npy')\n",
    "active_users = np.load('../Data/npy/active_userID_1489.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_following shape  (1489, 88)\n",
      "image_2048 shape  (88, 2048)\n",
      "user_category shape  (1489, 17)\n",
      "YouTuber_category shape  (88, 17)\n"
     ]
    }
   ],
   "source": [
    "print('user_following shape ',user_following.shape)\n",
    "print('image_2048 shape ',image_2048.shape)\n",
    "print('user_category shape ',user_category.shape)\n",
    "print('YouTuber_category shape ',YouTuber_category.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_category after normalized by max...\n",
      "user_category_norm shape  (1489, 17)\n"
     ]
    }
   ],
   "source": [
    "user_category_norm = np.zeros(user_category.shape)\n",
    "for i in range(len(user_category)):\n",
    "    user_category_norm[i] = user_category[i]/np.max(user_category[i])\n",
    "print('user_category after normalized by max...')\n",
    "print('user_category_norm shape ',user_category_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13, 15, 16, 24, 29, 37, 44], [3, 25, 67, 71, 74, 75, 82], [8, 11, 24, 28, 41, 63, 67, 79, 86], [8, 24, 28, 29, 63, 70, 79], [8, 24, 37, 63, 67, 70, 79], [8, 17, 24, 25, 31, 43, 63, 67, 70, 73, 74, 79], [3, 10, 11, 22, 40, 44, 47, 74, 76, 82], [8, 17, 21, 27, 28, 32, 33, 45, 49, 67, 75, 82, 84], [3, 25, 63, 74, 79], [3, 10, 11, 14, 25, 40, 45, 54, 60, 65, 67, 74, 75, 79, 82], [3, 11, 22, 24, 40, 54, 57, 63, 67, 74, 76, 79], [7, 11, 14, 24, 25, 40, 43, 54, 63, 67, 75, 79], [7, 8, 24, 41, 63, 79], [0, 11, 12, 25, 26, 27, 32, 33, 42, 44, 45, 60, 67, 69, 71, 72, 74, 76, 79, 82, 84], [8, 24, 29, 43, 57, 63, 67, 76, 79], [3, 8, 25, 28, 40, 75, 79], [8, 54, 63, 67, 70, 79], [3, 9, 10, 25, 40, 44, 45, 54, 60, 67, 71, 74, 76, 82, 84], [8, 10, 28, 40, 43, 45, 54, 67, 76, 79], [25, 32, 33, 67, 71, 82, 83, 84], [8, 24, 43, 63, 67, 70, 79], [8, 24, 28, 29, 41, 44, 57, 79], [8, 14, 24, 29, 41, 43, 57, 63, 67, 78, 79], [0, 12, 26, 27, 32, 33, 53, 55, 72, 84], [12, 17, 18, 27, 32, 33, 43, 45, 56, 63, 67, 71, 75, 84], [16, 25, 67, 71, 74, 76, 79], [8, 17, 24, 28, 41, 57, 63, 67, 70, 74, 79], [17, 19, 25, 26, 27, 42, 43, 71, 74, 83], [8, 17, 24, 28, 41, 43, 57, 63, 67, 70, 71, 79], [12, 25, 26, 27, 32, 44, 59, 60, 72, 74, 82], [8, 11, 14, 25, 28, 29, 40, 54, 63, 70, 71, 74, 76, 79], [8, 24, 29, 63, 79], [7, 8, 24, 28, 29, 40, 54, 63, 67, 79], [8, 10, 11, 12, 17, 18, 22, 25, 28, 40, 43, 54, 63, 67, 74, 76, 79], [2, 11, 24, 43, 47, 66], [12, 17, 18, 19, 39, 86], [8, 24, 37, 43, 57, 79], [3, 8, 10, 25, 31, 40, 54, 67, 71, 74, 79], [2, 14, 40, 54, 79], [45, 74, 76, 82, 84], [0, 9, 16, 21, 26, 27, 32, 33, 35, 37, 45, 60, 67, 71, 72, 74, 75, 79, 82, 84], [27, 32, 33, 59, 60, 84], [10, 11, 14, 24, 29, 43, 54, 67, 74, 79], [3, 8, 11, 17, 24, 28, 40, 41, 70, 79], [0, 12, 17, 25, 27, 32, 33, 43, 60, 67, 71, 72, 74, 82, 84, 86], [3, 25, 26, 27, 37, 45, 54, 60, 67, 74, 82, 84], [8, 10, 24, 28, 29, 41, 43, 57, 63, 67, 70], [17, 25, 32, 33, 45, 56, 60, 67, 69, 74, 84], [11, 25, 40, 44, 76], [0, 8, 24, 32, 43, 79], [0, 21, 27, 32, 33, 45, 60, 67, 74, 82, 84], [20, 28, 29, 43, 63, 67, 79], [8, 17, 24, 28, 29, 41, 43, 63, 67, 70, 79], [8, 24, 40, 43, 79], [3, 10, 14, 24, 25, 29, 40, 49, 54, 63, 67, 75, 79], [8, 54, 67, 71, 74, 79, 82], [0, 26, 27, 32, 33, 42, 45, 59, 74, 82, 84], [8, 11, 24, 28, 29, 41, 43, 57], [12, 26, 27, 32, 33, 43, 45, 55, 60, 67, 71, 72, 84], [8, 17, 24, 60, 63, 67, 71, 79], [10, 14, 25, 74, 79], [0, 11, 12, 17, 21, 25, 27, 32, 43, 45, 49, 60, 67, 71, 74, 75, 79, 82, 84], [8, 25, 28, 45, 47, 60, 67, 74, 82, 84], [3, 7, 10, 11, 16], [3, 7, 10, 14, 29, 40, 54, 67, 76, 79], [8, 17, 24, 25, 28, 29, 43, 45, 57, 63, 67, 71, 74, 75, 79, 82], [8, 17, 24, 28, 41, 43, 57, 63, 67, 70, 79], [3, 10, 11, 21, 25, 28, 29, 40, 41, 45, 49, 60, 63, 67, 74, 75, 79, 80, 82], [8, 10, 54, 67, 74, 79], [10, 11, 14, 38, 40, 54], [3, 9, 11, 25, 40, 45, 67, 79, 82], [3, 14, 25, 32, 33, 45, 49, 60, 67, 74, 75, 76, 79, 83, 84], [3, 8, 17, 25, 41, 43, 63, 67, 70, 76, 79], [11, 12, 26, 27, 33, 54, 72, 74, 84], [10, 11, 14, 22, 71, 74, 76], [10, 11, 25, 40, 54, 60, 63, 67, 74, 79, 82], [11, 16, 67, 74, 76, 79, 80], [8, 11, 28, 43, 57, 63, 67, 70, 74, 79], [17, 21, 25, 28, 45, 49, 60, 62, 67, 74, 82], [7, 8, 10, 11, 40, 43, 54, 67, 75, 79], [8, 24, 29, 43, 57, 63, 67, 70, 79], [8, 9, 11, 17, 25, 37, 43, 60, 63, 67, 79, 82], [8, 17, 24, 28, 54, 63, 67, 70, 79], [4, 7, 9, 10, 74, 77], [3, 7, 10, 11, 24, 25, 40, 49, 54, 63, 67, 74, 79], [3, 10, 11, 25, 40, 45, 54, 60, 74, 79, 82, 86], [8, 11, 14, 24, 67, 79], [8, 24, 28, 29, 41, 43, 57, 63, 70, 79], [8, 14, 25, 45, 54, 60, 67, 74, 79, 82], [3, 7, 9, 10, 16, 37, 40, 44, 78], [8, 17, 24, 28, 29, 41, 43, 57, 63, 67, 70, 79], [3, 7, 9, 10, 25, 43, 57, 67, 74, 75, 76, 79, 80], [8, 24, 28, 29, 57, 67, 79], [11, 14, 24, 54, 63, 67, 74, 79], [3, 8, 25, 28, 29, 45, 67, 71, 74, 76, 82], [3, 7, 10, 11, 14, 37, 38, 40, 44, 45, 49, 54, 60, 74, 76, 78, 79, 82, 86], [8, 10, 11, 17, 24, 40, 41, 43, 63, 67, 74, 79, 86], [3, 8, 11, 17, 24, 25, 57, 63, 67, 71, 74, 79], [25, 26, 27, 32, 33, 35, 53, 60, 62, 82, 84], [17, 25, 40, 49, 54, 67, 71], [2, 16, 20, 37, 44, 46, 76], [3, 8, 10, 11, 14, 23, 24, 28, 31, 40, 50, 63, 67, 70, 75, 79, 80], [8, 11, 17, 24, 28, 41, 43, 57, 63, 67, 70, 74, 79], [8, 11, 54, 67, 79], [0, 26, 27, 32, 33, 45, 60, 67, 72, 74, 82, 84], [3, 11, 25, 38, 40, 49, 60], [10, 21, 25, 32, 33, 45, 54, 60, 71, 74, 82, 84], [0, 6, 12, 26, 32, 33, 36, 44, 53, 59, 72], [17, 18, 24, 29, 32, 43, 55, 70, 71], [10, 21, 25, 44, 45, 60, 67, 75, 82, 84], [8, 24, 41, 76, 79, 80], [3, 11, 25, 63, 67, 74, 76], [25, 26, 27, 32, 33, 45, 59, 60, 67, 74, 79, 84], [8, 11, 17, 24, 28, 43, 63, 67, 70, 74, 79], [16, 25, 31, 36, 40, 71, 80, 82], [8, 13, 16, 28, 40, 41, 43, 63, 70, 76, 79], [3, 8, 10, 14, 25, 28, 29, 40, 54, 63, 74, 75, 79], [3, 7, 10, 11, 14, 38, 40, 49, 54, 67, 71, 74, 76, 79], [8, 17, 24, 28, 29, 41, 43, 63, 67, 70, 79], [8, 14, 17, 18, 24, 25, 41, 43, 45, 54, 60, 63, 67, 70, 79, 82], [11, 16, 22, 40, 49, 79], [3, 7, 8, 25, 33, 43, 63, 67, 74, 79, 83], [11, 14, 25, 67, 74, 76, 79], [0, 4, 10, 11, 16, 20, 25, 26, 33, 37, 38, 44, 45, 54, 74, 76, 82], [8, 28, 63, 67, 79], [4, 10, 25, 32, 33, 40, 45, 60, 67, 74, 76, 82], [13, 16, 37, 67, 74], [11, 12, 17, 25, 27, 32, 33, 45, 55, 60, 72, 73, 74, 76, 84], [0, 8, 25, 42, 67, 69, 71, 74, 76, 79], [0, 12, 21, 25, 27, 30, 32, 33, 67, 72], [3, 7, 8, 17, 24, 25, 28, 29, 38, 40, 41, 43, 57, 63, 67, 70, 75, 79], [0, 11, 12, 26, 27, 32, 33, 53, 60, 72, 74, 75, 81, 82, 84], [3, 8, 17, 24, 28, 29, 41, 43, 54, 63, 67, 70, 79], [8, 40, 54, 74, 79], [28, 29, 43, 67, 79], [25, 67, 74, 76, 79], [25, 27, 33, 60, 74, 83, 84, 86], [0, 25, 60, 72, 74, 76, 82, 84], [8, 24, 28, 29, 57, 63], [0, 25, 33, 59, 76, 83, 84], [3, 8, 11, 25, 28, 49, 60, 63, 67, 74, 79, 82], [3, 10, 11, 21, 25, 27, 33, 40, 45, 60, 67, 74, 82, 84], [0, 25, 27, 32, 33, 42, 44, 60, 67, 71, 72, 82, 84], [7, 10, 11, 40, 49, 74, 79], [3, 8, 11, 14, 25, 32, 33, 40, 43, 45, 49, 54, 60, 67, 70, 71, 74, 75, 79, 82], [7, 17, 18, 25, 31, 43], [29, 43, 54, 57, 79], [11, 14, 24, 36, 37, 40, 43, 54, 57, 67, 76, 79], [0, 6, 12, 26, 27, 32, 33, 44, 59, 67, 72, 83, 84], [11, 12, 27, 32, 67, 79, 84], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [11, 22, 24, 38, 75], [17, 25, 32, 45, 67, 71, 74, 82, 84], [3, 7, 11, 25, 27, 32, 33, 45, 60, 67, 71, 79, 82, 84], [9, 16, 17, 21, 24, 27, 32, 33, 37, 43, 60, 63, 67, 74, 79, 82, 83, 84], [3, 8, 10, 11, 14, 25, 40, 54, 63, 74, 76, 79], [21, 25, 32, 33, 45, 60, 67, 71, 74, 82, 84], [9, 10, 11, 15, 16, 37, 76], [22, 25, 44, 45, 57, 67, 71, 74, 76, 79, 82], [3, 25, 67, 74, 79, 82, 86], [8, 11, 14, 25, 49, 59, 63, 67, 71, 74, 75, 82], [0, 21, 31, 60, 76, 82, 84], [8, 11, 14, 17, 24, 28, 41, 43, 54, 63, 67, 70, 74, 76, 78, 79], [0, 12, 25, 26, 27, 32, 33, 35, 37, 44, 55, 60, 72, 74, 76, 82, 83, 84], [10, 11, 21, 38, 67, 74, 76], [3, 20, 25, 74, 82], [8, 24, 41, 63, 67, 79], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [3, 9, 10, 11, 40, 57, 66], [11, 25, 32, 45, 60, 67, 74, 76, 82, 84], [7, 26, 32, 33, 45, 60, 84], [3, 10, 11, 14, 25, 40, 67, 71, 75, 79, 82], [3, 7, 11, 25, 40], [3, 7, 17, 24, 25, 40, 67, 74, 75, 79], [26, 27, 44, 67, 71, 74, 76, 79, 83, 84], [30, 32, 33, 60, 72, 84], [0, 25, 27, 32, 33, 45, 67, 74, 76, 82, 84], [8, 24, 40, 43, 54, 63, 67, 78, 82], [3, 8, 10, 11, 14, 17, 24, 25, 28, 29, 40, 44, 54, 63, 67, 74, 76, 79, 82], [3, 7, 8, 10, 11, 24, 25, 28, 38, 40, 44, 49, 54, 60, 63, 67, 71, 74, 75, 79, 82], [3, 11, 67, 75, 79], [24, 28, 41, 63, 79, 80], [27, 32, 33, 37, 45, 67, 71, 74, 76, 82, 84], [3, 11, 40, 59, 67, 79], [0, 12, 26, 32, 33, 59, 60, 72, 74, 84], [7, 8, 10, 11, 28, 40, 63, 67, 79], [11, 25, 38, 40, 44, 74, 76], [3, 8, 10, 11, 24, 29, 40, 43, 44, 57, 63, 76, 79], [0, 21, 25, 26, 30, 32, 33, 35, 45, 55, 59, 60, 72, 74, 76, 82, 84, 86], [8, 11, 24, 28, 29, 63, 67, 79], [7, 8, 14, 17, 24, 43, 54, 63, 67, 71, 74, 79], [10, 11, 25, 54, 71, 82], [3, 25, 49, 67, 71, 76, 79, 80], [0, 6, 19, 25, 27, 32, 33, 45, 60, 67, 72, 74, 82, 83], [3, 14, 25, 31, 54, 67, 71, 72, 74, 76, 79, 86], [0, 12, 25, 26, 27, 42, 45, 54, 60, 67, 71, 72, 74, 79, 82, 84], [8, 14, 24, 40, 43, 54, 63, 79], [8, 24, 28, 29, 57, 67, 79], [0, 12, 17, 18, 21, 32, 67, 71, 84], [0, 3, 8, 10, 11, 14, 17, 24, 25, 27, 28, 38, 40, 41, 43, 49, 54, 63, 67, 71, 74, 75, 79, 82], [3, 7, 11, 17, 24, 25, 27, 32, 38, 40, 49, 60, 63, 67, 75, 79], [3, 25, 29, 40, 49, 60, 63, 67, 74, 75, 76, 79, 82], [3, 7, 10, 11, 14, 25, 38, 40, 67, 75, 79], [8, 17, 28, 29, 43, 63, 67, 79], [8, 11, 14, 40, 54], [3, 7, 8, 10, 11, 24, 25, 40, 63, 67, 70, 74, 79], [7, 8, 25, 28, 49, 63, 67, 70, 75, 79], [8, 17, 24, 28, 41, 63, 67, 70, 79], [8, 11, 14, 24, 28, 40, 43, 54, 63, 67, 76, 79], [8, 17, 18, 28, 29, 41, 43, 54, 63, 67, 79], [7, 9, 10, 11, 25, 40, 54, 67, 79, 82], [14, 24, 54, 67, 76, 79], [3, 7, 10, 11, 24, 25, 28, 40, 45, 49, 54, 60, 63, 67, 71, 74, 79, 82, 86], [8, 11, 14, 17, 24, 25, 40, 54, 63, 67, 74, 75, 79], [3, 11, 24, 38, 40, 79], [3, 7, 10, 11, 14, 24, 40, 54, 57, 67, 74, 79], [0, 3, 12, 25, 40, 49, 67, 71, 74, 75, 82, 84], [7, 10, 11, 22, 75, 76, 79], [0, 3, 10, 21, 25, 27, 30, 32, 33, 40, 42, 45, 60, 62, 63, 67, 69, 71, 74, 76, 79, 82, 84], [8, 11, 24, 57, 79], [0, 21, 32, 33, 45, 55, 72, 74, 83, 84], [11, 14, 40, 57, 78, 79], [8, 10, 14, 24, 40, 63, 67, 79], [3, 8, 10, 11, 17, 24, 25, 28, 29, 40, 41, 43, 57, 63, 67, 70, 74, 79], [0, 12, 26, 27, 32, 33, 35, 53, 55, 60, 67, 68, 72, 84], [0, 10, 25, 40, 67, 71, 76, 82, 85, 86], [3, 8, 10, 11, 14, 17, 24, 38, 40, 54, 57, 63, 67, 74, 75, 76, 79, 82], [3, 7, 11, 14, 25, 29, 40, 49, 54, 67, 71, 74, 75, 79, 82], [25, 26, 74, 82, 84], [0, 10, 11, 25, 26, 27, 32, 33, 40, 45, 59, 60, 69, 71, 72, 74, 76, 79, 80, 82, 84], [8, 10, 24, 28, 40, 43, 54, 63, 67, 79], [40, 49, 67, 75, 79], [9, 11, 14, 22, 40, 54, 79], [8, 14, 24, 28, 54, 63, 67], [2, 9, 32, 33, 37, 44, 69, 74, 76, 79], [7, 8, 10, 11, 14, 24, 28, 29, 40, 49, 63, 67, 74, 79], [0, 8, 26, 27, 33, 67, 72, 74, 84], [3, 8, 17, 21, 25, 27, 28, 32, 41, 43, 45, 60, 63, 67, 70, 71, 74, 75, 79, 82, 83, 84], [7, 10, 25, 40, 54, 60, 63, 67, 74, 79, 82], [8, 17, 28, 43, 57, 63, 67, 73, 76, 79], [7, 10, 11, 25, 40, 54, 67, 75], [0, 3, 10, 11, 14, 25, 40, 45, 54, 60, 67, 71, 74, 76, 82], [7, 8, 10, 14, 24, 28, 29, 40, 41, 43, 49, 54, 57, 63, 67, 70, 76, 78, 79], [3, 7, 10, 11, 40, 67, 79, 82], [3, 8, 10, 25, 28, 40, 41, 54, 63, 67, 70, 79, 80], [8, 11, 17, 24, 28, 29, 43, 63, 67, 70, 74, 79], [8, 24, 28, 29, 40, 41, 43, 63, 79], [8, 14, 24, 28, 40, 57, 63, 67, 71, 79], [11, 14, 54, 67, 79], [2, 9, 11, 22, 23, 76, 80], [8, 17, 24, 28, 29, 41, 43, 67, 70, 74, 79], [0, 12, 17, 26, 32, 33, 35, 55, 59, 72, 84], [8, 17, 24, 28, 29, 37, 41, 43, 63, 67, 70, 71, 79], [2, 13, 15, 16, 31, 44, 58, 76, 80], [3, 8, 14, 24, 28, 41, 63, 67, 70, 74, 78, 79], [8, 11, 24, 40, 63, 67, 79], [8, 17, 18, 24, 28, 29, 41, 43, 63, 67, 70, 79], [8, 24, 63, 67, 79], [8, 10, 28, 41, 63, 70, 79], [8, 24, 28, 41, 43, 57, 63, 70, 79], [7, 8, 17, 24, 28, 29, 41, 43, 70, 79], [3, 7, 9, 25, 44, 45, 60, 67, 74, 75, 79, 80, 82], [3, 25, 37, 40, 44, 49, 60, 67, 71, 74, 79, 82], [29, 63, 67, 74, 79], [0, 6, 12, 27, 32, 33, 35, 44, 53, 55, 60, 72, 74, 76, 83, 84], [3, 8, 14, 24, 29, 79], [4, 7, 26, 63, 76, 79, 80], [12, 26, 27, 32, 33, 35, 44, 55, 59, 72, 84], [10, 25, 33, 40, 45, 60, 71, 82], [3, 4, 9, 11, 22, 25, 38, 40, 54, 74, 75, 76, 79, 82, 85], [11, 22, 33, 45, 69, 76], [8, 10, 40, 46, 76, 79], [31, 44, 71, 76, 79, 82], [24, 28, 29, 41, 79], [8, 28, 29, 41, 49, 67], [3, 22, 32, 40, 45, 60, 71, 74, 76, 82], [3, 8, 10, 14, 17, 24, 25, 28, 54, 63, 67, 74, 79, 82], [28, 43, 45, 49, 60, 67, 71, 74, 75, 79, 82, 84], [8, 24, 28, 67, 79], [3, 7, 9, 11, 14, 20, 22, 24, 38, 44, 67, 76, 79], [11, 25, 54, 71, 79, 82], [0, 24, 25, 27, 33, 37, 54, 63, 67, 69, 79], [3, 10, 11, 14, 40, 74, 79], [0, 26, 27, 32, 33, 60, 72, 74, 82, 83, 84], [11, 25, 44, 67, 71, 74, 76], [8, 28, 40, 41, 70], [3, 7, 10, 11, 29, 40, 49, 54, 59, 67, 74, 75, 79, 82], [0, 25, 30, 32, 45, 60, 72, 84], [0, 14, 25, 32, 33, 40, 45, 54, 60, 72, 76, 79, 84], [8, 14, 24, 28, 29, 41, 43, 54, 57, 63, 67, 70, 79], [8, 11, 22, 24, 28, 41, 63, 67, 79], [8, 24, 29, 63, 79], [0, 13, 16, 26, 27, 32, 33, 44, 45, 60, 76, 79, 82, 83, 84], [8, 11, 14, 24, 28, 44, 46, 63, 74, 76, 79], [8, 14, 17, 24, 29, 43, 57, 63, 67, 79], [0, 6, 12, 26, 27, 32, 33, 53, 55, 68, 72, 84], [8, 24, 28, 41, 63, 67], [0, 3, 11, 17, 22, 25, 27, 32, 33, 43, 45, 59, 60, 67, 69, 71, 72, 74, 79, 82, 84], [8, 24, 28, 43, 63, 67, 79], [17, 38, 41, 43, 67, 79], [6, 12, 26, 27, 32, 33, 53, 55, 72, 84], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [8, 11, 24, 40, 63, 67, 74, 76, 79], [3, 8, 11, 24, 28, 43, 57, 79], [0, 8, 11, 12, 17, 24, 25, 26, 27, 32, 33, 43, 44, 63, 71, 72, 74, 79, 82, 83, 84], [11, 14, 43, 67, 79], [8, 17, 24, 28, 45, 60, 63, 67, 70, 74, 79], [8, 17, 18, 24, 28, 29, 40, 41, 43, 67, 70, 79], [0, 12, 26, 27, 32, 33, 35, 55, 59, 72, 81, 83, 84], [3, 7, 40, 49, 54, 74, 76, 79], [3, 8, 10, 11, 14, 28, 40, 49, 54, 74, 76, 79], [3, 11, 17, 21, 25, 26, 32, 33, 43, 45, 56, 60, 67, 71, 72, 74, 79, 82, 84], [7, 28, 43, 67, 79, 86], [17, 28, 29, 45, 63, 67, 79], [3, 11, 38, 40, 49, 54, 60, 74, 75, 79, 82, 86], [8, 9, 13, 16, 24, 27, 28, 29, 33, 37, 63, 67, 70, 79, 83], [8, 11, 14, 22, 24, 29, 40, 43, 54, 57, 63, 67, 74, 79], [8, 28, 43, 67, 74, 79], [8, 24, 28, 29, 41, 63, 70, 79], [8, 9, 11, 17, 24, 25, 29, 40, 43, 63, 67, 74, 75, 79], [8, 24, 43, 67, 79], [8, 24, 29, 43, 63, 67, 79], [8, 24, 28, 41, 43, 67, 70, 74, 79], [8, 25, 26, 43, 63, 67, 74, 79, 82], [3, 7, 11, 25, 40, 54, 74, 79, 82], [3, 11, 21, 43, 49, 67, 74, 79, 82], [8, 14, 43, 67, 74, 80], [3, 8, 25, 40, 44, 63, 67, 71, 75, 79, 82], [3, 6, 19, 25, 27, 33, 45, 59, 67, 71, 74, 79, 82, 83], [11, 37, 44, 46, 76], [11, 24, 25, 28, 63, 79], [0, 12, 26, 27, 32, 33, 51, 53, 59, 67, 72, 74, 83, 84], [0, 3, 10, 11, 25, 42, 60, 63, 66, 67, 69, 74, 79, 82], [8, 24, 28, 29, 41, 45, 60, 63, 67, 70, 79, 82], [3, 7, 8, 20, 25, 40, 45, 60, 74, 79, 82], [4, 7, 8, 10, 11, 24, 37, 38, 40, 44, 54, 79], [8, 24, 28, 32, 41, 43, 45, 60, 63, 67, 70, 71, 79], [0, 12, 33, 72, 84], [10, 12, 20, 25, 26, 27, 32, 33, 55, 59, 67, 71, 72, 74, 76, 82, 83, 84], [8, 14, 17, 24, 25, 28, 29, 40, 43, 45, 54, 63, 67, 71, 79, 82], [14, 22, 29, 76, 79], [0, 21, 25, 33, 40, 45, 59, 67, 76, 83, 84], [3, 11, 25, 40, 49, 74, 84], [3, 11, 40, 71, 74, 82], [8, 14, 24, 28, 43, 44, 54, 63, 67, 79], [3, 8, 10, 25, 43, 45, 54, 63, 67, 71, 74, 79, 82], [11, 17, 32, 43, 45, 55, 60, 71, 74, 82, 84], [0, 20, 27, 32, 33, 42, 55, 67, 74, 76, 82, 83, 84], [6, 12, 25, 26, 27, 32, 33, 35, 45, 55, 60, 72, 74, 84], [3, 8, 25, 28, 40, 67, 71, 79], [10, 11, 14, 24, 40, 54, 67, 74, 79], [3, 4, 10, 11, 25, 37, 67, 74, 76, 80, 82], [0, 11, 25, 33, 40, 49, 56, 60, 67, 71, 74], [3, 7, 10, 11, 14, 25, 38, 40, 49, 54, 60, 67, 71, 74, 75, 79, 82], [3, 10, 25, 63, 74, 76, 79], [8, 17, 25, 41, 76, 79], [3, 8, 10, 11, 24, 41, 63, 79], [3, 8, 11, 25, 40, 43, 49, 74, 75, 79, 82], [3, 8, 11, 16, 17, 19, 25, 28, 32, 37, 38, 43, 44, 45, 49, 57, 63, 67, 71, 74, 76, 79, 82], [0, 12, 16, 26, 27, 32, 33, 72, 84], [7, 10, 11, 33, 37, 43, 54, 59, 63, 67, 71, 74, 76, 79, 82], [8, 14, 24, 28, 43, 70, 78], [8, 14, 24, 54, 57, 63, 76], [11, 38, 44, 54, 71, 74, 76], [29, 41, 67, 76, 79], [3, 10, 11, 25, 38, 40, 49, 74, 75], [3, 10, 11, 25, 27, 32, 33, 60, 67, 71, 74, 76, 82, 84], [25, 26, 27, 32, 33, 35, 55, 59, 74, 84], [8, 11, 24, 28, 29, 41, 43, 63, 67, 70, 79], [4, 9, 40, 44, 47, 76, 80], [8, 17, 24, 27, 42, 43, 57, 63, 67, 72, 79, 84], [8, 11, 17, 24, 25, 43, 44, 63, 67, 71, 79, 82], [8, 11, 24, 25, 38, 44, 57, 63, 67, 74, 76, 79, 86], [8, 17, 18, 24, 25, 43, 63, 67, 74, 79], [3, 10, 11, 14, 38, 40, 43, 49, 54, 66, 67, 74, 78, 79], [8, 11, 17, 24, 41, 43, 63, 67, 75, 76, 79], [3, 11, 14, 24, 40, 43, 54, 63, 67, 79], [0, 12, 26, 32, 33, 35, 43, 53, 55, 72, 84], [17, 25, 32, 33, 43, 45, 60, 63, 67, 71, 74, 79, 82, 84], [27, 69, 71, 72, 74, 82, 84], [8, 11, 17, 24, 25, 27, 28, 32, 33, 43, 45, 60, 63, 67, 70, 74, 79, 82, 84], [3, 11, 25, 26, 27, 32, 33, 45, 60, 74, 75, 84], [8, 10, 11, 14, 24, 28, 40, 41, 67, 70, 79], [8, 11, 14, 24, 29, 40, 54, 57, 63, 67, 79], [0, 9, 12, 27, 32, 33, 44, 72, 73, 84, 86], [11, 25, 40, 76, 79], [28, 41, 54, 67, 79], [0, 6, 12, 26, 27, 30, 32, 33, 45, 55, 60, 72, 74, 76, 84], [3, 7, 8, 17, 24, 25, 28, 43, 50, 63, 67, 71, 74], [3, 8, 11, 17, 22, 24, 25, 38, 40, 63, 67, 74, 76, 79], [17, 24, 28, 29, 41, 43, 67, 70, 79], [0, 12, 26, 32, 33, 35, 55, 59, 72, 76, 84], [8, 17, 25, 28, 43, 45, 49, 60, 67, 70, 74, 82], [0, 3, 10, 11, 21, 25, 27, 32, 33, 40, 45, 60, 67, 71, 74, 76, 79, 82, 84], [8, 17, 24, 28, 29, 41, 43, 63, 67, 70, 74, 79], [21, 27, 32, 33, 37, 44, 45, 60, 67, 74, 82, 84], [14, 40, 43, 63, 67, 70, 74, 79], [17, 25, 26, 27, 32, 33, 43, 45, 60, 67, 74, 79, 82, 84], [0, 3, 9, 21, 25, 45, 60, 67, 71, 74, 82, 84], [2, 3, 8, 16, 20, 28, 40, 75, 76, 79, 80], [3, 10, 11, 20, 25, 38, 40, 46, 67, 74, 76, 79], [0, 20, 25, 27, 33, 59, 72, 74, 76], [3, 7, 8, 10, 11, 14, 17, 24, 25, 28, 29, 40, 43, 45, 54, 57, 67, 70, 79], [7, 8, 17, 24, 28, 40, 43, 63, 67, 70, 79], [8, 11, 24, 63, 75, 79], [0, 11, 12, 26, 27, 32, 33, 38, 43, 55, 60, 67, 72, 82, 84], [8, 26, 27, 32, 33, 35, 45, 74, 83, 84], [8, 11, 14, 17, 28, 29, 41, 43, 54, 63, 67, 74, 79], [0, 12, 26, 27, 32, 33, 72, 84], [0, 12, 26, 27, 59, 60, 72, 84], [3, 7, 10, 14, 24, 25, 40, 74, 79], [8, 11, 24, 28, 40, 41, 63, 67, 70, 75, 79], [25, 43, 67, 71, 74], [14, 63, 67, 71, 74, 79], [3, 8, 11, 25, 28, 38, 40, 41, 43, 67, 74, 76, 79], [0, 12, 27, 32, 33, 53, 55, 68, 72, 84], [7, 8, 28, 74, 79], [3, 10, 11, 14, 24, 40, 63, 67, 71, 74, 76, 78, 79], [3, 9, 10, 11, 25, 36, 38, 40, 43, 48, 49, 67, 71, 74, 75, 79, 80, 82], [45, 60, 67, 71, 74, 82], [3, 10, 17, 22, 25, 32, 43, 60, 67, 69, 73, 74, 76, 79, 82, 84], [0, 12, 25, 26, 27, 32, 33, 35, 37, 45, 53, 55, 59, 60, 68, 72, 74, 82, 84, 85], [3, 8, 10, 14, 24, 25, 29, 43, 57, 63, 67, 70, 74, 79], [0, 12, 27, 32, 33, 45, 60, 71, 82, 84], [7, 8, 11, 14, 54, 76, 79], [3, 25, 40, 63, 67, 74, 76, 79], [9, 27, 32, 33, 45, 60, 76, 79, 80, 84], [3, 8, 10, 11, 14, 24, 28, 29, 38, 40, 41, 57, 63, 79], [8, 14, 24, 28, 41, 63, 70, 79], [25, 26, 32, 60, 67, 74], [0, 12, 19, 27, 33, 67, 84], [0, 6, 12, 21, 27, 30, 33, 55, 72, 84], [3, 11, 25, 32, 33, 45, 54, 60, 67, 74], [11, 25, 27, 32, 33, 43, 45, 60, 67, 74, 79, 82, 84], [7, 21, 25, 26, 27, 43, 63, 67, 71, 76, 84], [3, 7, 11, 17, 18, 25, 26, 27, 44, 45, 50, 67, 71, 74, 76, 79, 80, 82, 84], [3, 25, 67, 74, 76, 79], [3, 8, 10, 17, 25, 28, 40, 45, 60, 63, 67, 71, 74, 79, 82], [8, 17, 24, 28, 29, 37, 41, 43, 63, 67, 70, 79], [0, 8, 40, 41, 67, 79], [8, 17, 24, 28, 29, 30, 43, 54, 60, 63, 67, 71, 74, 79], [17, 25, 45, 60, 67, 71, 74, 79, 82], [7, 11, 40, 54, 63, 67, 71, 74, 79], [3, 16, 17, 18, 25, 27, 32, 33, 37, 43, 45, 47, 60, 63, 67, 72, 74, 79, 83, 84], [3, 8, 10, 14, 24, 40, 57, 63, 79], [11, 25, 26, 27, 32, 33, 40, 45, 54, 60, 67, 71, 74, 76, 82, 83, 84], [33, 60, 76, 80, 82, 84], [11, 25, 26, 27, 32, 33, 45, 63, 67, 71, 74, 79], [3, 11, 38, 40, 54, 57, 63, 67, 71, 76, 79, 82], [17, 43, 67, 71, 74, 82], [8, 24, 57, 63, 67], [3, 10, 17, 40, 45, 59, 60, 74, 79], [8, 17, 18, 24, 41, 43, 57, 63, 67, 70, 74, 79], [10, 44, 48, 76, 80], [0, 6, 9, 12, 27, 32, 33, 53, 72, 84], [35, 44, 71, 74, 76, 84], [25, 27, 59, 60, 67, 74, 75, 79, 82, 84], [8, 17, 24, 28, 29, 41, 63, 67, 70, 79], [7, 8, 11, 17, 24, 25, 29, 43, 59, 63, 67, 74, 79], [8, 11, 17, 24, 28, 40, 43, 54, 67, 79], [4, 25, 32, 45, 54, 60, 74, 76, 82], [7, 10, 11, 45, 67, 71, 74, 79, 82], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [7, 8, 10, 11, 24, 28, 54, 63, 67, 70, 71, 74, 79, 82], [25, 32, 40, 42, 45, 54, 59, 60, 67, 71, 74, 82, 84], [25, 28, 45, 60, 67, 74, 79, 82], [8, 28, 54, 67, 74, 78, 79], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [25, 43, 45, 67, 74, 76, 84], [7, 8, 10, 14, 24, 28, 40, 41, 43, 54, 63, 67, 70, 79], [3, 25, 45, 54, 60, 67, 74, 82], [7, 10, 25, 44, 74, 82, 85], [0, 3, 12, 16, 25, 26, 27, 33, 40, 42, 43, 44, 45, 59, 60, 61, 67, 71, 72, 76, 79, 82, 83, 84], [8, 22, 24, 28, 29, 41, 43, 46, 63, 67, 76, 79], [28, 29, 41, 59, 67], [21, 25, 54, 60, 75, 79, 82, 86], [3, 11, 25, 57, 60, 63, 67, 71, 74, 75, 76, 79, 82], [0, 2, 11, 12, 20, 21, 25, 32, 33, 44, 45, 50, 53, 54, 60, 67, 71, 72, 74, 76, 82, 84, 87], [8, 25, 43, 71, 74], [26, 27, 32, 33, 53, 55, 60, 84], [13, 16, 17, 25, 27, 33, 55, 80, 84], [0, 11, 12, 25, 27, 32, 33, 60, 67, 71, 72, 74, 82, 84], [3, 8, 11, 17, 18, 25, 28, 45, 49, 56, 60, 62, 67, 75, 79, 82], [0, 6, 12, 32, 33, 60, 72, 84], [0, 8, 17, 21, 25, 27, 28, 32, 33, 43, 45, 60, 63, 67, 71, 72, 73, 74, 82, 84], [8, 17, 24, 28, 29, 41, 43, 57, 63, 67, 79], [3, 8, 10, 11, 14, 22, 24, 25, 29, 40, 43, 54, 57, 63, 67, 71, 74, 79, 82], [3, 10, 11, 14, 38, 40, 54, 66, 78, 79], [0, 21, 30, 32, 33, 42, 45, 60, 72, 82, 84], [0, 12, 25, 26, 27, 33, 44, 53, 59, 72, 84], [8, 14, 24, 41, 54, 63, 67, 70, 79], [8, 17, 24, 41, 63, 67, 74, 76], [25, 27, 33, 45, 59, 60, 67, 71, 79, 82, 84], [3, 10, 11, 25, 74, 76, 84], [8, 26, 27, 35, 43, 67, 71, 76, 79, 82], [3, 11, 25, 40, 49, 54, 67, 74, 78, 82], [7, 8, 14, 40, 49, 54, 70, 79], [8, 24, 28, 41, 63, 67, 70, 79], [8, 11, 24, 28, 40, 43, 57, 63, 70, 79], [27, 32, 33, 45, 55, 83, 84], [4, 25, 27, 32, 33, 40, 45, 60, 62, 76, 80, 82, 84], [0, 11, 40, 42, 45, 54, 60, 79, 82, 84], [7, 9, 10, 20, 38, 40, 44, 46, 60, 77], [25, 27, 32, 60, 74, 82, 84], [0, 12, 25, 26, 27, 32, 33, 55, 60, 72, 74, 82, 84], [0, 6, 12, 33, 53, 55, 72, 84], [11, 14, 28, 44, 74, 76, 82], [0, 21, 33, 42, 67, 76, 79, 84], [3, 8, 11, 14, 24, 25, 28, 40, 49, 57, 67, 70, 75, 79], [25, 43, 60, 67, 71, 74, 82], [0, 8, 11, 67, 74, 79, 82], [11, 24, 25, 38, 40, 44, 54, 76, 79], [17, 21, 27, 31, 32, 33, 55, 59, 60, 73, 74, 84], [8, 11, 24, 57, 67, 79], [3, 8, 11, 17, 25, 43, 49, 67, 79, 84], [8, 24, 25, 67, 74, 79], [3, 8, 11, 14, 24, 25, 28, 29, 37, 40, 41, 49, 54, 63, 66, 67, 70, 74, 76, 79, 80, 82], [12, 27, 32, 33, 74, 84], [8, 17, 28, 29, 41, 43, 63, 67, 70, 79], [9, 13, 16, 37, 44, 76], [17, 25, 27, 30, 43, 60, 67, 71, 74, 79, 82, 84], [10, 11, 24, 28, 29, 41, 70, 79], [0, 25, 26, 63, 67, 74, 82, 83, 84], [7, 67, 76, 79, 80], [8, 16, 18, 24, 25, 28, 31, 33, 41, 43, 45, 60, 63, 67, 70, 73, 74, 79, 82], [8, 25, 28, 29, 41, 63, 67, 70, 79], [8, 11, 24, 29, 54, 63, 78, 79], [3, 7, 10, 11, 25, 40, 44, 60, 67, 71, 74, 76, 79, 82], [3, 10, 11, 21, 25, 27, 32, 33, 37, 45, 56, 60, 71, 74, 79, 82, 84], [25, 26, 27, 32, 35, 59, 71, 76, 84], [8, 11, 24, 43, 57, 63, 67, 79], [3, 9, 38, 40, 49, 67, 76, 79], [3, 10, 11, 25, 38, 40, 49, 67, 74, 79], [11, 25, 27, 32, 33, 45, 60, 67, 71, 72, 74, 76, 82, 84], [8, 44, 56, 67, 74, 82], [3, 8, 11, 17, 24, 25, 28, 29, 40, 41, 43, 57, 63, 67, 70, 74, 79, 82], [8, 24, 28, 29, 79], [8, 17, 24, 28, 29, 41, 43, 63, 67, 70, 79], [3, 7, 11, 14, 79], [8, 17, 43, 63, 74, 75, 79], [25, 43, 45, 60, 67, 71, 74, 79, 82], [0, 2, 12, 25, 27, 32, 33, 67, 69, 72, 74, 84], [8, 11, 14, 28, 41, 43, 67, 79], [8, 24, 28, 43, 44, 47, 57, 63, 67, 76, 79], [11, 21, 32, 33, 45, 49, 60, 71, 74, 79, 82, 84], [3, 11, 25, 27, 45, 60, 63, 67, 71, 74, 79, 82, 84], [4, 10, 21, 25, 27, 32, 33, 42, 45, 50, 60, 67, 74, 76, 82, 83], [11, 27, 33, 55, 67, 74, 79, 84], [3, 21, 26, 27, 32, 40, 43, 45, 54, 63, 70, 71, 79, 84], [11, 28, 40, 63, 67, 79], [37, 44, 45, 54, 57, 60, 67, 71, 74, 79, 82], [12, 25, 26, 27, 33, 59, 76, 82, 84], [3, 8, 11, 44, 54, 57, 79], [37, 63, 67, 74, 79], [10, 11, 14, 24, 25, 40, 50, 54, 67, 79, 80], [40, 63, 67, 74, 76, 79, 80], [8, 17, 18, 43, 54, 63, 67, 70, 71, 74, 79, 82], [3, 7, 25, 67, 74, 82], [3, 11, 21, 24, 67, 79], [3, 7, 10, 11, 25, 38, 49, 74, 75], [3, 11, 25, 32, 38, 40, 45, 49, 50, 60, 67, 74, 76, 82, 84], [8, 17, 24, 28, 29, 41, 63, 70, 79], [8, 17, 24, 28, 29, 41, 54, 63, 67, 70, 74, 79], [3, 8, 9, 11, 17, 24, 25, 32, 33, 40, 43, 60, 67, 71, 76, 79, 82], [8, 41, 43, 63, 67, 79], [21, 25, 26, 27, 33, 35, 45, 54, 55, 59, 60, 67, 74, 82, 83, 84, 85], [3, 10, 11, 21, 25, 27, 32, 33, 40, 45, 49, 60, 67, 71, 74, 79, 82], [0, 6, 12, 17, 20, 21, 26, 32, 45, 55, 68, 72, 83, 84], [3, 8, 17, 24, 28, 29, 41, 43, 49, 63, 67, 70, 79], [3, 25, 60, 71, 74, 75, 82], [13, 16, 37, 44, 67, 71, 79], [3, 10, 40, 79, 80], [3, 40, 49, 63, 75, 79], [10, 14, 24, 74, 79], [3, 7, 8, 10, 11, 21, 24, 25, 29, 32, 38, 40, 41, 43, 49, 57, 60, 63, 67, 74, 79, 82], [3, 7, 8, 10, 11, 14, 25, 40, 50, 54, 67, 79, 82], [8, 24, 40, 41, 54, 67, 70, 79], [17, 21, 25, 26, 27, 29, 32, 33, 45, 49, 56, 60, 67, 71, 75, 79, 82, 83, 84], [8, 10, 11, 17, 18, 25, 29, 43, 63, 67, 71, 74, 79, 82], [8, 24, 28, 29, 41, 57, 63, 67, 70, 74, 79], [17, 25, 27, 32, 43, 45, 56, 60, 62, 63, 67, 71, 74, 84], [7, 27, 33, 44, 60, 67, 83, 84], [10, 11, 17, 18, 25, 40, 43, 45, 54, 56, 63, 67, 74, 79], [17, 21, 25, 26, 27, 32, 33, 45, 60, 67, 71, 74, 82, 84], [8, 10, 24, 29, 63, 67, 79], [3, 7, 10, 11, 22, 25, 40, 54, 75, 79], [5, 10, 49, 57, 63, 67, 75, 79], [10, 11, 25, 44, 45, 54, 67, 71, 74, 75, 76, 79, 82], [3, 8, 11, 14, 24, 57, 70, 78, 79], [0, 12, 21, 25, 26, 27, 32, 33, 35, 53, 59, 72, 74, 76, 82, 83, 84], [8, 43, 63, 67, 79], [10, 11, 14, 24, 28, 29, 40, 54, 63, 67, 78, 79], [10, 11, 38, 40, 67, 74], [0, 12, 26, 27, 32, 33, 35, 59, 60, 72, 83, 84], [11, 14, 40, 43, 54, 76, 79], [17, 25, 29, 67, 71, 74, 82], [8, 17, 24, 28, 29, 41, 43, 63, 67, 70, 79], [0, 11, 21, 25, 26, 27, 32, 33, 74, 76, 82, 84, 86], [8, 17, 24, 28, 41, 43, 63, 67, 70, 74], [17, 24, 26, 27, 32, 33, 43, 45, 54, 60, 71, 74, 76, 84], [3, 11, 25, 32, 40, 45, 49, 54, 56, 60, 74, 82, 84], [8, 14, 24, 28, 41, 43, 57, 63, 67, 70, 74], [8, 14, 24, 28, 29, 40, 41, 49, 54, 57, 63, 67, 70, 79], [8, 17, 24, 28, 41, 43, 56, 63, 67, 70, 74, 79], [10, 11, 14, 25, 71, 74, 80, 82], [3, 8, 11, 24, 28, 29, 41, 43, 49, 63, 67, 70, 79], [26, 32, 33, 45, 83, 84], [3, 11, 14, 25, 40, 54, 74, 78, 79], [3, 10, 11, 17, 24, 25, 30, 40, 43, 45, 54, 60, 63, 67, 71, 74, 79, 82], [0, 3, 8, 11, 17, 25, 33, 43, 63, 67, 71, 73, 74, 76, 79, 84], [3, 11, 25, 40, 67, 79, 82], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [11, 17, 24, 43, 67, 74], [7, 11, 25, 26, 40, 43, 44, 69, 74, 79, 82], [11, 12, 16, 21, 25, 26, 27, 32, 33, 35, 44, 45, 55, 60, 67, 74, 82, 83, 84], [0, 6, 27, 32, 33, 53, 68, 72, 76, 84], [7, 63, 67, 78, 79], [8, 17, 24, 28, 29, 40, 41, 43, 63, 67, 70, 79], [9, 16, 17, 18, 25, 38, 44, 67, 76, 79, 82], [8, 17, 24, 28, 29, 43, 57, 63, 67, 76, 79], [27, 32, 33, 60, 67, 79, 82, 84], [8, 14, 22, 23, 24, 25, 28, 40, 41, 63, 64, 74, 75, 79, 80, 86], [8, 11, 14, 17, 22, 23, 54, 63, 67, 69, 70, 79, 86], [8, 28, 43, 63, 67, 70], [3, 11, 25, 43, 63, 67, 74, 79, 82], [8, 11, 14, 24, 57, 63, 67, 79], [0, 21, 25, 27, 32, 33, 45, 60, 83, 84], [27, 45, 67, 71, 74, 79, 82, 84, 86], [6, 19, 27, 33, 45, 55, 60, 67, 71, 76, 83, 84], [8, 28, 29, 57, 67, 79], [2, 11, 54, 76, 78], [10, 11, 25, 45, 60, 74, 82], [26, 27, 32, 45, 54, 74, 84], [3, 8, 11, 25, 28, 40, 43, 54, 63, 67, 71, 74, 79, 82], [13, 16, 25, 31, 40, 44, 54, 60, 71, 73, 74, 76, 80, 82], [0, 12, 26, 27, 32, 33, 60, 72, 74, 84, 87], [16, 25, 26, 37, 44, 67, 74, 76, 84], [8, 24, 28, 43, 56, 57, 63, 79], [3, 8, 10, 11, 14, 25, 38, 40, 54, 63, 67, 74, 79, 82], [13, 17, 18, 43, 67, 71, 74, 79], [3, 7, 8, 14, 25, 40, 43, 54, 67, 71, 74, 75, 82], [3, 7, 25, 27, 33, 40, 45, 54, 60, 84], [10, 11, 14, 40, 54, 79], [8, 29, 38, 54, 67, 76, 79], [3, 8, 25, 40, 67, 71, 76, 79], [0, 3, 8, 10, 12, 17, 25, 27, 28, 32, 33, 37, 42, 43, 45, 60, 67, 72, 74, 75, 76, 79, 82, 83, 84, 86], [8, 11, 14, 28, 41, 43, 67, 79], [0, 12, 51, 52, 72, 76], [3, 25, 63, 67, 71, 82], [8, 17, 24, 28, 41, 63, 67, 70], [10, 11, 40, 54, 79], [0, 3, 8, 12, 14, 17, 25, 27, 28, 32, 33, 43, 45, 54, 60, 63, 67, 70, 71, 72, 74, 79, 82, 83, 84], [21, 25, 30, 32, 44, 60, 74, 82, 84], [8, 11, 25, 38, 40, 54, 63, 67, 71, 74, 79, 82], [0, 12, 32, 33, 72, 74, 82, 84], [3, 10, 11, 14, 22, 40, 54, 67, 78, 79], [0, 3, 11, 21, 25, 26, 27, 32, 33, 45, 59, 60, 67, 74, 79, 82, 84], [0, 26, 27, 31, 33, 49, 60, 67, 71, 72, 76, 84], [3, 11, 40, 49, 63, 67, 79], [8, 17, 18, 24, 28, 29, 40, 41, 43, 63, 70, 79], [8, 17, 24, 41, 43, 63, 67, 79], [8, 24, 41, 63, 67, 79], [3, 25, 67, 75, 79], [3, 8, 11, 25, 28, 40, 45, 49, 54, 60, 66, 67, 74, 82], [3, 8, 11, 40, 63], [24, 29, 30, 43, 63, 67, 74, 79, 86], [21, 26, 27, 32, 33, 45, 55, 72, 84], [11, 22, 24, 28, 41, 63, 67, 79], [2, 4, 9, 15, 16, 20, 37, 44, 46, 76, 80, 85], [8, 21, 25, 27, 28, 32, 33, 40, 45, 60, 67, 74, 76, 82, 83, 84], [8, 17, 43, 63, 67, 79], [9, 25, 37, 39, 67, 73, 74, 79, 86], [8, 11, 74, 76, 82], [3, 10, 11, 24, 25, 45, 54, 60, 71, 79, 82], [8, 17, 24, 25, 26, 27, 28, 29, 32, 33, 43, 56, 60, 63, 67, 71, 74, 75, 79, 82, 83], [8, 28, 41, 67, 70, 79], [7, 10, 25, 28, 40, 60, 63, 67, 74, 75, 82, 86], [3, 8, 10, 11, 16, 17, 24, 25, 28, 43, 44, 45, 60, 63, 67, 71, 76, 79, 82], [0, 11, 12, 21, 25, 26, 27, 32, 33, 35, 45, 49, 56, 60, 61, 67, 71, 74, 76, 82, 83, 84], [21, 27, 32, 33, 45, 60, 67, 76, 83, 84], [14, 24, 40, 41, 54, 74, 79], [3, 8, 49, 63, 67, 70], [3, 8, 24, 25, 28, 38, 40, 43, 49, 63, 66, 67, 74, 79, 82], [8, 24, 28, 41, 43, 57, 63, 67, 70, 79], [7, 8, 17, 22, 24, 25, 28, 29, 43, 63, 67, 70, 79], [8, 14, 28, 43, 63, 79], [25, 33, 40, 45, 60, 67, 74, 82, 84], [8, 17, 24, 28, 40, 41, 43, 49, 63, 67, 70, 74, 79], [3, 8, 11, 25, 40, 45, 49, 60, 63, 67, 71, 74, 75, 79, 82, 84], [6, 12, 19, 26, 27, 32, 33, 43, 60, 67, 74, 76, 84], [11, 40, 43, 54, 63, 67, 74, 76, 79], [8, 24, 28, 29, 41, 70], [11, 16, 24, 40, 63], [21, 25, 26, 27, 32, 33, 45, 60, 67, 71, 74, 82, 84, 86], [3, 10, 11, 14, 40, 41, 54, 67, 74, 76, 79], [0, 25, 27, 33, 74, 76, 84], [0, 12, 21, 27, 30, 32, 33, 45, 53, 55, 60, 72, 74, 84], [3, 7, 11, 24, 25, 40, 63, 67, 75, 79, 82], [3, 8, 14, 25, 40, 49, 63, 79], [0, 6, 12, 26, 27, 30, 32, 33, 35, 53, 55, 68, 72, 83, 84], [8, 43, 57, 63, 76, 79], [24, 29, 57, 76, 79], [3, 7, 10, 11, 25, 40, 44, 63, 67, 71, 74, 79, 82], [25, 45, 60, 74, 76, 82], [3, 11, 25, 26, 32, 33, 44, 45, 60, 67, 71, 74, 75, 76, 78, 82, 84], [3, 7, 32, 37, 44, 46, 67, 79], [7, 8, 10, 11, 14, 17, 25, 43, 44, 60, 63, 67, 71, 73, 74, 76, 79, 82], [0, 12, 21, 25, 26, 27, 32, 33, 35, 42, 45, 56, 60, 67, 72, 74, 82, 84], [8, 24, 28, 41, 63, 67, 70, 79], [25, 26, 27, 32, 33, 44, 59, 67, 69, 71, 74, 76, 83, 84], [0, 8, 9, 11, 24, 25, 38, 40, 41, 43, 44, 57, 63, 67, 74, 76, 79, 82], [0, 21, 27, 32, 33, 44, 45, 60, 67, 71, 74, 76, 82, 83, 84], [3, 8, 11, 14, 24, 28, 40, 41, 49, 54, 57, 63, 67, 70, 74, 76, 79], [3, 7, 10, 11, 38, 40, 79], [11, 25, 40, 54, 67, 79], [8, 14, 24, 29, 40, 57, 63, 79], [10, 11, 16, 24, 40, 45, 54, 60, 63, 74, 75, 79, 82], [8, 25, 45, 74, 76], [11, 40, 41, 49, 75, 79], [8, 17, 28, 41, 43, 63, 67, 70, 74, 79], [8, 17, 24, 41, 43, 44, 63, 67, 70, 74, 76, 79], [7, 10, 11, 25, 74, 75], [3, 8, 25, 28, 43, 45, 60, 63, 67, 71, 74, 82], [8, 11, 24, 25, 28, 63, 67, 79], [14, 24, 28, 40, 41, 54, 63, 67, 79], [0, 12, 22, 25, 26, 27, 42, 69, 72, 76, 84, 86], [8, 14, 24, 28, 29, 40, 43, 54, 63, 67, 79], [8, 11, 24, 25, 43, 63, 67, 74, 76, 79], [7, 8, 10, 11, 14, 25, 28, 29, 40, 54, 63, 67, 70, 79], [25, 45, 60, 67, 74, 82], [0, 3, 21, 26, 27, 32, 45, 49, 60, 67, 74, 76, 82], [3, 11, 28, 43, 75, 79], [25, 67, 71, 74, 82], [7, 8, 24, 34, 43, 67, 74, 76, 79], [8, 14, 17, 24, 29, 43, 54, 63, 67, 74, 79], [8, 10, 11, 14, 28, 38, 40, 54, 63, 67, 71, 74, 79], [25, 44, 67, 71, 74, 76], [3, 8, 11, 24, 28, 40, 76, 79], [11, 15, 16, 22, 23, 25, 31, 39, 40, 44, 46, 54, 60, 74, 76, 79, 82, 86], [10, 11, 21, 25, 32, 45, 54, 59, 60, 67, 74, 75, 79], [3, 8, 10, 11, 25, 45, 67, 76, 82], [3, 17, 18, 25, 26, 27, 43, 45, 63, 67, 71, 74, 76, 79, 82, 84], [8, 14, 22, 28, 63, 78, 79, 80], [3, 7, 25, 67, 75, 82], [3, 7, 8, 14, 24, 43, 45, 54, 60, 63, 67, 71, 74, 79, 82], [17, 19, 24, 25, 28, 29, 33, 43, 55, 63, 67, 74, 79, 84], [3, 8, 17, 24, 25, 32, 33, 38, 40, 49, 60, 63, 67, 71, 74, 75, 79, 82], [24, 28, 29, 63, 70, 79], [8, 11, 14, 17, 24, 25, 28, 40, 43, 54, 63, 67, 74, 76, 79], [8, 24, 28, 41, 63, 67, 70, 79], [8, 17, 24, 28, 29, 41, 63, 70, 76], [11, 24, 40, 49, 63, 67, 79], [11, 14, 25, 76, 79], [8, 10, 11, 20, 25, 27, 28, 32, 45, 49, 60, 67, 71, 74, 79, 82], [0, 12, 26, 27, 32, 33, 42, 60, 72, 84], [3, 11, 24, 40, 49, 63, 67, 71, 74, 76, 79], [8, 14, 17, 24, 28, 29, 40, 41, 43, 54, 63, 67, 79], [8, 17, 24, 32, 41, 63, 67, 70, 74, 79], [8, 17, 24, 28, 29, 41, 63, 67, 70, 79], [0, 8, 17, 28, 42, 43, 45, 67, 79, 84], [3, 11, 25, 36, 54, 67, 74, 75, 76, 79, 82], [8, 11, 24, 28, 41, 43, 54, 57, 63, 67, 70, 79], [11, 17, 24, 25, 43, 54, 67, 76, 79], [0, 3, 10, 11, 25, 32, 33, 44, 60, 74, 76, 83, 84], [8, 17, 24, 28, 29, 41, 43, 45, 67, 71, 79], [11, 25, 27, 32, 33, 67, 84], [8, 17, 24, 28, 29, 41, 43, 57, 63, 67, 70, 79], [17, 28, 43, 67, 76], [3, 7, 9, 16, 29, 43, 44, 57, 60, 67, 69, 71, 74, 76, 79, 82, 83], [8, 11, 24, 28, 40, 67, 74, 79], [32, 54, 67, 69, 74, 79], [8, 24, 28, 29, 43, 63, 67, 70, 74, 79], [11, 25, 40, 54, 59, 74, 76, 82], [3, 10, 11, 24, 28, 40, 49, 54, 63, 67, 79], [8, 11, 14, 24, 28, 63, 67, 74, 79], [17, 18, 25, 26, 27, 40, 63, 67, 70, 73, 74, 79, 82], [12, 13, 21, 25, 27, 32, 33, 37, 44, 55, 60, 83, 84], [10, 11, 25, 38, 40, 49, 74, 79, 80], [3, 8, 10, 11, 17, 24, 25, 40, 41, 49, 63, 74, 79], [10, 11, 40, 54, 79], [12, 27, 30, 32, 33, 55, 83, 84], [8, 17, 25, 43, 63, 67, 69, 73, 74, 79], [3, 8, 12, 19, 21, 25, 26, 27, 33, 40, 43, 45, 60, 67, 71, 74, 75, 79, 82, 84], [8, 17, 24, 28, 41, 43, 54, 63, 67, 70, 79], [3, 11, 25, 43, 44, 57, 66, 67, 71, 74, 79, 82], [3, 8, 11, 14, 24, 25, 40, 43, 45, 54, 63, 76, 79], [8, 10, 11, 22, 24, 25, 38, 40, 41, 63, 70, 76, 79], [8, 25, 28, 43, 44, 63, 67, 74, 76, 79], [3, 8, 10, 17, 25, 32, 33, 40, 45, 49, 56, 60, 71, 74, 79, 82, 84], [9, 10, 11, 38, 40, 76, 80], [26, 27, 43, 63, 67, 84], [0, 4, 9, 12, 16, 27, 37, 44, 45, 60, 67, 72, 76, 82, 83], [43, 45, 57, 63, 67, 79], [8, 11, 17, 24, 28, 29, 41, 63, 67, 70, 79], [11, 63, 67, 76, 79], [3, 10, 11, 14, 22, 40, 54, 78, 79], [11, 40, 49, 75, 79], [10, 17, 24, 40, 44, 57, 63], [3, 8, 11, 24, 25, 28, 29, 43, 63, 67, 70, 79, 82], [7, 24, 28, 29, 41, 43, 63, 67, 79], [7, 14, 24, 54, 67, 79], [8, 11, 14, 22, 24, 41, 43, 54, 57, 63, 67, 70, 74, 79, 80], [11, 25, 40, 45, 67, 74, 76, 82], [8, 10, 11, 14, 24, 40, 54, 63, 67, 79], [10, 11, 22, 74, 76, 82], [8, 14, 22, 28, 43, 57, 63, 67, 79], [8, 11, 24, 40, 43, 60, 63, 67, 74, 79], [13, 16, 25, 37, 55, 63, 67, 74, 76, 79, 82], [8, 11, 24, 28, 40, 41, 63, 67, 79], [25, 67, 69, 71, 74, 79, 82, 84], [8, 28, 29, 41, 43, 63, 70, 79], [8, 11, 25, 26, 28, 33, 43, 60, 67, 71, 74, 79, 82, 84], [3, 8, 11, 17, 25, 28, 41, 43, 63, 67, 74, 75, 79], [3, 7, 11, 14, 25, 54, 63, 74, 75, 82], [10, 11, 44, 46, 76, 80], [3, 7, 8, 24, 63, 67, 78, 79], [3, 11, 25, 27, 32, 33, 40, 45, 54, 60, 67, 71, 74, 76, 79, 82, 84], [8, 24, 28, 40, 41, 43, 57, 63, 67, 70, 79], [3, 10, 11, 25, 38, 45, 49, 74], [14, 24, 41, 70, 79], [8, 11, 24, 28, 40, 41, 63, 67, 79], [0, 12, 26, 27, 32, 33, 55, 60, 68, 72, 84], [25, 26, 32, 67, 71, 74, 79], [3, 8, 17, 28, 41, 43, 57, 63, 70, 74, 79], [3, 11, 14, 24, 28, 37, 43, 57, 63, 67, 74, 76, 79, 82], [8, 11, 14, 24, 29, 43, 57, 63, 67, 70, 79], [8, 11, 24, 28, 40, 43, 57, 63, 67, 79], [7, 8, 10, 11, 24, 28, 29, 43, 63, 67, 74, 79], [7, 8, 10, 11, 17, 24, 25, 28, 40, 43, 54, 63, 67, 71, 74, 76, 78, 79, 82], [3, 8, 24, 25, 38, 40, 49, 63, 67, 71, 75, 79], [25, 32, 45, 60, 74, 82, 84], [3, 8, 24, 25, 28, 43, 45, 49, 60, 63, 67, 71, 74, 79, 82], [14, 29, 41, 54, 57], [8, 17, 24, 28, 29, 40, 43, 57, 63, 67, 74, 76, 79], [3, 7, 10, 25, 75, 79], [8, 17, 24, 28, 41, 43, 57, 63, 67, 79], [8, 28, 41, 43, 70, 79], [3, 11, 24, 40, 41, 70, 74, 75, 76, 78, 79], [3, 25, 45, 60, 71, 74, 82, 84], [11, 67, 74, 76, 79], [8, 10, 11, 14, 24, 25, 40, 63, 67, 70, 79], [8, 10, 11, 14, 54, 67, 70, 74, 76, 79], [10, 11, 40, 67, 74], [2, 8, 17, 25, 28, 40, 43, 45, 60, 63, 67, 74, 79, 82, 84], [10, 16, 45, 60, 74, 82], [0, 21, 25, 26, 27, 30, 32, 33, 45, 59, 60, 71, 72, 74, 82, 83, 84], [25, 26, 27, 82, 84], [8, 10, 11, 24, 28, 38, 43, 63, 67, 70, 79], [8, 11, 17, 24, 28, 63, 67, 79], [14, 43, 46, 76, 79], [0, 27, 32, 33, 45, 60, 67, 71, 72, 74, 76, 82, 84], [8, 13, 17, 28, 63, 67, 79], [3, 10, 14, 40, 43, 54, 79], [16, 25, 42, 69, 76, 82, 86], [11, 14, 22, 40, 54, 71, 76, 79], [3, 10, 11, 25, 40, 79], [3, 8, 11, 16, 24, 25, 32, 40, 49, 63, 67, 71, 79], [8, 22, 24, 28, 41, 43, 79], [8, 11, 17, 28, 41, 43, 44, 63, 70, 73, 76, 79, 86], [3, 8, 24, 28, 40, 41, 63, 67, 79], [3, 25, 28, 42, 45, 49, 60, 67, 71, 74, 75, 76, 79, 82], [11, 24, 38, 40, 43, 57], [8, 17, 18, 24, 28, 43, 63, 67, 70, 71, 73, 79], [9, 10, 11, 37, 71, 74, 82], [10, 11, 16, 17, 25, 43, 44, 54, 74, 76], [8, 17, 24, 28, 29, 41, 43, 63, 67, 79], [8, 11, 17, 24, 28, 29, 40, 41, 43, 54, 63, 70, 79], [8, 17, 24, 28, 29, 43, 54, 57, 63, 70, 74, 79], [3, 10, 11, 14, 22, 38, 40, 44, 49, 66, 67, 74, 78, 79, 80, 82], [8, 24, 28, 43, 44, 63, 67, 70, 79], [0, 12, 21, 24, 25, 26, 27, 32, 33, 45, 56, 60, 63, 67, 71, 74, 79, 82, 83, 84], [8, 24, 28, 40, 41, 43, 54, 63, 67, 70, 71, 74, 79], [8, 24, 29, 43, 57, 63, 67, 79], [8, 11, 17, 28, 41, 43, 63, 67, 70, 79], [43, 44, 63, 67, 79, 82], [8, 24, 28, 41, 57], [0, 12, 21, 26, 27, 30, 32, 33, 35, 45, 55, 72, 84], [25, 27, 32, 42, 60, 67, 71, 72, 74, 82], [8, 28, 43, 63, 67, 70, 74, 79], [11, 19, 32, 33, 44, 63, 67, 71, 74, 75, 79, 82, 84], [8, 14, 24, 28, 43, 54, 57, 63, 67, 70, 79], [7, 8, 11, 14, 24, 28, 40, 54, 63, 67, 75, 79], [7, 25, 40, 49, 63, 67, 70, 74, 79], [10, 11, 22, 25, 27, 32, 33, 67, 71, 72, 74, 82, 84], [8, 17, 24, 28, 29, 41, 67, 70, 79], [11, 14, 40, 54, 67, 79], [8, 11, 17, 18, 28, 37, 63, 79, 86], [8, 17, 24, 28, 31, 43, 63, 67, 74, 76], [3, 8, 25, 28, 40, 49, 63, 67, 70, 79], [8, 17, 24, 28, 41, 43, 63, 67, 70], [9, 10, 11, 40, 80], [25, 33, 67, 71, 74, 79, 82], [3, 10, 11, 17, 25, 40, 49, 59, 66, 67, 71, 74, 76, 79], [3, 7, 10, 11, 40, 54, 79], [3, 11, 25, 40, 49, 60, 74, 82], [8, 28, 40, 54, 63, 67, 79], [3, 10, 11, 14, 25, 40, 54, 78, 79], [0, 12, 25, 26, 27, 32, 33, 42, 45, 55, 59, 60, 67, 71, 72, 74, 82, 83, 84], [0, 26, 27, 32, 33, 55, 60, 67, 72, 84], [8, 13, 16, 24, 28, 41, 63, 67, 70, 75, 79], [32, 33, 45, 56, 84, 87], [25, 40, 45, 49, 60, 67, 74, 82], [23, 28, 40, 41, 75], [8, 17, 24, 28, 29, 41, 63, 67, 70, 79], [8, 24, 25, 28, 29, 40, 63, 67, 79], [2, 3, 9, 10, 11, 14, 16, 25, 37, 40, 44, 48, 65, 69, 71, 74, 76, 79, 80, 82], [24, 28, 29, 37, 41, 44, 63, 70, 79, 85, 86], [3, 8, 10, 17, 25, 28, 60, 63, 67, 71, 74, 75, 79, 82], [3, 10, 11, 14, 17, 24, 40, 43, 54, 67, 74, 76, 79], [8, 24, 28, 57, 63, 67, 74, 79], [3, 7, 10, 11, 25, 40, 67, 74, 79], [3, 11, 14, 22, 25, 40, 54, 60, 63, 67, 71, 74, 75, 79, 82], [3, 25, 32, 33, 40, 45, 49, 74, 75], [8, 24, 28, 43, 57, 70], [0, 21, 25, 27, 32, 33, 45, 60, 67, 74, 82, 84], [8, 17, 24, 29, 43, 63], [3, 24, 25, 28, 38, 43, 54, 63, 67, 71, 74, 76, 79, 82], [8, 25, 28, 29, 41, 57, 67, 74, 79], [3, 8, 11, 14, 40, 54, 67, 74, 79, 82], [8, 14, 40, 41, 49, 54, 63, 67, 79], [8, 24, 28, 41, 43, 63, 67, 70, 74, 79], [21, 26, 32, 33, 45, 67, 76, 84, 86], [8, 17, 24, 25, 28, 40, 41, 44, 63, 70, 79], [0, 12, 21, 25, 32, 33, 45, 59, 60, 74, 76, 82, 84], [0, 12, 33, 53, 80, 84], [43, 63, 67, 74, 79], [8, 28, 41, 43, 63, 79], [8, 11, 43, 67, 79], [17, 26, 27, 32, 33, 43, 45, 60, 67, 71, 74, 79, 82, 84], [3, 10, 25, 38, 40, 63, 66, 67, 74, 75, 79], [7, 8, 10, 11, 14, 40, 63, 67, 79], [0, 12, 27, 32, 33, 55, 72, 84], [3, 10, 25, 49, 60, 67, 71, 74, 79, 82], [9, 11, 16, 25, 44, 54, 76, 86], [0, 25, 26, 27, 32, 33, 45, 60, 74, 82, 83, 84], [44, 54, 67, 74, 79], [3, 8, 10, 25, 43, 63, 67, 75, 76, 79], [3, 9, 10, 11, 13, 17, 25, 27, 32, 33, 37, 38, 40, 44, 54, 60, 67, 71, 74, 75, 76, 79, 82, 84], [7, 8, 10, 24, 28, 29, 49, 54, 57, 63, 67, 70, 74, 79], [3, 21, 25, 27, 33, 40, 60, 67, 71, 74, 75, 76, 79, 82, 84], [3, 11, 16, 17, 24, 25, 38, 40, 43, 44, 63, 67, 74, 79], [0, 24, 27, 32, 33, 43, 63, 67, 79, 84, 86], [3, 10, 11, 25, 31, 40, 75], [25, 32, 33, 42, 45, 60, 67, 69, 71, 74, 76, 82, 83, 84, 86], [7, 8, 14, 24, 28, 41, 43, 57, 63, 67, 75, 76, 79], [3, 7, 8, 10, 11, 17, 25, 40, 54, 67, 71, 74, 75, 76, 79, 82], [25, 67, 74, 79, 82], [10, 25, 38, 40, 54, 57, 74], [7, 8, 40, 54, 67, 74, 79], [0, 12, 26, 27, 32, 33, 55, 72, 84], [10, 25, 27, 74, 76], [10, 11, 25, 74, 79], [8, 24, 28, 29, 41, 57, 63, 67, 79], [8, 13, 16, 17, 24, 28, 29, 37, 41, 44, 63, 67, 70, 76, 79], [0, 26, 32, 33, 35, 45, 55, 76, 84], [8, 10, 11, 14, 24, 28, 38, 40, 43, 54, 70, 79, 80], [8, 40, 54, 70, 79], [8, 28, 29, 41, 43, 57, 63, 70], [8, 17, 24, 28, 40, 43, 63, 67, 79], [8, 17, 24, 25, 28, 33, 54, 60, 63, 67, 70, 74, 79], [3, 7, 8, 57, 67, 74, 79, 82], [10, 11, 24, 28, 57, 63, 67, 79], [0, 25, 26, 35, 59, 71, 74, 76, 84], [3, 10, 11, 25, 40, 44, 74, 76, 82], [17, 25, 26, 27, 32, 33, 43, 45, 59, 60, 67, 71, 74, 76, 79, 82, 83, 84], [7, 10, 40, 71, 74, 75, 79], [7, 8, 10, 14, 24, 54, 76, 79], [8, 17, 24, 25, 28, 43, 63, 67, 70, 79], [3, 7, 8, 10, 11, 14, 28, 40, 41, 54, 70, 75, 79], [12, 25, 40, 47, 67, 74, 75, 76, 79, 84], [8, 24, 29, 41, 43, 63, 70, 79], [0, 12, 20, 25, 27, 32, 33, 42, 60, 72, 76, 83, 84], [11, 25, 32, 45, 54, 60, 67, 71, 74, 79], [11, 43, 57, 74, 80], [8, 11, 24, 28, 29, 41, 63, 67, 70, 76, 79, 86], [8, 17, 24, 28, 41, 43, 57, 67, 70, 74, 79], [14, 22, 40, 54, 67, 74, 76, 79], [3, 11, 24, 40, 57], [0, 2, 4, 16, 33, 37, 44, 76], [21, 32, 45, 56, 60, 74, 82, 83, 84], [7, 10, 11, 38, 40, 67, 74, 76, 80], [3, 24, 25, 28, 32, 41, 43, 45, 60, 67, 74, 79, 82], [10, 14, 54, 63, 79, 80], [7, 8, 24, 28, 41, 43, 63, 67, 74, 79], [11, 14, 17, 57, 67, 76, 79], [0, 9, 12, 16, 25, 37, 40, 45, 47, 72, 76, 80], [0, 6, 21, 25, 26, 27, 32, 33, 45, 55, 60, 67, 71, 72, 74, 76, 82, 83, 84], [21, 25, 26, 27, 33, 45, 55, 74, 82, 83, 87], [3, 7, 8, 10, 11, 25, 40, 74, 75, 76, 79], [3, 8, 25, 45, 49, 60, 63, 67, 74, 82], [3, 8, 10, 11, 24, 25, 28, 40, 43, 54, 63, 67, 74, 79], [3, 10, 11, 25, 27, 32, 33, 38, 40, 44, 45, 60, 67, 71, 74, 79, 82, 84], [2, 4, 11, 14, 22, 37, 44, 46, 76, 78, 80], [2, 24, 40, 41, 79], [8, 17, 28, 29, 41, 63, 79], [3, 11, 17, 25, 40, 63, 67, 74, 82], [3, 7, 8, 11, 63, 67, 79], [25, 33, 40, 45, 60, 67, 71, 72, 74, 75, 79, 82, 83, 84], [8, 17, 24, 25, 28, 43, 54, 63, 67, 74, 79], [3, 11, 22, 25, 38, 40, 60, 74, 76, 80], [25, 26, 27, 32, 38, 74, 82, 84], [11, 27, 37, 43, 67, 79, 82], [11, 17, 26, 27, 28, 32, 33, 43, 57, 67, 71, 76, 79], [8, 24, 28, 43, 63, 79], [7, 8, 11, 17, 25, 43, 45, 54, 60, 63, 67, 71, 74, 79, 82], [8, 11, 24, 32, 43, 45, 60, 63, 67, 74, 79, 82], [24, 28, 63, 67, 79], [8, 28, 43, 67, 79], [17, 43, 67, 71, 74, 79], [8, 17, 24, 28, 41, 43, 57, 63, 67, 70, 79], [8, 24, 28, 29, 40, 41, 43, 54, 63, 67, 70, 79], [11, 25, 26, 32, 33, 45, 59, 60, 66, 71, 74, 82], [8, 40, 43, 63, 67, 76, 79], [3, 10, 25, 45, 50, 60, 67, 71, 74, 75, 82, 84], [11, 24, 27, 33, 37, 67, 74, 79, 84], [8, 28, 63, 67, 79], [24, 29, 63, 67, 74, 79], [11, 25, 26, 27, 35, 55, 67, 71, 74, 82], [3, 7, 8, 10, 14, 24, 25, 40, 54, 63, 67, 71, 79], [11, 17, 40, 43, 45, 49, 60, 63, 79], [3, 8, 11, 14, 40, 49, 54, 67, 74, 79], [8, 24, 28, 63, 70, 79], [3, 11, 15, 25, 37, 38, 40, 54, 74, 76], [25, 40, 67, 71, 74, 79, 82], [3, 11, 14, 25, 38, 40, 54, 67, 74, 79, 82], [8, 17, 24, 41, 63, 67, 70, 79], [3, 8, 17, 43, 54, 74, 76, 82], [25, 32, 33, 45, 56, 60, 67, 74, 82, 84], [29, 43, 44, 57, 74, 79], [0, 12, 25, 26, 27, 32, 33, 59, 60, 71, 72, 74, 83, 84], [3, 8, 11, 14, 24, 40, 43, 49, 54, 57, 63, 67, 70, 74, 76, 78, 79, 82], [14, 24, 40, 54, 57, 79], [3, 8, 11, 24, 28, 40, 41, 59, 63, 67, 70, 79], [3, 8, 14, 24, 43, 63, 67, 74, 79, 82], [3, 7, 10, 11, 22, 28, 31, 33, 37, 45, 47, 59, 60, 63, 69, 71, 75, 79, 82, 84, 86], [8, 24, 43, 57, 67, 79], [8, 11, 24, 28, 29, 41, 63, 67, 70, 79], [10, 11, 14, 40, 54, 71, 75], [0, 12, 26, 27, 32, 33, 53, 55, 59, 72, 84], [3, 11, 14, 24, 25, 40, 41, 43, 54, 63, 67, 79], [3, 8, 11, 14, 24, 40, 54, 63, 67, 74, 79], [8, 10, 37, 41, 44, 63, 67, 70, 74, 79], [21, 25, 26, 27, 32, 33, 45, 55, 59, 60, 74, 76, 83, 84], [25, 26, 45, 59, 60, 67, 74, 82], [25, 26, 35, 74, 84], [8, 17, 24, 28, 29, 41, 43, 57, 63, 67, 70, 79], [4, 9, 21, 25, 27, 32, 33, 45, 49, 67, 76, 84], [0, 6, 12, 13, 16, 25, 27, 32, 33, 37, 44, 45, 60, 67, 72, 74, 82], [0, 11, 12, 14, 25, 26, 27, 32, 33, 35, 45, 54, 59, 60, 67, 72, 74, 79, 84], [3, 8, 10, 11, 14, 25, 31, 40, 54, 67, 74, 75, 79, 82], [3, 25, 67, 71, 74, 79], [3, 10, 11, 12, 17, 20, 22, 25, 26, 27, 32, 33, 43, 45, 54, 55, 59, 60, 63, 67, 71, 74, 76, 79, 82, 84], [0, 11, 17, 18, 25, 26, 27, 32, 33, 45, 55, 59, 60, 67, 71, 72, 74, 76, 79, 82, 84], [8, 17, 24, 25, 28, 29, 41, 43, 45, 60, 63, 67, 70, 74, 82, 83], [3, 10, 25, 38, 40, 76], [8, 17, 24, 28, 41, 63, 67, 79], [8, 11, 17, 24, 28, 41, 63, 67, 70, 79], [12, 26, 27, 32, 33, 53, 55, 60, 72, 83, 84], [3, 10, 25, 60, 67, 71, 74, 79, 82], [8, 10, 11, 24, 28, 29, 41, 57, 63, 67, 70, 78, 79], [7, 11, 14, 24, 29, 54, 63, 67, 74, 79], [0, 3, 11, 17, 25, 26, 31, 33, 35, 43, 45, 51, 55, 60, 67, 74, 82, 83, 84], [8, 17, 24, 28, 29, 41, 43, 45, 63, 67, 70, 79], [3, 8, 28, 40, 41, 49, 63, 70], [7, 8, 17, 25, 27, 33, 43, 45, 54, 60, 63, 67, 71, 74, 79, 82, 84], [0, 3, 21, 25, 27, 32, 33, 45, 60, 67, 71, 74, 79, 82, 83, 84], [8, 63, 67, 74, 75, 76, 79, 80], [8, 17, 24, 25, 43, 45, 60, 63, 67, 74, 79, 82], [8, 11, 24, 28, 29, 41, 43, 57, 63, 70, 75, 79], [3, 11, 14, 38, 79], [0, 42, 45, 54, 67, 71, 72, 74, 82, 84], [11, 14, 40, 57, 67, 74, 79, 80], [8, 12, 17, 28, 32, 33, 45, 49, 60, 62, 67, 74, 75, 79, 82], [7, 8, 17, 24, 28, 41, 63, 67, 79], [3, 11, 25, 27, 33, 40, 49, 54, 59, 69, 82], [21, 25, 27, 32, 33, 45, 60, 62, 67, 69, 74, 76, 82, 83, 84, 86], [3, 8, 25, 40, 60, 63, 67, 71, 74, 76, 79, 82], [8, 25, 28, 63, 67, 74, 79], [3, 10, 11, 14, 24, 40, 54, 79], [0, 26, 27, 32, 33, 35, 45, 59, 60, 74, 84], [8, 28, 29, 41, 63, 70], [28, 29, 67, 78, 79], [8, 11, 14, 24, 25, 28, 37, 40, 54, 63, 67, 74, 79], [8, 14, 29, 41, 43, 49, 54, 70, 79], [3, 11, 14, 44, 54, 74, 76, 79, 82], [3, 8, 10, 11, 14, 24, 25, 43, 44, 54, 57, 59, 67, 71, 74, 76, 79], [0, 9, 12, 26, 27, 32, 33, 45, 60, 67, 71, 72, 74, 79, 84, 86], [3, 10, 11, 14, 54, 76, 79], [8, 24, 43, 67, 79], [3, 10, 11, 40, 49], [2, 8, 14, 24, 43, 54, 63, 76], [0, 3, 7, 8, 11, 12, 17, 21, 24, 25, 26, 27, 28, 29, 32, 33, 37, 43, 44, 45, 55, 59, 60, 63, 67, 71, 72, 74, 75, 79, 82, 83, 84, 86], [16, 37, 63, 67, 79], [2, 5, 13, 16, 37, 44], [8, 17, 24, 28, 41, 57, 63, 67, 70, 74, 79], [44, 67, 74, 76, 79, 82], [12, 25, 27, 32, 33, 44, 45, 60, 67, 74, 76, 82, 83, 84, 86], [8, 40, 63, 70, 75, 79], [11, 28, 38, 40, 50, 78, 79], [17, 25, 27, 32, 33, 40, 43, 45, 60, 67, 71, 74, 76, 79, 82, 84], [8, 17, 28, 43, 73, 79], [3, 5, 10, 11, 25, 45, 60, 67, 74, 80, 82, 83], [25, 27, 44, 60, 67, 69, 82, 84], [3, 11, 40, 63, 67, 74, 79], [8, 11, 43, 54, 63, 67, 74, 79], [8, 24, 29, 54, 63, 70, 76, 79], [17, 41, 67, 76, 80], [14, 25, 26, 32, 43, 45, 54, 60, 67, 74, 79, 82, 84], [8, 11, 13, 16, 17, 24, 28, 29, 37, 41, 44, 63, 67, 70, 74, 76, 79], [25, 40, 54, 74, 76, 82], [8, 28, 29, 41, 43, 70, 79], [12, 26, 32, 33, 53, 59, 84], [7, 11, 17, 24, 25, 40, 43, 54, 63, 67, 75, 79, 80], [8, 14, 24, 28, 41, 54, 63, 67, 70, 79], [8, 11, 17, 25, 74, 76, 79], [3, 11, 25, 43, 60, 66, 71, 74, 82], [8, 24, 29, 63, 67, 74, 79], [3, 11, 14, 24, 25, 40, 54, 57, 63, 67, 79], [11, 40, 67, 71, 79], [8, 11, 14, 17, 18, 24, 28, 37, 40, 41, 43, 54, 63, 67, 70, 79], [6, 25, 26, 32, 33, 45, 53, 55, 56, 60, 67, 71, 84], [11, 22, 38, 40, 54], [0, 10, 25, 26, 27, 31, 32, 45, 60, 67, 69, 72, 74, 82, 83, 84], [14, 54, 67, 74, 79], [11, 25, 32, 33, 55, 60, 74, 82, 84, 86], [3, 8, 10, 11, 14, 24, 28, 29, 41, 43, 54, 63, 70, 74, 76, 79], [3, 10, 11, 14, 25, 40, 49, 67, 74, 76, 79], [8, 17, 28, 41, 43, 67, 70, 79], [7, 8, 17, 24, 25, 28, 41, 43, 63, 67, 70, 79], [8, 24, 63, 67, 79], [8, 9, 13, 16, 37, 40, 63, 67, 74, 79], [32, 43, 60, 67, 71, 72, 74, 79, 82], [6, 17, 21, 32, 45, 60, 71, 74, 82, 84], [0, 12, 25, 32, 45, 60, 67, 72, 74, 82, 84], [8, 17, 43, 54, 63, 67, 79], [8, 28, 29, 41, 63, 67, 70, 79], [8, 11, 14, 17, 24, 43, 54, 57, 63, 67, 74, 79], [3, 7, 8, 10, 11, 14, 17, 22, 24, 28, 29, 38, 40, 49, 54, 63, 67, 71, 74, 75, 76, 79], [8, 17, 24, 40, 43, 54, 57, 63, 67, 79], [3, 8, 10, 11, 14, 22, 38, 40, 57, 63, 74, 75, 76, 78, 79], [0, 12, 25, 27, 32, 33, 45, 60, 67, 72, 74, 82, 84], [3, 4, 41, 43, 44, 63, 67, 76, 79], [3, 10, 11, 38, 40, 79], [8, 24, 29, 40, 70, 79], [10, 25, 37, 67, 76], [8, 17, 28, 41, 43, 54, 63, 67, 70, 79], [6, 12, 32, 45, 53, 60, 67, 74, 76, 79, 82, 84], [10, 11, 14, 38, 40, 54, 67, 78, 79], [3, 10, 11, 25, 26, 27, 33, 45, 49, 56, 60, 67, 71, 74, 75, 76, 82, 83, 84], [3, 8, 10, 11, 14, 17, 22, 24, 29, 40, 41, 43, 54, 57, 63, 74, 79], [3, 8, 24, 25, 28, 40, 43, 49, 63, 67, 70, 71, 79, 82], [8, 17, 24, 29, 41, 43, 57, 63, 67, 73, 79], [3, 7, 11, 40, 49, 54, 67, 75, 79, 82], [3, 10, 11, 14, 40, 54, 60, 67, 74, 82], [8, 10, 11, 25, 63, 67, 71, 74, 79, 82], [11, 14, 22, 43, 50, 67, 76, 78, 86], [0, 11, 12, 25, 26, 33, 40, 44, 49, 67, 74, 76, 79, 82], [11, 24, 38, 40, 57, 67, 79], [8, 17, 28, 43, 45, 63, 67, 70, 79], [8, 14, 17, 24, 28, 29, 41, 43, 57, 63, 67, 70, 79], [0, 9, 12, 26, 32, 33, 35, 51, 59, 72, 73, 83, 84], [11, 25, 27, 32, 33, 45, 60, 67, 71, 74, 82, 84], [3, 8, 10, 11, 17, 24, 28, 29, 40, 43, 54, 63, 67, 76], [8, 17, 18, 24, 25, 28, 43, 63, 67, 70, 74, 79], [9, 11, 16, 22, 44, 65, 76, 80], [8, 11, 24, 25, 28, 40, 41, 43, 63, 67, 74, 79], [8, 17, 28, 41, 43, 63, 67, 70, 79], [8, 24, 28, 29, 43, 57, 63, 67, 70, 74, 76, 79], [6, 26, 27, 32, 33, 35, 55, 72, 84], [8, 24, 28, 29, 37, 43, 63, 67, 70], [7, 11, 25, 40, 50, 54, 71, 75, 79], [7, 11, 15, 43, 54, 67, 71, 79], [26, 27, 32, 33, 60, 84], [3, 7, 25, 27, 33, 45, 60, 67, 82, 84], [7, 8, 40, 54, 79], [16, 25, 32, 37, 44, 60, 67, 71, 74, 76, 82], [11, 14, 38, 40, 54, 74, 78], [8, 16, 28, 37, 63, 76], [10, 11, 14, 25, 67, 74, 79], [3, 11, 16, 44, 76], [10, 11, 14, 25, 37, 40, 54, 67, 76, 79], [8, 17, 43, 54, 63, 67, 71, 74, 79, 82, 84], [3, 10, 11, 25, 40, 45, 49, 54, 67, 71, 75, 79, 82], [40, 67, 74, 76, 84], [3, 25, 30, 43, 54, 56, 67, 74, 76, 79, 82], [0, 3, 8, 9, 10, 21, 25, 26, 27, 32, 33, 40, 43, 45, 60, 62, 67, 74, 76, 79, 82, 83, 84], [11, 24, 38, 54, 63, 67, 74, 79], [3, 8, 16, 17, 19, 24, 25, 26, 28, 33, 44, 72, 76, 84], [8, 10, 40, 49, 60, 67, 74, 75, 79, 82], [0, 3, 7, 17, 21, 25, 26, 27, 30, 32, 33, 40, 43, 45, 49, 54, 55, 59, 60, 67, 71, 72, 74, 75, 79, 82, 83, 84], [3, 10, 11, 25, 76], [7, 8, 28, 29, 57, 63, 70], [8, 14, 24, 40, 79], [3, 7, 8, 10, 11, 17, 24, 25, 28, 40, 41, 49, 54, 63, 67, 70, 79], [7, 10, 16, 17, 25, 27, 42, 67, 69, 76, 82], [11, 12, 21, 25, 32, 33, 45, 67, 74, 84], [0, 12, 25, 26, 27, 32, 33, 35, 59, 60, 72, 82, 84], [7, 25, 29, 43, 45, 67, 74], [3, 25, 27, 32, 33, 40, 45, 49, 60, 74, 82, 84], [7, 8, 10, 14, 29, 40, 54, 76, 79], [0, 12, 26, 32, 33, 83, 84], [8, 17, 24, 28, 29, 41, 43, 63, 70, 79], [1, 2, 9, 13, 20, 34, 37, 76, 80], [25, 27, 32, 45, 60, 67, 82, 84], [8, 14, 29, 54, 63, 67], [25, 60, 67, 71, 74, 82, 84], [8, 24, 28, 41, 43, 63, 67, 70, 79], [0, 3, 11, 12, 17, 21, 25, 26, 27, 32, 33, 40, 42, 45, 60, 66, 67, 71, 72, 74, 82, 84, 86], [3, 7, 10, 11, 54, 67, 74, 79], [8, 24, 29, 57, 79], [8, 24, 63, 67, 76, 79], [0, 6, 25, 27, 32, 33, 60, 67, 72, 74, 82, 83, 84, 87], [17, 19, 20, 25, 26, 27, 32, 33, 43, 44, 55, 56, 59, 60, 67, 72, 76, 79, 82, 83, 84], [8, 11, 25, 38, 40, 67, 71, 74], [17, 25, 32, 33, 43, 44, 45, 67, 71, 74, 76, 79, 82, 83, 84], [50, 54, 59, 76, 79], [8, 24, 28, 40, 41, 43, 54, 63, 67, 70, 79], [8, 11, 24, 28, 40, 41, 63, 67, 70, 79], [8, 11, 17, 25, 43, 45, 54, 60, 63, 67, 71, 74, 79, 82], [0, 25, 26, 32, 33, 45, 59, 60, 67, 74, 82, 84], [0, 1, 12, 25, 27, 32, 33, 42, 44, 45, 60, 72, 74, 76, 82, 83, 84], [8, 17, 28, 29, 40, 41, 43, 56], [8, 11, 17, 24, 28, 29, 43, 57, 67, 79], [3, 24, 40, 41, 49, 74, 79], [8, 24, 28, 29, 41, 63, 67, 79], [14, 24, 25, 32, 43, 45, 54, 60, 67, 71, 74, 76, 79, 82], [8, 28, 54, 57, 67, 74, 79], [8, 24, 29, 41, 63, 67, 70, 79], [8, 11, 16, 17, 24, 25, 28, 38, 41, 43, 44, 63, 67, 74, 76, 79, 82], [8, 24, 63, 67, 79], [3, 10, 11, 12, 17, 20, 22, 25, 26, 27, 32, 33, 43, 45, 54, 55, 59, 60, 63, 67, 71, 74, 76, 79, 82, 84], [0, 20, 55, 68, 84], [11, 38, 40, 66, 74, 79], [14, 24, 40, 79, 80], [8, 24, 29, 63, 67, 79], [3, 7, 8, 11, 14, 40, 49, 63, 67, 75, 79], [3, 8, 10, 11, 14, 24, 25, 40, 49, 54, 63, 70, 71, 79], [7, 9, 10, 13, 16, 20, 25, 44, 46, 74, 75, 76, 80, 82], [0, 21, 25, 27, 32, 33, 40, 45, 60, 67, 71, 72, 74, 82, 83, 84], [3, 8, 11, 24, 25, 28, 29, 41, 45, 49, 60, 62, 63, 67, 70, 74, 75, 79, 82], [10, 11, 24, 25, 40, 63, 67, 76, 79], [0, 12, 13, 16, 25, 42, 72, 82, 84], [10, 11, 25, 40, 54, 74, 75, 79], [59, 60, 74, 82, 84], [0, 6, 25, 26, 27, 32, 33, 45, 60, 67, 71, 72, 74, 83, 84], [8, 24, 28, 41, 63, 67, 70, 79], [3, 7, 10, 11, 76, 78], [17, 24, 25, 32, 33, 43, 67, 71, 72, 74, 79], [3, 8, 10, 14, 24, 28, 63, 67, 71, 74, 76, 79], [8, 17, 24, 28, 41, 43, 63, 67, 70, 79], [0, 12, 26, 32, 33, 35, 59, 72, 74, 84], [8, 17, 24, 28, 41, 43, 63, 67, 70, 71, 74, 79], [0, 3, 12, 13, 16, 20, 25, 27, 30, 32, 33, 37, 42, 44, 45, 60, 67, 69, 71, 72, 73, 74, 82, 83, 84], [8, 11, 14, 24, 28, 54, 63, 67, 79], [4, 8, 43, 57, 74, 76, 79], [25, 32, 43, 45, 57, 60, 67, 69, 71, 74, 82], [12, 25, 27, 32, 33, 35, 55, 56, 59, 60, 67, 68, 71, 74, 82, 84], [3, 7, 10, 40, 54, 74, 76, 79], [10, 11, 40, 75, 80], [17, 43, 45, 60, 63, 67, 79, 82], [8, 12, 17, 18, 24, 25, 41, 43, 63, 67, 73, 74, 79, 86], [7, 8, 10, 11, 24, 28, 29, 38, 57, 63, 74, 79], [24, 28, 41, 70, 79], [0, 21, 25, 26, 27, 54, 59, 60, 82, 84], [0, 3, 21, 26, 33, 45, 55, 60, 67, 72, 82, 84], [26, 27, 32, 33, 37, 45, 55, 60, 63, 67, 74, 79, 82, 84], [8, 28, 38, 40, 41, 49, 63, 70, 79], [10, 11, 14, 24, 54, 57, 74, 78, 79], [10, 25, 45, 49, 74, 75, 80, 82], [8, 17, 40, 67, 71], [8, 24, 28, 29, 43, 63, 67, 70, 79], [0, 12, 21, 26, 27, 30, 32, 33, 72, 74, 83, 84], [17, 24, 28, 41, 43, 63, 67, 70], [8, 28, 43, 63, 67, 79], [8, 10, 11, 14, 76, 79, 80], [3, 10, 11, 25, 26, 45, 54, 60, 67, 71, 74, 76, 82, 84], [3, 7, 8, 10, 25, 28, 40, 63, 67, 79], [8, 10, 11, 24, 25, 37, 44, 63, 67, 79, 82], [25, 27, 44, 45, 60, 67, 71, 74, 76, 79, 82], [8, 22, 24, 28, 63, 79], [3, 10, 11, 14, 22, 25, 38, 40, 49, 54, 60, 74, 79, 82], [8, 11, 14, 17, 24, 28, 40, 41, 43, 49, 63, 67, 76, 79], [7, 10, 11, 28, 40, 63, 67, 74, 79, 82, 86], [10, 11, 16, 17, 25, 27, 32, 33, 40, 44, 60, 67, 71, 74, 79, 82], [7, 25, 40, 54, 74, 75, 76], [3, 8, 24, 43, 49, 75], [8, 17, 25, 43, 54, 63, 67, 71, 74, 79], [3, 11, 28, 41, 43, 76, 79], [7, 10, 11, 12, 16, 22, 25, 37, 44, 64, 69, 71, 72, 74, 75, 76, 80, 82, 84], [0, 12, 26, 27, 33, 35, 53, 55, 72, 84], [0, 30, 32, 33, 60, 67, 72, 74, 79, 82, 84], [0, 11, 12, 25, 26, 27, 32, 33, 40, 54, 67, 72, 74, 79, 82, 84], [11, 25, 27, 32, 33, 38, 45, 60, 62, 67, 69, 74, 76, 82, 83, 84], [25, 26, 27, 32, 33, 45, 49, 56, 60, 67, 71, 74, 82, 84], [3, 10, 11, 38, 40, 54, 67, 74, 79], [17, 24, 25, 43, 63, 67, 79], [11, 17, 18, 24, 25, 28, 38, 40, 43, 57, 63, 67, 71, 74, 75, 79], [17, 28, 29, 43, 63, 67, 78, 79, 86], [8, 14, 17, 24, 28, 29, 40, 54, 63, 67, 79], [3, 11, 24, 25, 40, 43, 45, 60, 63, 67, 71, 74, 79, 82], [3, 8, 10, 11, 25, 40, 49, 67, 74, 79, 80, 82], [8, 17, 24, 25, 28, 29, 41, 43, 63, 67, 70, 71, 74, 79], [7, 8, 11, 28, 43, 67, 74, 79], [10, 45, 60, 67, 71, 74, 79, 82], [8, 17, 28, 41, 43, 63, 71], [11, 20, 40, 49, 63, 67, 71, 74, 79], [8, 11, 17, 24, 25, 40, 43, 63, 67, 70, 74, 76, 79], [8, 10, 11, 24, 28, 54, 57, 63, 70, 74, 79, 82], [3, 10, 25, 40, 71, 74, 76, 79, 86], [11, 14, 40, 54, 76, 78, 79], [25, 26, 27, 32, 33, 43, 44, 55, 60, 67, 72, 74, 76, 79, 82, 83, 84], [7, 8, 10, 11, 24, 25, 28, 67, 79], [17, 44, 67, 74, 83], [3, 8, 10, 11, 43, 67, 74, 79], [8, 25, 28, 49, 63, 67, 74, 79, 82], [3, 8, 10, 11, 24, 28, 63, 67, 76, 79], [12, 25, 26, 27, 32, 33, 45, 60, 63, 67, 71, 74, 79, 82, 84], [20, 46, 54, 58, 71, 74, 76], [8, 11, 17, 28, 29, 41, 43, 63, 79], [2, 11, 16, 37, 44, 76, 80], [8, 25, 26, 27, 29, 32, 33, 43, 45, 60, 67, 74, 79, 83, 84], [3, 20, 25, 43, 54, 69, 82], [8, 22, 24, 28, 29, 40, 41, 63, 67, 71, 74, 79], [0, 10, 13, 16, 25, 26, 40, 44, 45, 60, 67, 74, 82], [0, 12, 25, 26, 27, 32, 33, 44, 45, 60, 72, 74, 83, 84], [0, 25, 26, 45, 60, 67, 74, 84], [8, 24, 28, 29, 41, 43, 57, 63, 67, 79], [17, 18, 25, 43, 63, 67, 71, 73, 74, 79], [3, 7, 10, 11, 14, 25, 40, 43, 49, 54, 74, 75, 79, 82], [3, 8, 11, 14, 24, 25, 43, 54, 60, 63, 67, 74, 79, 82], [3, 8, 11, 17, 21, 25, 27, 28, 32, 33, 45, 49, 60, 67, 74, 75, 76, 79, 82, 84], [8, 17, 18, 24, 28, 29, 41, 43, 45, 60, 63, 67, 70, 74, 79, 82], [12, 21, 26, 27, 32, 45, 60, 62, 67, 79, 84], [7, 8, 10, 11, 28, 29, 63, 79, 80], [7, 17, 24, 25, 37, 40, 43, 67, 71, 74, 79], [8, 10, 14, 24, 38, 57, 60, 63, 66, 67, 71, 74, 79, 82], [3, 11, 16, 17, 20, 28, 44], [8, 24, 41, 43, 63, 67, 70, 74, 79], [8, 24, 29, 41, 43, 70], [11, 43, 67, 69, 74, 79], [8, 24, 28, 29, 40, 41, 57, 63, 70, 74, 79], [10, 11, 14, 24, 25, 40, 44, 54, 63, 67, 76, 79], [3, 11, 25, 37, 43, 45, 49, 59, 60, 67, 74, 76, 82, 84], [8, 10, 14, 24, 28, 29, 40, 54, 63, 70, 79], [3, 7, 11, 40, 75, 79], [0, 12, 25, 26, 27, 32, 33, 45, 59, 60, 72, 74, 82, 84], [24, 29, 54, 63, 67, 71, 78, 79], [6, 27, 35, 45, 54, 55, 60], [57, 63, 67, 74, 79], [8, 11, 14, 24, 28, 40, 41, 54, 63, 67, 70, 74, 79], [3, 8, 11, 24, 28, 38, 40, 43, 49, 63, 67, 70, 74, 79], [8, 24, 28, 41, 63, 70, 79], [3, 21, 25, 32, 43, 45, 60, 67, 74, 82, 84], [11, 40, 67, 76, 79], [8, 24, 43, 54, 57, 63, 79], [25, 27, 33, 83, 84], [12, 16, 27, 32, 33, 53, 67, 72, 83, 84], [13, 14, 16, 37, 41, 44, 54, 76, 79], [8, 43, 67, 70, 79], [8, 17, 24, 28, 57, 63, 67, 74, 79], [11, 25, 26, 27, 32, 33, 35, 45, 59, 60, 67, 74, 82, 84], [8, 10, 11, 14, 24, 40, 54, 63, 79], [11, 12, 22, 24, 26, 27, 33, 63, 67, 74, 79, 84], [8, 29, 54, 63, 79], [3, 4, 11, 13, 16, 17, 18, 25, 27, 43, 48, 67, 73, 74, 76, 80, 82], [27, 33, 49, 67, 71, 74, 82], [0, 9, 12, 21, 25, 27, 32, 33, 38, 43, 44, 55, 60, 67, 76, 80, 83, 84], [3, 8, 11, 14, 22, 28, 40, 41, 43, 54, 57, 63, 79], [3, 7, 8, 11, 24, 40, 63, 74, 75, 79], [8, 24, 28, 29, 41, 63, 79], [22, 24, 28, 29, 40, 67, 79], [3, 8, 11, 17, 24, 28, 29, 41, 43, 57, 67, 70, 79], [3, 21, 25, 27, 37, 45, 49, 60, 67, 74, 75, 82, 84], [8, 67, 74, 76, 79, 82], [10, 14, 22, 40, 54, 67, 79, 80], [4, 11, 16, 44, 76, 80], [3, 17, 25, 27, 32, 43, 45, 60, 67, 71, 74, 76, 82, 83, 84], [3, 7, 10, 11, 14, 25, 40, 67, 74, 79, 82], [24, 28, 41, 43, 63, 67, 70, 79], [3, 17, 41, 43, 54, 63, 67, 79], [3, 8, 10, 14, 25, 40, 43, 54, 63, 67, 76, 79], [0, 12, 26, 27, 33, 35, 59, 72, 84], [3, 4, 10, 11, 25, 50, 66, 76], [8, 17, 43, 44, 45, 67, 71, 76, 82], [17, 25, 28, 29, 41, 43, 45, 54, 60, 63, 67, 70, 74, 82], [3, 10, 11, 25, 38, 40, 57, 67, 71, 74, 76, 82], [8, 25, 26, 28, 41, 43, 63, 67, 70, 74, 79], [10, 24, 57, 76, 86], [11, 25, 45, 49, 54, 56, 60, 74, 82], [0, 7, 25, 37, 67, 71, 72, 74, 76, 79], [22, 25, 32, 33, 60, 74, 76, 84], [7, 8, 29, 63, 67, 74, 79], [3, 8, 11, 17, 24, 25, 41, 43, 63, 67, 71, 74, 76, 79, 82], [9, 12, 25, 26, 27, 32, 33, 45, 59, 72], [11, 25, 27, 32, 33, 60, 67, 72, 74, 82], [8, 9, 10, 24, 28, 29, 57, 79], [12, 26, 27, 32, 33, 35, 55, 60, 72, 83, 84], [0, 32, 33, 45, 60, 67, 72, 74, 76, 82, 84], [8, 11, 17, 24, 28, 43, 63, 67, 70, 79], [3, 11, 14, 24, 40, 43, 67, 76, 78, 79], [17, 21, 25, 27, 32, 33, 43, 45, 54, 56, 60, 67, 74, 79, 82, 83, 84], [11, 14, 24, 63, 67, 74, 79], [21, 25, 26, 27, 32, 33, 45, 60, 67, 71, 82, 84], [8, 43, 57, 63, 67, 79], [3, 11, 25, 40, 49, 63, 67, 74, 75, 79, 82], [8, 17, 24, 28, 43, 63, 67, 79], [3, 11, 14, 40, 54, 63, 78, 79], [25, 27, 32, 33, 37, 44, 60, 69, 74, 76, 82, 84], [6, 26, 27, 56, 60, 71, 74, 84], [10, 11, 25, 37, 74, 76, 82], [7, 8, 10, 11, 24, 28, 29, 40, 41, 43, 49, 67, 70, 79], [8, 17, 24, 28, 29, 41, 43, 44, 60, 63, 67, 70, 74, 76, 79, 82], [8, 17, 24, 43, 67, 79], [3, 10, 11, 21, 25, 67, 71, 74, 75, 82], [8, 11, 23, 28, 38, 63], [8, 17, 18, 24, 25, 28, 32, 33, 43, 45, 60, 63, 67, 71, 74, 79, 82], [11, 26, 32, 33, 56, 60, 74, 82], [8, 12, 27, 32, 40, 45, 60, 63, 67, 74, 79, 82, 83, 84], [25, 67, 71, 74, 82, 84], [8, 10, 11, 24, 25, 28, 38, 40, 41, 43, 54, 60, 63, 67, 71, 74, 76, 79, 82], [3, 25, 40, 49, 63, 67, 71, 79, 82], [0, 13, 16, 26, 27, 32, 33, 35, 45, 59, 60, 72, 76, 83, 84], [7, 11, 14, 24, 28, 40, 57, 67, 75, 79], [8, 25, 27, 32, 33, 40, 45, 60, 67, 71, 74, 79, 82, 84], [12, 27, 32, 33, 60, 67, 84], [7, 8, 24, 29, 40, 57, 63, 67, 79], [21, 27, 32, 33, 67, 82, 84], [3, 10, 11, 25, 40, 43, 45, 49, 54, 67, 74, 75, 79, 82], [7, 8, 17, 22, 24, 43, 63, 67, 76, 79, 86], [11, 17, 21, 24, 25, 37, 40, 43, 45, 60, 63, 67, 71, 74, 79, 82], [10, 11, 17, 25, 27, 28, 33, 45, 48, 63, 67, 74], [17, 25, 37, 45, 60, 63, 67, 74, 79, 82], [24, 29, 57, 67, 74, 79], [0, 12, 21, 25, 27, 32, 33, 45, 60, 72, 82, 84], [8, 10, 11, 14, 40, 54, 63, 78, 79], [12, 27, 32, 33, 59, 60, 63, 67, 74, 79, 83, 84], [3, 10, 11, 22, 50, 76, 78, 86], [9, 11, 37, 40, 76, 80], [11, 14, 17, 24, 28, 40, 41, 43, 54, 63, 67, 70, 74, 79], [8, 24, 28, 63, 67, 70, 79], [21, 25, 26, 27, 32, 33, 45, 60, 67, 71, 74, 84], [32, 45, 60, 74, 76, 82], [8, 10, 11, 14, 24, 29, 40, 41, 43, 54, 63, 67, 74, 79], [0, 12, 33, 45, 67, 72, 76, 84], [25, 33, 45, 71, 74, 82], [25, 44, 60, 67, 76, 83], [11, 44, 46, 76, 86], [21, 30, 32, 59, 84, 86], [8, 11, 17, 25, 28, 30, 45, 60, 67, 74, 75, 79], [9, 10, 11, 25, 40, 54, 56], [8, 40, 41, 67, 74, 79], [25, 26, 27, 32, 60, 67, 71, 72, 74, 82], [3, 11, 25, 49, 66, 74, 82], [10, 14, 24, 28, 40, 54, 67, 78, 79], [8, 11, 14, 24, 40, 54, 67, 74, 79], [9, 16, 17, 37, 43, 44, 45, 63, 67, 71, 74, 75, 76, 79, 84], [3, 14, 25, 60, 67, 71, 74, 76, 79, 82], [25, 27, 32, 33, 45, 60, 74, 82, 84], [3, 10, 11, 38, 66], [8, 17, 24, 28, 29, 41, 43, 57, 63, 70, 79], [8, 25, 43, 45, 63, 67, 71, 74, 76, 79, 82], [11, 14, 24, 29, 43, 54, 67, 79], [10, 11, 40, 54, 79], [10, 41, 43, 57, 67, 74, 76], [11, 25, 33, 49, 67, 74, 79, 80, 82], [22, 24, 49, 67, 71, 74, 79], [8, 24, 28, 43, 63], [8, 17, 24, 28, 29, 41, 63, 67, 70, 74, 79], [3, 7, 11, 71, 75, 76, 78, 79], [7, 8, 17, 25, 28, 43, 63, 67, 71, 79], [3, 7, 57, 75, 79], [3, 11, 25, 26, 27, 32, 33, 40, 45, 54, 60, 71, 74, 79, 82, 84], [3, 8, 11, 14, 40, 43, 54, 63, 67, 74, 76, 79], [11, 24, 28, 40, 41, 67, 70, 75], [3, 11, 25, 54, 63, 67, 74, 79], [8, 24, 25, 28, 41, 63, 67, 70, 76, 79], [8, 17, 24, 28, 41, 54, 63, 67, 76, 79], [10, 29, 74, 76, 79], [10, 11, 14, 38, 40, 54, 57, 79], [40, 43, 54, 67, 79, 84], [0, 26, 32, 33, 35, 45, 60, 61, 72, 84], [3, 11, 40, 49, 60, 63, 67, 74, 79, 82], [0, 17, 25, 26, 27, 32, 33, 37, 43, 45, 60, 67, 71, 76, 82, 84], [9, 16, 26, 32, 33, 43, 55, 76, 80, 83, 84], [3, 25, 43, 74, 79, 82], [3, 8, 24, 28, 41, 49, 67, 70, 79], [8, 14, 17, 24, 28, 41, 43, 63, 67, 70], [8, 11, 24, 63, 70, 79], [3, 8, 11, 17, 26, 35, 38, 43, 44, 55, 63, 70, 71, 76, 80, 82, 83]]\n"
     ]
    }
   ],
   "source": [
    "following_true = [0]*len(user_following)\n",
    "for i in range(len(user_following)):\n",
    "    each_user = []\n",
    "    for j in range(len(user_following[i])):\n",
    "        if user_following[i][j] == 1:\n",
    "            each_user.append(j)\n",
    "    following_true[i] = each_user\n",
    "print(following_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followings  5\n",
      "Max number of followings  34\n"
     ]
    }
   ],
   "source": [
    "#following \n",
    "minlen = 10000\n",
    "maxlen = 0\n",
    "num_of_follower = []\n",
    "for i in range(len(following_true)):\n",
    "    if len(following_true[i]) < minlen:\n",
    "        minlen = len(following_true[i])\n",
    "    if len(following_true[i]) > maxlen:\n",
    "        maxlen = len(following_true[i])\n",
    "    num_of_follower.append(len(following_true[i]))\n",
    "print('Min number of followings ',minlen)\n",
    "print('Max number of followings ',maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over 8: 1073\n",
      "over 10: 792\n",
      "over 12: 499\n"
     ]
    }
   ],
   "source": [
    "over_10 = 0\n",
    "over_8 = 0\n",
    "over_12 = 0\n",
    "for num in num_of_follower:\n",
    "    if num >= 10:\n",
    "        over_10 += 1\n",
    "    if num >= 8:\n",
    "        over_8 += 1\n",
    "    if num >= 12:\n",
    "        over_12 += 1\n",
    "print('over 8:',over_8)\n",
    "print('over 10:',over_10)\n",
    "print('over 12:',over_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_amount = 150\n",
    "yt_test_amount = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx = [i for i in range(len(user_following))]\n",
    "#test_idx is the number of user for testing\n",
    "test_idx = random.sample(user_idx,test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training  and Testing\n",
    "train_t = [0]*(len(user_following))\n",
    "train_f = [0]*(len(user_following))\n",
    "# Testing \n",
    "test_t = [0]*test_amount\n",
    "test_f = [0]*test_amount\n",
    "test_pos = -1\n",
    "\n",
    "for i in range(len(user_following)):\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "        for j in range(88):\n",
    "            if user_following[i][j] == 1:\n",
    "                t_for_train.append(j)\n",
    "            else:\n",
    "                f_for_train.append(j)\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train\n",
    "        \n",
    "    else: #if in test id, choose 2 true and other \n",
    "        test_pos += 1\n",
    "        temp_t = []\n",
    "        temp_f = []\n",
    "        for j in range(88):\n",
    "            if user_following[i][j] == 1:\n",
    "                temp_t.append(j)\n",
    "            else:\n",
    "                temp_f.append(j)\n",
    "        # random choose 2 true and 8 false for test \n",
    "        if len(temp_t)*0.2 < 1:\n",
    "            t_for_test = random.sample(temp_t,1)\n",
    "            f_for_test  = random.sample(temp_f,yt_test_amount-1)\n",
    "        else:\n",
    "            t_num = int(round(float(len(temp_t)*0.2)))\n",
    "            t_for_test = random.sample(temp_t,t_num)\n",
    "            f_for_test  = random.sample(temp_f,yt_test_amount-t_num)\n",
    "        test_t[test_pos] = t_for_test\n",
    "        test_f[test_pos] = f_for_test\n",
    "        \n",
    "        #other for training\n",
    "        t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "        f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test/150\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 1489\n",
      "The length of train_f: 1489\n",
      "The length of test_t: 150\n",
      "The length of test_f: 150\n"
     ]
    }
   ],
   "source": [
    "# train_t[i] user i positive feedback\n",
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_t))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation  Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "n: the number of users\n",
    "m: the number of YouTubers\n",
    "k: latent dims\n",
    "l: feature dims\n",
    "\"\"\"\n",
    "n = 1489\n",
    "m = 88  \n",
    "k = 128\n",
    "l = 2048 \n",
    "\n",
    "user = tf.placeholder(tf.int32,shape=(1,))\n",
    "i = tf.placeholder(tf.int32, shape=(1,))\n",
    "j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "#auxliary \n",
    "xf = tf.placeholder(tf.float32, shape=(None,l))\n",
    "l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "r = tf.placeholder(tf.float32,shape=(None,))\n",
    "\n",
    "\n",
    "image_i = tf.placeholder(tf.float32, shape=(1,l))\n",
    "image_j = tf.placeholder(tf.float32, shape=(1,l))\n",
    "\n",
    "with tf.variable_scope(\"item_level\"):\n",
    "    user_latent = tf.get_variable(\"user_latent\", [n, k],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    item_latent = tf.get_variable(\"item_latent\", [m, k],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3)) \n",
    "    aux_item = tf.get_variable(\"aux_item\", [m, k],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    W1 = tf.get_variable(\"W1\", [n, k],\n",
    "                                      initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wu = tf.get_variable(\"Wu\", [k,k],\n",
    "                                      initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wy = tf.get_variable(\"Wy\", [m,k,k],\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wa = tf.get_variable(\"Wa\", [k,k],\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wv = tf.get_variable(\"Wv\", [k,l],\n",
    "                                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    \n",
    "\n",
    "    aux_new = tf.get_variable(\"aux_new\", [1,k], initializer=tf.constant_initializer(0.0))\n",
    "    ########## Error part, how to get auxisize dynamically\n",
    "    ####aux_size= tf.get_variable(name='aux_size', initializer=l_id.get_shape().as_list()[-1])\n",
    "    \n",
    "with tf.variable_scope('feature_level'):\n",
    "    Beta = tf.get_variable(\"beta\", [n,l],\n",
    "                             # initializer=tf.contrib.layers.xavier_initializer())\n",
    "                                     initializer=tf.random_normal_initializer(0.00001,0.000001,seed=10))\n",
    "\n",
    "#lookup the latent factors by user and id\n",
    "u = tf.nn.embedding_lookup(user_latent, user) #(1*k) user latent factor\n",
    "vi = tf.nn.embedding_lookup(item_latent, i) \n",
    "vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "w1 = tf.nn.embedding_lookup(W1, user) #(1*k)\n",
    "wu = Wu\n",
    "#wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user)) #(k*k)\n",
    "wy = tf.squeeze(tf.nn.embedding_lookup(Wy, i)) #(k*k)\n",
    "wa = Wa\n",
    "#wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user)) #(k*k)\n",
    "wv = Wv\n",
    "#wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user)) #(k,l)\n",
    "\n",
    "beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-99048b126718>:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "a_list=tf.Variable([])\n",
    "q = tf.constant(0)\n",
    "def att_cond(q,a_list):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "def att_body(q,a_list):\n",
    "    xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "    \n",
    "    a_list = tf.concat([a_list,[(tf.matmul( w1, tf.nn.relu( tf.matmul(wu, u, transpose_b=True) +\n",
    "        tf.matmul(wy, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "        tf.matmul(wa, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "        tf.matmul(wv, xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "    q += 1\n",
    "    return q,  a_list\n",
    "\n",
    "_, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "a_list_soft=tf.nn.softmax(a_list)\n",
    "\n",
    "\n",
    "aux_np = tf.expand_dims(tf.zeros(128),0) #dimension (1,32)\n",
    "q = tf.constant(0)\n",
    "def sum_att_cond(q,aux_np):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def sum_att_body(q,aux_np):\n",
    "    #aux_np+=a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)\n",
    "    aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "    q += 1\n",
    "    return q, aux_np\n",
    "\n",
    "_,aux_np = tf.while_loop(sum_att_cond,sum_att_body,[q,aux_np])\n",
    "\n",
    "\"\"\"\n",
    "for q in range(3): #qauxliary item\n",
    "    aux_np+=a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "aux_np+=u #user_latent factor + sum (alpha*auxilary)\n",
    "aux_new=tf.assign(aux_new,aux_np) #aux_new  aux_np\n",
    "\n",
    "#\n",
    "xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,image_i, transpose_b=True)\n",
    "xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,image_j, transpose_b=True)\n",
    "\n",
    "xuij = xui- xuj\n",
    "\n",
    "l2_norm = tf.add_n([\n",
    "            0.001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "            0.001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "            0.001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "  \n",
    "            0.001 * tf.reduce_sum(tf.multiply(w1, w1)),\n",
    "            0.001 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "            0.001 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "            0.001 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "            0.001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "            \n",
    "            0.1 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "            \n",
    "          ])\n",
    "\n",
    "loss = l2_norm -tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "auc = tf.reduce_mean(tf.to_float(xuij > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.23338842]]\n",
      "train_auc:------------------- 0.9376777408637874\n",
      "time: 6585.584819555283  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.15217773]]\n",
      "train_auc:------------------- 0.9760863787375416\n",
      "time: 15306.118017673492  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.14251459]]\n",
      "train_auc:------------------- 0.980704318936877\n",
      "time: 24344.214306116104  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.13951455]]\n",
      "train_auc:------------------- 0.9820963455149502\n",
      "time: 33117.7545003891  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.13787766]]\n",
      "train_auc:------------------- 0.9830431893687708\n",
      "time: 42165.32394313812  sec\n",
      "Total cost  42165.32394313812  sec\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "loss_acc_list = []\n",
    "t0=time.time()\n",
    "\n",
    "#use_true=init_list_of_objects(136)\n",
    "#use_test=init_list_of_objects(136)\n",
    "\n",
    "train_pair_t=[] #positive feedback\n",
    "train_pair_f=[] #negative feedback\n",
    "train_yes_id=[] \n",
    "for q in range(5):\n",
    "    print('Iteraction:',q)\n",
    "    train_auc=0\n",
    "    total_loss=0\n",
    "    xuij_auc=0\n",
    "    length = 0\n",
    "    for z in range(1489):\n",
    "        \"\"\"\n",
    "        yes YouTuber feature (for auxilary)\n",
    "        yesr userYouTuber(user_category  YouTuber_category)\n",
    "        r_3 user YouTuber(max)\n",
    "        \"\"\"\n",
    "        yes=[]\n",
    "        yesr=[]\n",
    "        \n",
    "        \n",
    "        sample=random.sample(train_t[z],len(train_t[z])) #3sample true's YouTuber\n",
    "        train_yes_id.append(sample) #sample\n",
    "        \n",
    "        #sample=random.sample(train_t[z]+train_f[z],len(train_t[z])+len(train_f[z]))\n",
    "        \n",
    "        #change\n",
    "        r_3=np.zeros(len(sample)) \n",
    "        alpha_history = []\n",
    "        a_list_history = []\n",
    "        U_history = []\n",
    "        Y_history = []\n",
    "        \n",
    "        #print(len(sample))\n",
    "        #check if all YouTuber are in train_t or train_f\n",
    "        #if len(train_t[z])+len(train_f[z]) != 88:\n",
    "            #print(z,len(train_t[z])+len(train_f[z]))\n",
    "         \n",
    "        for k in range(len(sample)):\n",
    "            yes.append(image_2048[sample[k]])\n",
    "            yesr.append(YouTuber_category[sample[k]]*user_category_norm[z])\n",
    "            #print('YouTuber_category ', YouTuber_category[sample[k]])\n",
    "            #print('User_category ',user_category_norm[z])\n",
    "        #print(len(yes))\n",
    "        for k in range(len(sample)):\n",
    "            r_3[k]=max(yesr[k])\n",
    "        #print('r_3:',r_3)\n",
    "        \n",
    "        yes=np.array(yes)\n",
    "        #print('user shape should be ',np.array([z]).shape)\n",
    "        #print('xf shape should be ',yes.shape)\n",
    "        #print('r shape should be ',np.array(r_3).shape)\n",
    "        #print('l_id shape should be ',np.array(sample).shape)\n",
    "        \n",
    "        #not_used_list = list(set(train_t[z]).difference(set(sample)))\n",
    "        \n",
    "        train_t_sample = random.sample(train_t[z],len(train_t[z]))\n",
    "        #print('number of positive feedback', len(train_t[z]))\n",
    "        for ta in train_t_sample:\n",
    "            #ta=random.choice(train_t[z]) #ta is true positve photo\n",
    "            train_pair_t.append(ta)\n",
    "            image_1=np.expand_dims(image_2048[ta],0) #(1,2048)\n",
    "            #print('Image_1 shape ',image_1.shape)\n",
    "            train_f_sample = random.sample(train_f[z],20)\n",
    "            for b in train_f_sample:\n",
    "                #print('likes:',ta,';Not likes:',b)\n",
    "                #b=random.choice(train_f[z])  #b is no feedback photo\n",
    "                train_pair_f.append(b)\n",
    "                image_2=np.expand_dims(image_2048[b],0) #(1,2048)\n",
    "                #print('Image_2 shape',image_2.shape)\n",
    "            \n",
    "                #use_test[z].append(b)\n",
    "                Uu,Yy,_a_list,r3,_auc, _loss,_=sess.run([user_latent,item_latent,a_list,a_list_soft,auc,loss,train_op], feed_dict={user: [z],\n",
    "                                        i: [ta], j: [b], xf: yes , l_id:sample, l_id_len:[len(sample)],r:r_3,\n",
    "                                        image_i:image_1,image_j:image_2})\n",
    "                #print('User latent factor')\n",
    "                #print(Uu.shape)\n",
    "                #print(Uu)\n",
    "                #print('Item latent factor')\n",
    "                #print(Yy.shape)\n",
    "                #print(Yy)\n",
    "                U_history.append(Uu)\n",
    "                Y_history.append(Yy)\n",
    "                \n",
    "                #print(XUIJ)\n",
    "                #print('loss=',_loss)\n",
    "                #print('auc=',_auc)\n",
    "                #print(z,ta,b)\n",
    "                #print('alpha list after softmax:',r3)\n",
    "                #print('alpha list before softmax:',_a_list)\n",
    "                a_list_history.append(_a_list)\n",
    "                alpha_history.append(r3)\n",
    "                train_auc+=_auc\n",
    "                total_loss+=_loss\n",
    "                length += 1\n",
    "            #now1+=1\n",
    "            \n",
    "        with open('../Data/alpha_txt/'+str(q)+'_'+str(z)+'.txt', 'w') as f:\n",
    "            for idd in range(len(alpha_history)):\n",
    "                f.write('softmax alpha:')\n",
    "                f.write(str(alpha_history[idd])+'\\n')\n",
    "                f.write('before softmax:')\n",
    "                f.write(str(a_list_history[idd])+'\\n')\n",
    "        np.savez('../Data/latent_factor/'+str(q)+'_'+str(z)+'.npz', User=U_history, YouTuber=Y_history)\n",
    "    \n",
    "    #print('mine:',xuij_auc/136)    \n",
    "    #print('a_list_soft:',r3)\n",
    "    print(\"total_loss:-----------------\", total_loss/length)\n",
    "    print(\"train_auc:-------------------\", train_auc/length)\n",
    "    loss_acc_list.append([total_loss/length,train_auc/length,time.time()-t0])\n",
    "    print('time:',time.time()-t0,' sec')\n",
    "print('Total cost ',time.time()-t0,' sec')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "loss= [[0.23338842]]\n",
      "acc= 0.9376777408637874\n",
      "time= 6585.584819555283\n",
      "Iteration: 1\n",
      "loss= [[0.15217773]]\n",
      "acc= 0.9760863787375416\n",
      "time= 15306.118017673492\n",
      "Iteration: 2\n",
      "loss= [[0.14251459]]\n",
      "acc= 0.980704318936877\n",
      "time= 24344.214306116104\n",
      "Iteration: 3\n",
      "loss= [[0.13951455]]\n",
      "acc= 0.9820963455149502\n",
      "time= 33117.7545003891\n",
      "Iteration: 4\n",
      "loss= [[0.13787766]]\n",
      "acc= 0.9830431893687708\n",
      "time= 42165.32394313812\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(loss_acc_list)):\n",
    "    print('Iteration:',i)\n",
    "    print('loss=',loss_acc_list[i][0])\n",
    "    print('acc=',loss_acc_list[i][1])\n",
    "    print('time=',loss_acc_list[i][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent factor and Each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, Y, A, A1, Au, Ay, Aa, Av,B =sess.run([user_latent, item_latent, aux_item, W1, Wu, Wy, Wa, Wv,Beta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User latent shape:  (1489, 128)\n",
      "photo latent shape:  (88, 128)\n",
      "Auxilary latent shape:  (88, 128)\n",
      "W1 weight shape:  (1489, 128)\n",
      "Wu weight shape: (128, 128)\n",
      "Wy weight shape: (88, 128, 128)\n",
      "Wa weight shape: (128, 128)\n",
      "Wv weight shape: (128, 2048)\n",
      "Beta shape: (1489, 2048)\n"
     ]
    }
   ],
   "source": [
    "print('User latent shape: ',U.shape)\n",
    "print('photo latent shape: ', Y.shape)\n",
    "print('Auxilary latent shape: ',A.shape)\n",
    "print('W1 weight shape: ',A1.shape)\n",
    "print('Wu weight shape:',Au.shape)\n",
    "print('Wy weight shape:', Ay.shape)\n",
    "print('Wa weight shape:',Aa.shape)\n",
    "print('Wv weight shape:',Av.shape)\n",
    "print('Beta shape:',B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1484\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "1 1259\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "2 1191\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "3 1026\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "4 1465\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "5 1309\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "6 132\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "7 1050\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "8 1116\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "9 1381\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "10 1192\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "11 1209\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "12 678\n",
      "softmax alpha-------------- [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "13 113\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "14 234\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "15 840\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "16 1451\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "17 1290\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "18 726\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "19 425\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "20 927\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "21 345\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "22 485\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "23 262\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "24 624\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "25 860\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "26 1482\n",
      "softmax alpha-------------- [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "27 947\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "28 936\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "29 104\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "30 505\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "31 705\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "32 911\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "33 981\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "34 839\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "35 1093\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "36 496\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "37 87\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "38 607\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "39 297\n",
      "softmax alpha-------------- [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "40 369\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "41 540\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "42 478\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "43 1471\n",
      "softmax alpha-------------- [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "44 197\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "45 586\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "46 184\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "47 640\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "48 892\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "49 1146\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "50 691\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "51 58\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "52 494\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "53 955\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "54 406\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "55 891\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "56 790\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "57 412\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "58 738\n",
      "softmax alpha-------------- [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "59 61\n",
      "softmax alpha-------------- [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "60 52\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "61 692\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "62 1348\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "63 26\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "64 772\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "65 850\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "66 1460\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "67 545\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "68 901\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "69 159\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "70 358\n",
      "softmax alpha-------------- [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "71 970\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "72 910\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "73 1302\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "74 97\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "75 1171\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "76 368\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "77 842\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "78 1469\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "79 187\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "80 346\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "81 1013\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "82 1355\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "83 869\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "84 316\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "85 1282\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "86 1445\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "87 141\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "88 1217\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "89 1216\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "90 1107\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "91 581\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "92 1110\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "93 108\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "94 934\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "95 834\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "96 633\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "97 815\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "98 405\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "99 7\n",
      "softmax alpha-------------- [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "100 1467\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "101 423\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "102 745\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "103 643\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "104 717\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "105 1463\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "106 1193\n",
      "softmax alpha-------------- [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "107 340\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "108 808\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "109 995\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "110 286\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "111 1247\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "112 1263\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "113 163\n",
      "softmax alpha-------------- [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "114 904\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "115 902\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "116 1479\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "117 1088\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "118 1429\n",
      "softmax alpha-------------- [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "119 461\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "120 357\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "121 1327\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "122 202\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "123 1364\n",
      "softmax alpha-------------- [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "124 1283\n",
      "softmax alpha-------------- [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "125 301\n",
      "softmax alpha-------------- [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "126 133\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "127 222\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "128 1458\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "129 82\n",
      "softmax alpha-------------- [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "130 509\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "131 1423\n",
      "softmax alpha-------------- [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "132 1096\n",
      "softmax alpha-------------- [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "133 1148\n",
      "softmax alpha-------------- [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "134 475\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "135 1437\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "136 455\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "137 162\n",
      "softmax alpha-------------- [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "138 1125\n",
      "softmax alpha-------------- [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "139 613\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "140 311\n",
      "softmax alpha-------------- [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "141 138\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "142 1462\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "143 1106\n",
      "softmax alpha-------------- [0.25 0.25 0.25 0.25]\n",
      "144 1054\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "145 306\n",
      "softmax alpha-------------- [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "146 1426\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "147 814\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "148 299\n",
      "softmax alpha-------------- [0.2 0.2 0.2 0.2 0.2]\n",
      "149 139\n",
      "softmax alpha-------------- [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "[-0.87695783 -2.66442253 -4.19097787 -6.34985523 -5.73631431 -4.19851697\n",
      " -1.84714279 -5.68520039 -8.56167878 -5.13303488 -6.69492372 -4.44460157\n",
      " -1.96728664 -4.88487261 -8.08803155 -5.44513045 -4.23558596 -5.057499\n",
      " -5.52054017 -3.57807346 -4.47013203 -2.07320449 -5.07690009 -4.39375272\n",
      " -8.61217364 -4.59949044 -3.36997826 -2.58011023 -6.34648173 -8.41200222\n",
      " -5.35621513 -5.43931786 -2.35262347  0.06571692 -4.02486543 -5.04045182\n",
      " -5.6682783  -4.86243693 -3.36948422 -3.83841281 -6.56616374 -9.60528972\n",
      " -4.40296487 -7.14749882 -2.84649501 -4.04303275 -3.33147927 -3.8901343\n",
      " -6.27482785 -6.96030302 -5.46359593 -0.31712818 -3.39741566 -3.21499128\n",
      " -6.3946122  -1.88606172 -5.18672638 -7.87193789 -3.37489204 -2.13322483\n",
      " -2.88895539 -3.68180922 -4.42304085 -6.8832562  -5.54643511 -4.25979094\n",
      " -6.39866222 -4.95402619 -3.44654611 -4.1175889  -8.19825665 -5.45177459\n",
      " -1.17989343 -4.32626534 -4.23136888 -6.20981434 -2.17406332 -5.78011439\n",
      " -6.7949192  -7.26017407 -5.63315542 -4.01878029 -4.87320903  1.26217638\n",
      "  0.43738615 -3.58960251 -4.31906516 -4.00494443]\n"
     ]
    }
   ],
   "source": [
    "result=np.zeros((test_amount,88))\n",
    "RS=np.zeros((test_amount,88))\n",
    "#test_idx --> Test  index\n",
    "\n",
    "test_yes_id=[]\n",
    "for s in range(test_amount):\n",
    "    print(s,test_idx[s])\n",
    "\n",
    "    yes=[]\n",
    "    sample=random.sample(train_t[test_idx[s]],len(train_t[test_idx[s]])) #training part positive feedback YouTuber Auxilary\n",
    "    #sample=result_yes_id[now]\n",
    "    test_yes_id.append(sample)\n",
    "    alpha=np.zeros([len(sample)])\n",
    "    \n",
    "    for a in range(len(sample)):\n",
    "        r =np.max(YouTuber_category[sample[a]]*user_category_norm[test_idx[s]]) #sample a category vec *user_category vec\n",
    "        #print(test_idx[s])\n",
    "        #print(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0)))\n",
    "        alpha[a]=np.dot(A1[test_idx[s]],(relu(np.dot(Au,np.expand_dims(U[test_idx[s]],0).T)+np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T)+np.dot(Aa,\n",
    "                            np.expand_dims(A[sample[a]],0).T)+ np.dot(Av,np.expand_dims(image_2048[sample[a]],0).T))))*r\n",
    "    mul=np.zeros((1,128))\n",
    "    #print('alpha------------',alpha)\n",
    "    print('softmax alpha--------------',softmax(alpha))\n",
    "    for i in range(len(sample)):\n",
    "        mul+=softmax(alpha)[i]*A[sample[i]] #attention alpha*Ai part \n",
    "    new_mul=mul+U[test_idx[s]]  #(U+auxilary)\n",
    "    for k in range(88):\n",
    "        result[s][k]=np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "        RS[s][k] = np.dot(new_mul,Y[k].T)+np.dot(B[test_idx[s]], image_2048[k].T)\n",
    "print(RS[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "testRS = np.zeros((test_amount,yt_test_amount)) #shape 150*20\n",
    "target = np.zeros((test_amount,yt_test_amount))\n",
    "#test_t true\n",
    "#test_f false\n",
    "        \n",
    "for z in range(test_amount):\n",
    "    user_id = test_idx[z]\n",
    "    #positive target YouTuber list\n",
    "    youtube_t = test_t[z] \n",
    "    #not target YouTuber list\n",
    "    youtube_f = test_f[z]\n",
    "    \n",
    "    #targetRS\n",
    "    for i in range(len(youtube_t)):\n",
    "        testRS[z][i] = RS[z][youtube_t[i]]\n",
    "        target[z][i] = 1\n",
    "    for i in range(len(youtube_f)):\n",
    "        testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of positive data in testing: 300.0\n",
      "total testing data: 3000\n"
     ]
    }
   ],
   "source": [
    "sumtarget = 0\n",
    "for i in range(len(target)):\n",
    "    #print(np.sum(target[i]))\n",
    "    sumtarget += np.sum(target[i])\n",
    "print('num of positive data in testing:',sumtarget)\n",
    "print('total testing data:',test_amount*yt_test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN(sortlist,n):\n",
    "    topList = []\n",
    "    for i in range(n):\n",
    "        topList.append(sortlist.index(max(sortlist)))\n",
    "        #print(max(sortlist))\n",
    "        #print(sortlist.index(max(sortlist)))\n",
    "        sortlist[sortlist.index(max(sortlist))] = -1000000000\n",
    "    return topList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 6, 0]\n",
      "[0, 10]\n",
      "[9, 0]\n",
      "[5, 19, 16]\n",
      "[1, 2, 10, 19]\n",
      "[1, 16]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[9, 11]\n",
      "[15, 0]\n",
      "[0, 1]\n",
      "[1, 0, 2]\n",
      "[9]\n",
      "[10]\n",
      "[9]\n",
      "[2, 6, 14]\n",
      "[0]\n",
      "[8, 11, 19]\n",
      "[14, 8, 4, 9]\n",
      "[3, 14]\n",
      "[0, 2, 16]\n",
      "[12]\n",
      "[17, 6]\n",
      "[10, 5]\n",
      "[19, 11]\n",
      "[1, 0]\n",
      "[8, 2, 18]\n",
      "[13, 8, 6, 9]\n",
      "[2]\n",
      "[2, 3]\n",
      "[9, 18]\n",
      "[19, 7, 10, 3]\n",
      "[9, 17, 0]\n",
      "[16]\n",
      "[11, 17, 1]\n",
      "[3, 17]\n",
      "[0, 1]\n",
      "[2, 12, 16, 3, 0]\n",
      "[10, 0]\n",
      "[5]\n",
      "[5, 4, 16]\n",
      "[9, 0]\n",
      "[0]\n",
      "[0, 5]\n",
      "[15, 7]\n",
      "[5]\n",
      "[2, 0]\n",
      "[1, 10]\n",
      "[0]\n",
      "[15, 19]\n",
      "[3, 0]\n",
      "[13, 9]\n",
      "[3, 6]\n",
      "[0]\n",
      "[18, 5]\n",
      "[1, 11, 0]\n",
      "[1, 18]\n",
      "[3, 6]\n",
      "[2, 0]\n",
      "[18, 0]\n",
      "[10, 13]\n",
      "[9, 1, 8]\n",
      "[7, 1, 13]\n",
      "[0]\n",
      "[7, 4, 2, 3]\n",
      "[19]\n",
      "[9]\n",
      "[1, 13]\n",
      "[10]\n",
      "[14, 19]\n",
      "[3, 4, 13, 2]\n",
      "[7, 0, 9]\n",
      "[0, 16]\n",
      "[6]\n",
      "[0, 13]\n",
      "[9]\n",
      "[0, 19]\n",
      "[12]\n",
      "[17]\n",
      "[0, 2]\n",
      "[19]\n",
      "[1, 0, 2]\n",
      "[5, 10, 8]\n",
      "[0, 1]\n",
      "[5]\n",
      "[0, 5, 2]\n",
      "[4, 1]\n",
      "[6]\n",
      "[0, 1]\n",
      "[18, 12]\n",
      "[2, 1, 10]\n",
      "[14]\n",
      "[17, 15]\n",
      "[15, 13]\n",
      "[5]\n",
      "[2, 19, 8]\n",
      "[0, 17]\n",
      "[5, 2, 0]\n",
      "[3, 18]\n",
      "[10, 11]\n",
      "[12, 7]\n",
      "[11]\n",
      "[15]\n",
      "[7]\n",
      "[16]\n",
      "[18, 7, 0]\n",
      "[7]\n",
      "[0, 15, 9]\n",
      "[14]\n",
      "[3]\n",
      "[15, 1, 4]\n",
      "[2, 0]\n",
      "[3, 12, 2, 1]\n",
      "[11, 12]\n",
      "[7]\n",
      "[12]\n",
      "[18, 0, 1]\n",
      "[0]\n",
      "[1, 9]\n",
      "[2, 1]\n",
      "[4, 2]\n",
      "[0, 2]\n",
      "[7, 18]\n",
      "[1, 4]\n",
      "[2, 5, 16]\n",
      "[14, 15]\n",
      "[1, 8]\n",
      "[0]\n",
      "[19, 3]\n",
      "[0]\n",
      "[8]\n",
      "[0, 2, 1]\n",
      "[3, 7]\n",
      "[3, 5, 2]\n",
      "[1]\n",
      "[14, 18, 2]\n",
      "[4]\n",
      "[7]\n",
      "[18, 10]\n",
      "[7]\n",
      "[16, 13]\n",
      "[4]\n",
      "[16]\n",
      "[18]\n",
      "[4, 15]\n",
      "[0, 17]\n",
      "[13, 1, 2]\n",
      "[19]\n",
      "[5, 0, 13]\n",
      "[7]\n",
      "avg_accuarcy for count_0: 0.14145658263305322\n"
     ]
    }
   ],
   "source": [
    "count_0_all = []\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),int(np.sum(target[i])))\n",
    "    count_0_all.append(top_0)\n",
    "    print(top_0)\n",
    "\n",
    "acc_0 = 0\n",
    "total = 0\n",
    "for i in range(len(count_0_all)):\n",
    "    for j in range(len(count_0_all[i])):\n",
    "        #print(int(np.sum(target[i])))\n",
    "        total+=int(np.sum(target[i]))\n",
    "        if count_0_all[i][j] < int(np.sum(target[i])): #01 (target)\n",
    "            acc_0 += 1\n",
    "avg_acc = acc_0/total\n",
    "print('avg_accuarcy for count_0:',avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = (2*prec*rec)/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\n",
      "[0]\n",
      "[9]\n",
      "[5]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[9]\n",
      "[15]\n",
      "[0]\n",
      "[1]\n",
      "[9]\n",
      "[10]\n",
      "[9]\n",
      "[2]\n",
      "[0]\n",
      "[8]\n",
      "[14]\n",
      "[3]\n",
      "[0]\n",
      "[12]\n",
      "[17]\n",
      "[10]\n",
      "[19]\n",
      "[1]\n",
      "[8]\n",
      "[13]\n",
      "[2]\n",
      "[2]\n",
      "[9]\n",
      "[19]\n",
      "[9]\n",
      "[16]\n",
      "[11]\n",
      "[3]\n",
      "[0]\n",
      "[2]\n",
      "[10]\n",
      "[5]\n",
      "[5]\n",
      "[9]\n",
      "[0]\n",
      "[0]\n",
      "[15]\n",
      "[5]\n",
      "[2]\n",
      "[1]\n",
      "[0]\n",
      "[15]\n",
      "[3]\n",
      "[13]\n",
      "[3]\n",
      "[0]\n",
      "[18]\n",
      "[1]\n",
      "[1]\n",
      "[3]\n",
      "[2]\n",
      "[18]\n",
      "[10]\n",
      "[9]\n",
      "[7]\n",
      "[0]\n",
      "[7]\n",
      "[19]\n",
      "[9]\n",
      "[1]\n",
      "[10]\n",
      "[14]\n",
      "[3]\n",
      "[7]\n",
      "[0]\n",
      "[6]\n",
      "[0]\n",
      "[9]\n",
      "[0]\n",
      "[12]\n",
      "[17]\n",
      "[0]\n",
      "[19]\n",
      "[1]\n",
      "[5]\n",
      "[0]\n",
      "[5]\n",
      "[0]\n",
      "[4]\n",
      "[6]\n",
      "[0]\n",
      "[18]\n",
      "[2]\n",
      "[14]\n",
      "[17]\n",
      "[15]\n",
      "[5]\n",
      "[2]\n",
      "[0]\n",
      "[5]\n",
      "[3]\n",
      "[10]\n",
      "[12]\n",
      "[11]\n",
      "[15]\n",
      "[7]\n",
      "[16]\n",
      "[18]\n",
      "[7]\n",
      "[0]\n",
      "[14]\n",
      "[3]\n",
      "[15]\n",
      "[2]\n",
      "[3]\n",
      "[11]\n",
      "[7]\n",
      "[12]\n",
      "[18]\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[4]\n",
      "[0]\n",
      "[7]\n",
      "[1]\n",
      "[2]\n",
      "[14]\n",
      "[1]\n",
      "[0]\n",
      "[19]\n",
      "[0]\n",
      "[8]\n",
      "[0]\n",
      "[3]\n",
      "[3]\n",
      "[1]\n",
      "[14]\n",
      "[4]\n",
      "[7]\n",
      "[18]\n",
      "[7]\n",
      "[16]\n",
      "[4]\n",
      "[16]\n",
      "[18]\n",
      "[4]\n",
      "[0]\n",
      "[13]\n",
      "[19]\n",
      "[5]\n",
      "[7]\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),1) #\n",
    "    count_0_all.append(top_0)\n",
    "    print(top_0)\n",
    "    if top_0[0] < int(np.sum(target[i])):\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.30666666666666664 recall  0.15333333333333332\n"
     ]
    }
   ],
   "source": [
    "top1_prec = correct/len(testRS)\n",
    "top1_recall = correct/(sumtarget)\n",
    "print('prec ',top1_prec,'recall ',top1_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: 0.20444444444444443\n"
     ]
    }
   ],
   "source": [
    "#f1 score\n",
    "print('F1_score:',F1_score(top1_prec,top1_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 6, 0]\n",
      "[0, 10, 1]\n",
      "[9, 0, 1]\n",
      "[5, 19, 16]\n",
      "[1, 2, 10]\n",
      "[1, 16, 0]\n",
      "[1, 0, 8]\n",
      "[1, 0, 12]\n",
      "[9, 11, 6]\n",
      "[15, 0, 10]\n",
      "[0, 1, 18]\n",
      "[1, 0, 2]\n",
      "[9, 10, 6]\n",
      "[10, 0, 16]\n",
      "[9, 5, 12]\n",
      "[2, 6, 14]\n",
      "[0, 16, 2]\n",
      "[8, 11, 19]\n",
      "[14, 8, 4]\n",
      "[3, 14, 8]\n",
      "[0, 2, 16]\n",
      "[12, 0, 15]\n",
      "[17, 6, 0]\n",
      "[10, 5, 12]\n",
      "[19, 11, 16]\n",
      "[1, 0, 2]\n",
      "[8, 2, 18]\n",
      "[13, 8, 6]\n",
      "[2, 11, 0]\n",
      "[2, 3, 6]\n",
      "[9, 18, 6]\n",
      "[19, 7, 10]\n",
      "[9, 17, 0]\n",
      "[16, 7, 19]\n",
      "[11, 17, 1]\n",
      "[3, 17, 15]\n",
      "[0, 1, 16]\n",
      "[2, 12, 16]\n",
      "[10, 0, 14]\n",
      "[5, 18, 8]\n",
      "[5, 4, 16]\n",
      "[9, 0, 16]\n",
      "[0, 2, 5]\n",
      "[0, 5, 14]\n",
      "[15, 7, 12]\n",
      "[5, 1, 10]\n",
      "[2, 0, 16]\n",
      "[1, 10, 7]\n",
      "[0, 18, 9]\n",
      "[15, 19, 14]\n",
      "[3, 0, 17]\n",
      "[13, 9, 17]\n",
      "[3, 6, 18]\n",
      "[0, 16, 7]\n",
      "[18, 5, 3]\n",
      "[1, 11, 0]\n",
      "[1, 18, 17]\n",
      "[3, 6, 2]\n",
      "[2, 0, 1]\n",
      "[18, 0, 15]\n",
      "[10, 13, 15]\n",
      "[9, 1, 8]\n",
      "[7, 1, 13]\n",
      "[0, 10, 11]\n",
      "[7, 4, 2]\n",
      "[19, 8, 3]\n",
      "[9, 0, 6]\n",
      "[1, 13, 14]\n",
      "[10, 0, 6]\n",
      "[14, 19, 11]\n",
      "[3, 4, 13]\n",
      "[7, 0, 9]\n",
      "[0, 16, 7]\n",
      "[6, 19, 2]\n",
      "[0, 13, 1]\n",
      "[9, 6, 3]\n",
      "[0, 19, 15]\n",
      "[12, 18, 0]\n",
      "[17, 0, 10]\n",
      "[0, 2, 1]\n",
      "[19, 14, 5]\n",
      "[1, 0, 2]\n",
      "[5, 10, 8]\n",
      "[0, 1, 15]\n",
      "[5, 11, 10]\n",
      "[0, 5, 2]\n",
      "[4, 1, 13]\n",
      "[6, 0, 17]\n",
      "[0, 1, 11]\n",
      "[18, 12, 17]\n",
      "[2, 1, 10]\n",
      "[14, 12, 18]\n",
      "[17, 15, 5]\n",
      "[15, 13, 7]\n",
      "[5, 18, 15]\n",
      "[2, 19, 8]\n",
      "[0, 17, 12]\n",
      "[5, 2, 0]\n",
      "[3, 18, 6]\n",
      "[10, 11, 13]\n",
      "[12, 7, 0]\n",
      "[11, 5, 0]\n",
      "[15, 2, 3]\n",
      "[7, 4, 19]\n",
      "[16, 5, 17]\n",
      "[18, 7, 0]\n",
      "[7, 12, 16]\n",
      "[0, 15, 9]\n",
      "[14, 1, 10]\n",
      "[3, 11, 16]\n",
      "[15, 1, 4]\n",
      "[2, 0, 6]\n",
      "[3, 12, 2]\n",
      "[11, 12, 7]\n",
      "[7, 15, 0]\n",
      "[12, 0, 5]\n",
      "[18, 0, 1]\n",
      "[0, 3, 9]\n",
      "[1, 9, 6]\n",
      "[2, 1, 18]\n",
      "[4, 2, 19]\n",
      "[0, 2, 12]\n",
      "[7, 18, 19]\n",
      "[1, 4, 7]\n",
      "[2, 5, 16]\n",
      "[14, 15, 13]\n",
      "[1, 8, 0]\n",
      "[0, 3, 8]\n",
      "[19, 3, 1]\n",
      "[0, 18, 6]\n",
      "[8, 17, 13]\n",
      "[0, 2, 1]\n",
      "[3, 7, 15]\n",
      "[3, 5, 2]\n",
      "[1, 14, 3]\n",
      "[14, 18, 2]\n",
      "[4, 11, 14]\n",
      "[7, 17, 2]\n",
      "[18, 10, 13]\n",
      "[7, 1, 6]\n",
      "[16, 13, 1]\n",
      "[4, 6, 2]\n",
      "[16, 2, 13]\n",
      "[18, 0, 14]\n",
      "[4, 15, 6]\n",
      "[0, 17, 1]\n",
      "[13, 1, 2]\n",
      "[19, 15, 16]\n",
      "[5, 0, 13]\n",
      "[7, 12, 6]\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_3 = topN(list(testRS[i]),3) #\n",
    "    count_0_all.append(top_3)\n",
    "    print(top_3)\n",
    "    for j in range(len(top_3)):\n",
    "        if top_3[j] < int(np.sum(target[i])):\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.2644444444444444 recall  0.39666666666666667\n"
     ]
    }
   ],
   "source": [
    "top3_prec = correct/(len(testRS)*3)\n",
    "top3_recall = correct/(sumtarget)\n",
    "print('prec ',top3_prec,'recall ',top3_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: 0.31733333333333336\n"
     ]
    }
   ],
   "source": [
    "#f1 score\n",
    "print('F1_score:',F1_score(top3_prec,top3_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_score(0.2222222222222222,0.0333333333333333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 6, 0, 14, 4]\n",
      "[0, 10, 1, 16, 5]\n",
      "[9, 0, 1, 17, 12]\n",
      "[5, 19, 16, 12, 0]\n",
      "[1, 2, 10, 19, 13]\n",
      "[1, 16, 0, 6, 18]\n",
      "[1, 0, 8, 19, 4]\n",
      "[1, 0, 12, 2, 14]\n",
      "[9, 11, 6, 14, 3]\n",
      "[15, 0, 10, 11, 4]\n",
      "[0, 1, 18, 7, 11]\n",
      "[1, 0, 2, 3, 10]\n",
      "[9, 10, 6, 3, 19]\n",
      "[10, 0, 16, 18, 11]\n",
      "[9, 5, 12, 17, 8]\n",
      "[2, 6, 14, 1, 17]\n",
      "[0, 16, 2, 6, 12]\n",
      "[8, 11, 19, 5, 1]\n",
      "[14, 8, 4, 9, 15]\n",
      "[3, 14, 8, 6, 18]\n",
      "[0, 2, 16, 1, 17]\n",
      "[12, 0, 15, 17, 19]\n",
      "[17, 6, 0, 1, 16]\n",
      "[10, 5, 12, 7, 0]\n",
      "[19, 11, 16, 14, 3]\n",
      "[1, 0, 2, 5, 4]\n",
      "[8, 2, 18, 5, 15]\n",
      "[13, 8, 6, 9, 3]\n",
      "[2, 11, 0, 10, 12]\n",
      "[2, 3, 6, 13, 8]\n",
      "[9, 18, 6, 7, 12]\n",
      "[19, 7, 10, 3, 18]\n",
      "[9, 17, 0, 19, 11]\n",
      "[16, 7, 19, 3, 8]\n",
      "[11, 17, 1, 0, 18]\n",
      "[3, 17, 15, 13, 6]\n",
      "[0, 1, 16, 18, 2]\n",
      "[2, 12, 16, 3, 0]\n",
      "[10, 0, 14, 1, 19]\n",
      "[5, 18, 8, 17, 9]\n",
      "[5, 4, 16, 10, 9]\n",
      "[9, 0, 16, 19, 3]\n",
      "[0, 2, 5, 8, 18]\n",
      "[0, 5, 14, 2, 3]\n",
      "[15, 7, 12, 0, 8]\n",
      "[5, 1, 10, 4, 3]\n",
      "[2, 0, 16, 14, 4]\n",
      "[1, 10, 7, 12, 18]\n",
      "[0, 18, 9, 10, 12]\n",
      "[15, 19, 14, 0, 4]\n",
      "[3, 0, 17, 6, 14]\n",
      "[13, 9, 17, 4, 6]\n",
      "[3, 6, 18, 19, 14]\n",
      "[0, 16, 7, 10, 17]\n",
      "[18, 5, 3, 4, 6]\n",
      "[1, 11, 0, 13, 15]\n",
      "[1, 18, 17, 0, 16]\n",
      "[3, 6, 2, 14, 0]\n",
      "[2, 0, 1, 10, 11]\n",
      "[18, 0, 15, 9, 13]\n",
      "[10, 13, 15, 5, 9]\n",
      "[9, 1, 8, 0, 17]\n",
      "[7, 1, 13, 0, 2]\n",
      "[0, 10, 11, 6, 15]\n",
      "[7, 4, 2, 3, 6]\n",
      "[19, 8, 3, 2, 14]\n",
      "[9, 0, 6, 8, 5]\n",
      "[1, 13, 14, 5, 16]\n",
      "[10, 0, 6, 5, 2]\n",
      "[14, 19, 11, 12, 3]\n",
      "[3, 4, 13, 2, 6]\n",
      "[7, 0, 9, 1, 14]\n",
      "[0, 16, 7, 18, 10]\n",
      "[6, 19, 2, 5, 13]\n",
      "[0, 13, 1, 17, 6]\n",
      "[9, 6, 3, 13, 15]\n",
      "[0, 19, 15, 7, 9]\n",
      "[12, 18, 0, 8, 4]\n",
      "[17, 0, 10, 3, 1]\n",
      "[0, 2, 1, 7, 17]\n",
      "[19, 14, 5, 10, 4]\n",
      "[1, 0, 2, 3, 15]\n",
      "[5, 10, 8, 2, 6]\n",
      "[0, 1, 15, 9, 19]\n",
      "[5, 11, 10, 7, 13]\n",
      "[0, 5, 2, 1, 18]\n",
      "[4, 1, 13, 0, 12]\n",
      "[6, 0, 17, 11, 16]\n",
      "[0, 1, 11, 3, 2]\n",
      "[18, 12, 17, 14, 8]\n",
      "[2, 1, 10, 18, 11]\n",
      "[14, 12, 18, 19, 2]\n",
      "[17, 15, 5, 8, 3]\n",
      "[15, 13, 7, 18, 14]\n",
      "[5, 18, 15, 0, 11]\n",
      "[2, 19, 8, 10, 0]\n",
      "[0, 17, 12, 1, 11]\n",
      "[5, 2, 0, 4, 6]\n",
      "[3, 18, 6, 19, 13]\n",
      "[10, 11, 13, 8, 0]\n",
      "[12, 7, 0, 19, 14]\n",
      "[11, 5, 0, 4, 8]\n",
      "[15, 2, 3, 11, 18]\n",
      "[7, 4, 19, 2, 0]\n",
      "[16, 5, 17, 11, 2]\n",
      "[18, 7, 0, 8, 16]\n",
      "[7, 12, 16, 0, 3]\n",
      "[0, 15, 9, 4, 6]\n",
      "[14, 1, 10, 0, 12]\n",
      "[3, 11, 16, 0, 7]\n",
      "[15, 1, 4, 0, 14]\n",
      "[2, 0, 6, 14, 9]\n",
      "[3, 12, 2, 1, 4]\n",
      "[11, 12, 7, 2, 15]\n",
      "[7, 15, 0, 10, 6]\n",
      "[12, 0, 5, 4, 13]\n",
      "[18, 0, 1, 5, 2]\n",
      "[0, 3, 9, 4, 5]\n",
      "[1, 9, 6, 0, 2]\n",
      "[2, 1, 18, 11, 19]\n",
      "[4, 2, 19, 16, 0]\n",
      "[0, 2, 12, 17, 9]\n",
      "[7, 18, 19, 2, 6]\n",
      "[1, 4, 7, 17, 6]\n",
      "[2, 5, 16, 0, 18]\n",
      "[14, 15, 13, 19, 3]\n",
      "[1, 8, 0, 14, 16]\n",
      "[0, 3, 8, 9, 19]\n",
      "[19, 3, 1, 9, 8]\n",
      "[0, 18, 6, 2, 3]\n",
      "[8, 17, 13, 6, 10]\n",
      "[0, 2, 1, 8, 17]\n",
      "[3, 7, 15, 1, 12]\n",
      "[3, 5, 2, 19, 0]\n",
      "[1, 14, 3, 18, 12]\n",
      "[14, 18, 2, 17, 0]\n",
      "[4, 11, 14, 16, 8]\n",
      "[7, 17, 2, 15, 19]\n",
      "[18, 10, 13, 3, 7]\n",
      "[7, 1, 6, 15, 2]\n",
      "[16, 13, 1, 8, 7]\n",
      "[4, 6, 2, 1, 7]\n",
      "[16, 2, 13, 1, 14]\n",
      "[18, 0, 14, 1, 17]\n",
      "[4, 15, 6, 14, 2]\n",
      "[0, 17, 1, 11, 10]\n",
      "[13, 1, 2, 6, 10]\n",
      "[19, 15, 16, 6, 8]\n",
      "[5, 0, 13, 11, 3]\n",
      "[7, 12, 6, 9, 2]\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_5 = topN(list(testRS[i]),5) #\n",
    "    count_0_all.append(top_5)\n",
    "    print(top_5)\n",
    "    for j in range(len(top_5)):\n",
    "        if top_5[j] < int(np.sum(target[i])):\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.21466666666666667 recall  0.5366666666666666\n"
     ]
    }
   ],
   "source": [
    "top5_prec = correct/(len(testRS)*5)\n",
    "top5_recall = correct/(sumtarget)\n",
    "print('prec ',top5_prec,'recall ',top5_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: 0.3066666666666667\n"
     ]
    }
   ],
   "source": [
    "#f1 score\n",
    "print('F1_score:',F1_score(top5_prec,top5_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaddata = np.load('../Data/latent_factor/0_0.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "User_latent_factor = loaddata['User']\n",
    "YouTuber_latent_factor = loaddata['YouTuber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 1489, 128)\n",
      "(140, 88, 128)\n"
     ]
    }
   ],
   "source": [
    "print(User_latent_factor.shape)\n",
    "print(YouTuber_latent_factor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09262235, -0.07439136,  0.00155749, ..., -0.07487268,\n",
       "        -0.02528663, -0.00655919],\n",
       "       [-0.11952104, -0.00523345, -0.00117738, ...,  0.06385711,\n",
       "         0.07218839, -0.13394912],\n",
       "       [ 0.15034142,  0.03697095,  0.05438279, ..., -0.02960717,\n",
       "         0.12263244,  0.0829374 ],\n",
       "       ...,\n",
       "       [-0.25210676,  0.11575705,  0.10584038, ..., -0.08173846,\n",
       "        -0.03480363,  0.08626124],\n",
       "       [-0.06635989,  0.19320491, -0.15399617, ...,  0.09256274,\n",
       "        -0.0277265 , -0.04665166],\n",
       "       [-0.04696163, -0.09584661,  0.03970387, ...,  0.00857876,\n",
       "         0.13848732,  0.02843303]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "User_latent_factor[139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05488598e-01, -8.71802345e-02,  1.18648242e-02, ...,\n",
       "        -8.76639783e-02, -3.74541730e-02, -1.73222553e-02],\n",
       "       [-1.20766789e-01, -4.02020710e-03,  1.30983084e-04, ...,\n",
       "         6.51101023e-02,  7.34319538e-02, -1.32882565e-01],\n",
       "       [ 1.49330139e-01,  3.79822180e-02,  5.53940684e-02, ...,\n",
       "        -2.85958778e-02,  1.23643726e-01,  8.39484707e-02],\n",
       "       ...,\n",
       "       [-7.58756176e-02, -5.20650204e-03, -1.19225644e-01, ...,\n",
       "        -3.81558798e-02,  7.09720924e-02,  3.08277160e-02],\n",
       "       [ 2.59203613e-02, -2.47363211e-03,  7.64821097e-02, ...,\n",
       "         1.28513249e-03, -9.45569798e-02, -1.27508372e-01],\n",
       "       [-9.71664861e-02, -6.25763312e-02,  7.75660202e-02, ...,\n",
       "         3.47987786e-02,  3.43698896e-02, -1.14809208e-01]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTuber_latent_factor[139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
