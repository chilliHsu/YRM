{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pandas as pd\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Img0.5_ALL_E150.npz',\n",
       " 'Img0.5_ALL_E160.npz',\n",
       " 'Img0.5_ALL_E170.npz',\n",
       " 'Img0.5_ALL_E180.npz',\n",
       " 'Img0.5_ALL_E190.npz',\n",
       " 'Img0.5_ALL_E200.npz',\n",
       " 'Img0.5_ALL_E210.npz',\n",
       " 'Img0.5_ALL_E220.npz',\n",
       " 'Img0.5_ALL_E230.npz',\n",
       " 'Img0.5_ALL_E240.npz',\n",
       " 'Img0.5_ALL_E250.npz']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#從grid_search_weight中找尋不同的file \n",
    "path = 'D:/ChilliHsu/Data/grid_search_weight/Our/Dimension/'\n",
    "all_files = os.listdir(path)\n",
    "files = [file for file in all_files if 'Img0.5' in file and '.npz' in file]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_sum(pars):\n",
    "    all_squ_sum = []\n",
    "    for par in pars:\n",
    "        all_squ_sum.append(np.sum(np.multiply(par,par)))\n",
    "    return all_squ_sum \n",
    "def shape_sum(pars):\n",
    "    all_shape = []\n",
    "    for par in pars:\n",
    "        all_shape.append(par.shape)\n",
    "    return all_shape\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_following = np.load('../Data/npy/user_following_1489.npy')\n",
    "all_3374 = np.load('../Data/npy/all_2939D_img0.5.npy')\n",
    "user_category = np.load('../Data/npy/user_category_1489.npy')\n",
    "YouTuber_category = np.load('../Data/npy/YouTuber_category_0.7.npy')\n",
    "active_users = np.load('../Data/npy/active_userID_1489.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_category after normalized by max...\n",
      "user_category_norm shape  (1489, 17)\n",
      "user cateogory norm [[0.         1.         0.         ... 0.05714286 0.         0.        ]\n",
      " [0.24390244 0.         0.02439024 ... 0.         0.         0.09756098]\n",
      " [0.04210526 0.04210526 0.05263158 ... 0.02105263 0.         0.02105263]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.01408451 0.01408451 0.04225352 ... 0.02816901 0.         0.02816901]\n",
      " [0.03703704 0.22222222 0.14814815 ... 0.         0.         0.        ]]\n",
      "Min number of followings  5\n",
      "Max number of followings  34\n",
      "[3, 6, 10, 18, 26, 37, 44, 46, 59, 65, 67, 75, 95, 99, 106, 114, 116, 133, 135, 147, 160, 165, 186, 188, 208, 221, 231, 243, 259, 270, 284, 298, 303, 304, 321, 326, 330, 339, 340, 360, 363, 370, 372, 378, 402, 403, 407, 419, 426, 428, 441, 443, 486, 503, 504, 510, 512, 513, 523, 524, 540, 564, 572, 592, 605, 611, 617, 626, 627, 633, 634, 639, 642, 646, 648, 679, 692, 696, 697, 704, 705, 726, 727, 732, 734, 739, 742, 749, 752, 761, 770, 779, 784, 797, 827, 831, 835, 849, 857, 863, 886, 911, 927, 933, 946, 947, 953, 960, 967, 984, 985, 990, 1049, 1050, 1074, 1085, 1092, 1104, 1113, 1116, 1124, 1175, 1184, 1200, 1207, 1216, 1220, 1230, 1235, 1250, 1264, 1265, 1275, 1277, 1281, 1283, 1307, 1329, 1333, 1335, 1388, 1404, 1411, 1414, 1426, 1438, 1443, 1449, 1474, 1476]\n",
      "5.466666666666667\n"
     ]
    }
   ],
   "source": [
    "#over5 = 0\n",
    "#for num in YouTuber_followers:\n",
    "#    if num >= 5:\n",
    "#        over5+=1\n",
    "#print('The num of followers over 5:',over5)\n",
    "user_category_norm = np.zeros(user_category.shape)\n",
    "for i in range(len(user_category)):\n",
    "    user_category_norm[i] = user_category[i]/np.max(user_category[i])\n",
    "print('user_category after normalized by max...')\n",
    "print('user_category_norm shape ',user_category_norm.shape)\n",
    "print('user cateogory norm',user_category_norm)\n",
    "following_true = [0]*len(user_following)\n",
    "for i in range(len(user_following)):\n",
    "    each_user = []\n",
    "    for j in range(len(user_following[i])):\n",
    "        if user_following[i][j] == 1:\n",
    "            each_user.append(j)\n",
    "    following_true[i] = each_user\n",
    "#print(following_true)\n",
    "#最少跟最多的following \n",
    "minlen = 10000\n",
    "maxlen = 0\n",
    "num_of_follower = []\n",
    "for i in range(len(following_true)):\n",
    "    if len(following_true[i]) < minlen:\n",
    "        minlen = len(following_true[i])\n",
    "    if len(following_true[i]) > maxlen:\n",
    "        maxlen = len(following_true[i])\n",
    "    num_of_follower.append(len(following_true[i]))\n",
    "print('Min number of followings ',minlen)\n",
    "print('Max number of followings ',maxlen)\n",
    "test_amount = 150\n",
    "yt_test_amount = 18\n",
    "user_idx = [i for i in range(len(user_following))]\n",
    "#user_idx = user_idx_over10\n",
    "#test_idx is the number of user for testing\n",
    "random.seed(5)\n",
    "test_idx = sorted(random.sample(user_idx,test_amount))\n",
    "print(test_idx)\n",
    "# Training  and Testing --New\n",
    "train_t = [0]*(len(user_following))\n",
    "train_f = [0]*(len(user_following))\n",
    "# Testing \n",
    "test_t = [0]*test_amount\n",
    "test_f = [0]*test_amount\n",
    "test_pos = -1\n",
    "\n",
    "for i in range(len(user_following)):\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "        for j in range(88):\n",
    "            if user_following[i][j] == 1:\n",
    "                t_for_train.append(j)\n",
    "            else:\n",
    "                f_for_train.append(j)\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train\n",
    "        \n",
    "    else: #if in test id, choose 2 true and other \n",
    "        test_pos += 1\n",
    "        temp_t = []\n",
    "        temp_f = []\n",
    "        for j in range(88):\n",
    "            if user_following[i][j] == 1:\n",
    "                temp_t.append(j)\n",
    "            else:\n",
    "                temp_f.append(j)\n",
    "        #print(len(temp_t),math.ceil(0.5*len(temp_t)))\n",
    "        t_for_test = random.sample(temp_t,math.ceil(0.5*len(temp_t)))\n",
    "        f_for_test  = random.sample(temp_f,yt_test_amount-len(t_for_test))\n",
    "        \n",
    "        test_t[test_pos] = t_for_test\n",
    "        test_f[test_pos] = f_for_test\n",
    "        \n",
    "        #other for training\n",
    "        t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "        #print(len(t_for_train ))\n",
    "        f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test/test_amount\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "index = 0 \n",
    "for train_idx in range(len(train_t)):\n",
    "    if train_idx in test_idx:\n",
    "        #print(len(train_t[train_idx])+len(train_f[train_idx])+len(test_t[index])+len(test_f[index]))\n",
    "        #print(train_f[train_idx])\n",
    "        #print(test_f[index])\n",
    "        all_idx = train_t[train_idx]+train_f[train_idx]+test_t[index]+test_f[index]\n",
    "        print(len(sorted(list(set(all_idx)))))\n",
    "        index+=1\n",
    "    else:\n",
    "        all_idx = train_t[train_idx]+train_f[train_idx]\n",
    "        print(len(sorted(list(set(all_idx)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScoreMatrix(RS):\n",
    "    #取出test的資料\n",
    "    print('RS shape',RS.shape)\n",
    "    testRS = np.zeros((test_amount,yt_test_amount)) #shape 150*18\n",
    "    target = np.zeros((test_amount,yt_test_amount))\n",
    "    #test_t 是true的\n",
    "    #test_f 是false的\n",
    "\n",
    "    for z in range(test_amount):\n",
    "        user_id = test_idx[z]\n",
    "        #positive target YouTuber list\n",
    "        youtube_t = test_t[z] \n",
    "        #not target YouTuber list\n",
    "        youtube_f = test_f[z]\n",
    "\n",
    "        #前兩個放target的RS\n",
    "        for i in range(len(youtube_t)):\n",
    "            testRS[z][i] = RS[z][youtube_t[i]]\n",
    "            target[z][i] = user_following[user_id][youtube_t[i]]\n",
    "        for i in range(len(youtube_f)):\n",
    "            testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]\n",
    "            target[z][i+len(youtube_t)] = user_following[user_id][youtube_f[i]]\n",
    "    sumtarget = 0\n",
    "    for i in range(len(target)):\n",
    "        #print(np.sum(target[i]))\n",
    "        sumtarget += np.sum(target[i])\n",
    "    print('num of positive data in testing:',sumtarget)\n",
    "    print('total testing data:',test_amount*yt_test_amount)\n",
    "    return target, testRS,sumtarget\n",
    "\n",
    "def topN(sortlist,n):\n",
    "    topList = []\n",
    "    for i in range(n):\n",
    "        topList.append(sortlist.index(max(sortlist)))\n",
    "        #print(max(sortlist))\n",
    "        #print(sortlist.index(max(sortlist)))\n",
    "        sortlist[sortlist.index(max(sortlist))] = -1000000000\n",
    "    return topList\n",
    "\n",
    "def F1_score(prec,rec):\n",
    "    f1 = (2*prec*rec)/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTOP1(target,testRS,sumtarget):\n",
    "    print('top1')\n",
    "    correct = 0\n",
    "    for i in range(len(testRS)):\n",
    "        top_0 = topN(list(testRS[i]),1) #取一個\n",
    "        \n",
    "        #print(top_0)\n",
    "        if top_0[0] < int(np.sum(target[i])):\n",
    "            correct += 1\n",
    "    top1_prec = correct/len(testRS)\n",
    "    top1_recall = correct/(sumtarget)\n",
    "    print('prec ',top1_prec,'recall ',top1_recall)\n",
    "    #f1 score\n",
    "    print('F1_score:',F1_score(top1_prec,top1_recall))\n",
    "    return top1_prec,top1_recall,F1_score(top1_prec,top1_recall)\n",
    "def getTOP3(target,testRS,sumtarget):\n",
    "    print('top3')\n",
    "    correct = 0\n",
    "    for i in range(len(testRS)):\n",
    "        top_3 = topN(list(testRS[i]),3) #取一個\n",
    "        \n",
    "        #print(top_3)\n",
    "        for j in range(len(top_3)):\n",
    "            if top_3[j] < int(np.sum(target[i])):\n",
    "                correct += 1\n",
    "    top3_prec = correct/(len(testRS)*3)\n",
    "    top3_recall = correct/(sumtarget)\n",
    "    print('prec ',top3_prec,'recall ',top3_recall)\n",
    "    #f1 score\n",
    "    print('F1_score:',F1_score(top3_prec,top3_recall))\n",
    "    return top3_prec,top3_recall,F1_score(top3_prec,top3_recall)\n",
    "def getTOP5(target,testRS,sumtarget):\n",
    "    print('top5')\n",
    "    correct = 0\n",
    "    for i in range(len(testRS)):\n",
    "        top_5 = topN(list(testRS[i]),5) #取一個\n",
    "       \n",
    "        #print(top_5)\n",
    "        for j in range(len(top_5)):\n",
    "            if top_5[j] < int(np.sum(target[i])):\n",
    "                correct += 1\n",
    "    top5_prec = correct/(len(testRS)*5)\n",
    "    top5_recall = correct/(sumtarget)\n",
    "    print('prec ',top5_prec,'recall ',top5_recall)\n",
    "    #f1 score\n",
    "    print('F1_score:',F1_score(top5_prec,top5_recall))\n",
    "    return top5_prec,top5_recall,F1_score(top5_prec,top5_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NDCG\n",
    "https://daiwk.github.io/posts/nlp-ndcg.html\n",
    "\"\"\"\n",
    "# pre_list\n",
    "\"\"\"\n",
    "test_amount = 150\n",
    "yt_test_amount = 18\n",
    "\"\"\"\n",
    "def NDCG(target,testRS): #target是真正的喜好\n",
    "    all_sort = []\n",
    "    num_ndcg = 10\n",
    "    pre_matrix = np.zeros(shape=(test_amount,yt_test_amount)) #(150,18)\n",
    "    for i in range(test_amount): #user amount = 150\n",
    "        top_n = topN(list(testRS[i]),num_ndcg) #取10個\n",
    "        #print(top_n)\n",
    "        all_sort.append(topN(list(testRS[i]),len(testRS[i])))\n",
    "        #print('all_sort',topN(list(testRS[i]),len(testRS[i])))\n",
    "        for j in range(len(top_n)):\n",
    "            pre_matrix[i][top_n[j]] = 1\n",
    "\n",
    "    #Ideal DCG，理想状况下的DCG。也就是说，相关性完全由高到低排序时算出的DCG：\n",
    "    def IDCG(ideal_list): #ideal_list example = [1,1,1,1,1,0,0,....]\n",
    "        idcg=0\n",
    "        #print('ideal',ideal_list)\n",
    "        for i in range(len(ideal_list)):\n",
    "            #print((2**true_list[i]-1),math.log2(i+2))\n",
    "            idcg+= (2**ideal_list[i]-1)/ math.log2(i+2)\n",
    "        #print('idcg',idcg)\n",
    "        return idcg\n",
    "    def DCG(prec_list): #找出前n名的[1,1,1,0,...]\n",
    "        dcg=0\n",
    "        #print('prec',prec_list)\n",
    "        for i in range(len(prec_list)):\n",
    "            dcg+= (2**prec_list[i]-1)/ math.log2(i+2)\n",
    "        #print('dcg',dcg)\n",
    "        return dcg\n",
    "    total_ndcg = 0\n",
    "    \n",
    "    for m in range(test_amount): # the number of testing users\n",
    "        idcg = IDCG(target[m][:num_ndcg])\n",
    "        pre_list = []\n",
    "        least_pre_list = []\n",
    "        for s in all_sort[m][:num_ndcg]:\n",
    "            #print(m,s,target[m][s])\n",
    "            pre_list.append(target[m][s]) #把prec_list 的 score加進去\n",
    "        for s in all_sort[m][num_ndcg:]:\n",
    "            #print(s)\n",
    "            #print(target[m][s])\n",
    "            least_pre_list.append(target[m][s]) #把prec_list 的 score加進去\n",
    "        dcg = DCG(pre_list)\n",
    "        ndcg = dcg/idcg\n",
    "        #print(ndcg)\n",
    "        total_ndcg += ndcg\n",
    "    avg_ndcg = total_ndcg/test_amount\n",
    "    print('NDCG:',avg_ndcg)\n",
    "    return pre_matrix,avg_ndcg\n",
    "\n",
    "# MAP\n",
    "\"\"\"\n",
    ">>> y_true = np.array([0, 0, 1, 1])\n",
    ">>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    ">>> average_precision_score(y_true, y_scores)\n",
    "\"\"\"\n",
    "def MAP(target,testRS):\n",
    "    print('target:',target)\n",
    "    print('testRS:',testRS)\n",
    "    total_prec = 0\n",
    "    for u in range(test_amount):\n",
    "        y_true = target[u]\n",
    "        y_scores = testRS[u]\n",
    "        total_prec+=average_precision_score(y_true, y_scores)\n",
    "    Map_value = total_prec/test_amount\n",
    "    print('MAP',Map_value)\n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(U, Y, A, E,Au, Ay, Aa, Av,B):\n",
    "    \n",
    "    test_amount = 150\n",
    "    yt_test_amount = 18\n",
    "    result=np.zeros((test_amount,88))\n",
    "    RS=np.zeros((test_amount,88))\n",
    "    #test_idx --> Test 的 index\n",
    "    sum_alpha = 0\n",
    "    for s in range(test_amount):\n",
    "        #print(s,test_idx[s])\n",
    "\n",
    "        yes=[]\n",
    "        #sample=random.sample(train_t[test_idx[s]],len(train_t[test_idx[s]])) #從training part 的positive feedback 取出YouTuber 當成Auxilary\n",
    "        sample = [i for i in range(88)]\n",
    "        #sample = train_t[test_idx[s]]\n",
    "        \n",
    "        #sample=result_yes_id[now]\n",
    "        alpha=np.zeros([len(sample)])\n",
    "\n",
    "        for a in range(len(sample)):\n",
    "            r =np.max(YouTuber_category[sample[a]]*user_category_norm[test_idx[s]]) #sample a 的category vec *user_category vec\n",
    "            alpha_a = np.dot(Au[test_idx[s]][sample[a]],np.expand_dims(U[test_idx[s]],0).T)+np.dot(Ay[test_idx[s]][sample[a]],np.expand_dims(Y[sample[a]],0).T)+np.dot(Aa[test_idx[s]][sample[a]],\n",
    "                    np.expand_dims(A[sample[a]],0).T)+ np.dot(Av[test_idx[s]][sample[a]],np.dot(E,np.expand_dims(all_3374[sample[a]],0).T))\n",
    "            \"\"\"\n",
    "            relu part ...\n",
    "            \"\"\"\n",
    "            alpha[a]=np.sum((relu(alpha_a)))*r\n",
    "            \"\"\"\n",
    "            tanh part ...\n",
    "            \"\"\"\n",
    "            #alpha[a]=np.sum((np.tanh(alpha_a)))*r\n",
    "            \n",
    "            \n",
    "        mul=np.zeros((1,64))\n",
    "        #print('alpha--------',alpha)\n",
    "        #print('add alpha------------',np.add(alpha,0.000000001))\n",
    "        added_alpha = np.add(np.maximum(alpha, 0),0.0000000001)\n",
    "        norm_alpha = added_alpha/np.sum(added_alpha)\n",
    "        #print('alpha-----------',alpha)\n",
    "        #print('norm alpha--------------',norm_alpha)\n",
    "        sum_alpha += np.sum(alpha)\n",
    "        for i in range(len(sample)):\n",
    "            mul+=norm_alpha[i]*A[sample[i]] #attention alpha*Ai part\n",
    "        new_mul=mul+U[test_idx[s]]  #(U+auxilary)\n",
    "    \n",
    "        \n",
    "        \n",
    "        for k in range(88):\n",
    "            result[s][k]=np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "            RS[s][k] = np.dot(new_mul,Y[k].T)+np.dot(B[test_idx[s]],np.dot(E, all_3374[k].T))\n",
    "            \n",
    "    print('sum_alpha',sum_alpha)\n",
    "    return RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Img0.5_ALL_E150.npz',\n",
       " 'Img0.5_ALL_E160.npz',\n",
       " 'Img0.5_ALL_E170.npz',\n",
       " 'Img0.5_ALL_E180.npz',\n",
       " 'Img0.5_ALL_E190.npz',\n",
       " 'Img0.5_ALL_E200.npz',\n",
       " 'Img0.5_ALL_E210.npz',\n",
       " 'Img0.5_ALL_E220.npz',\n",
       " 'Img0.5_ALL_E230.npz',\n",
       " 'Img0.5_ALL_E240.npz',\n",
       " 'Img0.5_ALL_E250.npz']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#With Embedding\n",
    "import os \n",
    "#從grid_search_weight中找尋不同的file \n",
    "path = '../Data/grid_search_weight/Our/'\n",
    "all_files = os.listdir(path)\n",
    "new_all_files = []\n",
    "for file in all_files:\n",
    "    if 'ALL' in file:\n",
    "        new_all_files.append(file)\n",
    "all_files = new_all_files\n",
    "print(all_files)\n",
    "all_files = ['Img0.5_ALL_E150.npz','Img0.5_ALL_E160.npz','Img0.5_ALL_E170.npz']\"\"\"\n",
    "all_files = files\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/grid_search_weight/Our/Dimension/'\n",
    "#all_files = ['Img0.5_ALL_E150.npz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Img0.5_ALL']\n",
      "Img0.5_ALL_E150.npz\n",
      "sum_alpha 3.0750550994598838\n",
      "RS shape (150, 88)\n",
      "num of positive data in testing: 820.0\n",
      "total testing data: 2700\n",
      "top1\n",
      "prec  0.7533333333333333 recall  0.1378048780487805\n",
      "F1_score: 0.2329896907216495\n",
      "top3\n",
      "prec  0.6888888888888889 recall  0.3780487804878049\n",
      "F1_score: 0.48818897637795267\n",
      "top5\n",
      "prec  0.6306666666666667 recall  0.5768292682926829\n",
      "F1_score: 0.6025477707006369\n",
      "NDCG: 0.8137306986354945\n",
      "target: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "testRS: [[ 0.75143993  0.5449787   2.82483478 ...  0.59418849 -4.28071483\n",
      "  -4.95285718]\n",
      " [ 2.2871334   1.12219407  2.53280818 ...  1.77540384 -1.09365622\n",
      "   1.9905526 ]\n",
      " [-1.85267849  1.22839205  1.69518074 ... -3.1334452  -3.01955887\n",
      "  -3.77707551]\n",
      " ...\n",
      " [ 0.05939156 -0.37174721 -1.53542544 ... -1.19099339 -2.8990944\n",
      "  -2.52105059]\n",
      " [ 1.27485579 -1.90758565  0.42914706 ... -1.48810054 -3.30071359\n",
      "  -3.2351926 ]\n",
      " [ 1.05832612  3.28721598  2.77312569 ... -2.41653921 -1.80259392\n",
      "   3.14512607]]\n",
      "MAP 0.7336752364981649\n",
      "--------------------------------------------------------------------------------------------\n",
      "Img0.5_ALL_E160.npz\n",
      "sum_alpha 2.983189378444462\n",
      "RS shape (150, 88)\n",
      "num of positive data in testing: 820.0\n",
      "total testing data: 2700\n",
      "top1\n",
      "prec  0.68 recall  0.12439024390243902\n",
      "F1_score: 0.21030927835051547\n",
      "top3\n",
      "prec  0.6888888888888889 recall  0.3780487804878049\n",
      "F1_score: 0.48818897637795267\n",
      "top5\n",
      "prec  0.6426666666666667 recall  0.5878048780487805\n",
      "F1_score: 0.6140127388535033\n",
      "NDCG: 0.8036232488543135\n",
      "target: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "testRS: [[-0.00991497 -0.98109455  0.96008141 ... -1.51777223 -4.82603019\n",
      "  -5.59050094]\n",
      " [ 1.11124881 -0.06320213  1.0422236  ...  0.4557012  -0.86834477\n",
      "   0.1493058 ]\n",
      " [-1.97147932  2.14379437  0.10209186 ... -1.95090578 -2.43610566\n",
      "  -3.21605228]\n",
      " ...\n",
      " [-0.3036269  -0.82564965 -1.8302107  ... -1.11892267 -2.02187209\n",
      "  -2.89511602]\n",
      " [ 3.16071059  0.42181567  4.02013784 ...  0.82462388 -2.99066704\n",
      "  -2.28578027]\n",
      " [ 0.34227278  0.23182486  1.5515406  ... -4.89842453 -6.29426279\n",
      "   1.74497642]]\n",
      "MAP 0.7274482159832767\n",
      "--------------------------------------------------------------------------------------------\n",
      "Img0.5_ALL_E170.npz\n",
      "sum_alpha 3.3446377955344104\n",
      "RS shape (150, 88)\n",
      "num of positive data in testing: 820.0\n",
      "total testing data: 2700\n",
      "top1\n",
      "prec  0.7533333333333333 recall  0.1378048780487805\n",
      "F1_score: 0.2329896907216495\n",
      "top3\n",
      "prec  0.7133333333333334 recall  0.39146341463414636\n",
      "F1_score: 0.505511811023622\n",
      "top5\n",
      "prec  0.6493333333333333 recall  0.5939024390243902\n",
      "F1_score: 0.6203821656050955\n",
      "NDCG: 0.8182336274167566\n",
      "target: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "testRS: [[ 6.05320159e+00  3.94539578e+00  5.87021096e+00 ...  6.14768769e+00\n",
      "  -2.40449633e+00 -3.32622940e+00]\n",
      " [ 8.55571932e-01  1.77470969e-01  1.37930498e+00 ...  1.49764980e-02\n",
      "  -2.74161620e+00  4.80392614e-01]\n",
      " [ 5.64275231e-01  1.66176267e+00  2.99831477e+00 ... -1.51813407e+00\n",
      "  -6.00437422e-01 -9.45935568e-01]\n",
      " ...\n",
      " [ 9.71944412e-01  1.41996128e+00 -6.39127016e-01 ...  1.45764214e+00\n",
      "  -2.83548297e+00 -3.90586690e+00]\n",
      " [ 5.12560128e+00  1.97334291e+00  3.76010194e+00 ...  2.82160257e+00\n",
      "   1.93120841e-03 -7.02922089e-02]\n",
      " [ 2.34101016e+00  3.82143122e+00  2.35296966e+00 ... -1.35644894e+00\n",
      "   8.95971674e-01  3.35555909e+00]]\n",
      "MAP 0.7422462465122555\n",
      "--------------------------------------------------------------------------------------------\n",
      "Img0.5_ALL_E180.npz\n",
      "sum_alpha 2.7883527939227526\n",
      "RS shape (150, 88)\n",
      "num of positive data in testing: 820.0\n",
      "total testing data: 2700\n",
      "top1\n",
      "prec  0.6533333333333333 recall  0.11951219512195121\n",
      "F1_score: 0.2020618556701031\n",
      "top3\n",
      "prec  0.6977777777777778 recall  0.3829268292682927\n",
      "F1_score: 0.4944881889763779\n",
      "top5\n",
      "prec  0.6346666666666667 recall  0.5804878048780487\n",
      "F1_score: 0.6063694267515924\n",
      "NDCG: 0.7971963332661118\n",
      "target: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "testRS: [[ 0.98754681 -1.26586662  1.24320486 ... -1.85502079 -5.41174729\n",
      "  -6.84582023]\n",
      " [ 0.43194341 -0.65823381  0.82170516 ... -0.10479599 -1.56229572\n",
      "  -0.20125918]\n",
      " [-1.76598686  1.67058055 -0.65522689 ... -1.84517663 -2.76386766\n",
      "  -2.9300369 ]\n",
      " ...\n",
      " [-0.52038163 -0.99145421 -1.90559216 ... -1.36185837 -2.38578953\n",
      "  -3.16056341]\n",
      " [ 2.66555601  0.46213758  3.46754976 ...  0.65124002 -2.27659768\n",
      "  -1.56064781]\n",
      " [ 0.30431348 -0.04702269  1.44951204 ... -4.71627436 -5.69054815\n",
      "   1.63574112]]\n",
      "MAP 0.7185042213940493\n",
      "--------------------------------------------------------------------------------------------\n",
      "Img0.5_ALL_E190.npz\n",
      "sum_alpha 3.0928580089366693\n",
      "RS shape (150, 88)\n",
      "num of positive data in testing: 820.0\n",
      "total testing data: 2700\n",
      "top1\n",
      "prec  0.74 recall  0.1353658536585366\n",
      "F1_score: 0.22886597938144332\n",
      "top3\n",
      "prec  0.7288888888888889 recall  0.4\n",
      "F1_score: 0.5165354330708661\n",
      "top5\n",
      "prec  0.6546666666666666 recall  0.598780487804878\n",
      "F1_score: 0.6254777070063694\n",
      "NDCG: 0.8197714388103451\n",
      "target: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "testRS: [[ 6.01748705  3.97916711  5.70018852 ...  6.06768073 -2.85058724\n",
      "  -3.26068593]\n",
      " [ 0.6036533   0.07363736  0.91929588 ... -0.46608654 -1.9864584\n",
      "   1.36940547]\n",
      " [ 0.5404814   1.45934286  2.57021076 ... -0.93469544 -0.8389429\n",
      "  -0.34315423]\n",
      " ...\n",
      " [ 1.81548753  2.21602898  0.23969505 ...  2.16843466 -2.68391748\n",
      "  -3.23445281]\n",
      " [ 5.30053894  1.62182896  3.32556018 ...  1.49809259 -0.72193935\n",
      "  -0.67988734]\n",
      " [ 3.85079279  2.38539669  2.1036973  ... -2.15258215  0.4509916\n",
      "   1.98531799]]\n",
      "MAP 0.7489659063594888\n",
      "--------------------------------------------------------------------------------------------\n",
      "Img0.5_ALL_E200.npz\n",
      "sum_alpha 3.0585308983347868\n",
      "RS shape (150, 88)\n",
      "num of positive data in testing: 820.0\n",
      "total testing data: 2700\n",
      "top1\n",
      "prec  0.7866666666666666 recall  0.14390243902439023\n",
      "F1_score: 0.24329896907216492\n",
      "top3\n",
      "prec  0.7422222222222222 recall  0.4073170731707317\n",
      "F1_score: 0.525984251968504\n",
      "top5\n",
      "prec  0.6733333333333333 recall  0.6158536585365854\n",
      "F1_score: 0.6433121019108281\n",
      "NDCG: 0.8504844217886027\n",
      "target: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "testRS: [[ 6.3112811   3.88200431  5.19416544 ...  5.27566049 -1.71929768\n",
      "  -2.2656897 ]\n",
      " [-1.93146716 -2.09466272 -0.75386693 ... -3.68288663 -3.348997\n",
      "  -1.20924024]\n",
      " [ 0.55632731  2.16292837  3.00732071 ... -0.9656013  -2.6621568\n",
      "  -1.47100252]\n",
      " ...\n",
      " [ 0.72526791 -0.29205659 -0.0804826  ...  0.92738235 -1.32167657\n",
      "  -2.59250501]\n",
      " [ 4.58799747  2.37768868  4.14670401 ...  1.44126216 -0.39474283\n",
      "  -1.02340148]\n",
      " [ 3.59372612  7.91880732  5.29402726 ...  2.25280841  1.45835149\n",
      "   6.63739326]]\n",
      "MAP 0.7779707490186925\n",
      "--------------------------------------------------------------------------------------------\n",
      "Img0.5_ALL_E210.npz\n",
      "sum_alpha 3.036913951501396\n",
      "RS shape (150, 88)\n",
      "num of positive data in testing: 820.0\n",
      "total testing data: 2700\n",
      "top1\n",
      "prec  0.78 recall  0.14268292682926828\n",
      "F1_score: 0.24123711340206183\n",
      "top3\n",
      "prec  0.7533333333333333 recall  0.41341463414634144\n",
      "F1_score: 0.5338582677165353\n",
      "top5\n",
      "prec  0.664 recall  0.6073170731707317\n",
      "F1_score: 0.6343949044585987\n",
      "NDCG: 0.8375956509527985\n",
      "target: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "testRS: [[ 3.82932059  1.06181289  3.19890551 ...  1.49841866 -2.69236679\n",
      "  -3.54713518]\n",
      " [-0.32735872 -1.80168656 -0.11278619 ... -0.9295705  -2.33256072\n",
      "   0.50228576]\n",
      " [-1.46718555  1.310109    0.91524918 ... -2.05978196 -2.12730914\n",
      "  -2.99217907]\n",
      " ...\n",
      " [ 0.36432784  0.08042165 -0.59481569 ...  0.02513794 -1.75023983\n",
      "  -1.25572917]\n",
      " [ 4.70112685  1.57816854  3.89979982 ...  2.04952145 -0.77262117\n",
      "  -1.02537505]\n",
      " [ 1.92379195  0.98549388  2.52840832 ... -1.86570511 -2.59602605\n",
      "   2.33012411]]\n",
      "MAP 0.7660444559201166\n",
      "--------------------------------------------------------------------------------------------\n",
      "Img0.5_ALL_E220.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_alpha 3.0122749167664455\n",
      "RS shape (150, 88)\n",
      "num of positive data in testing: 820.0\n",
      "total testing data: 2700\n",
      "top1\n",
      "prec  0.74 recall  0.1353658536585366\n",
      "F1_score: 0.22886597938144332\n",
      "top3\n",
      "prec  0.7 recall  0.38414634146341464\n",
      "F1_score: 0.49606299212598426\n",
      "top5\n",
      "prec  0.6386666666666667 recall  0.5841463414634146\n",
      "F1_score: 0.6101910828025477\n",
      "NDCG: 0.8160627563388737\n",
      "target: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "testRS: [[ 4.58541055  2.4597297   4.06965662 ...  3.29635486 -3.37544953\n",
      "  -2.75169015]\n",
      " [-0.66160165 -2.14028611 -0.22498502 ...  0.15207052 -4.3693835\n",
      "   1.7855203 ]\n",
      " [-1.04745033  2.18550255  0.86152701 ... -2.70225732 -2.71086138\n",
      "  -2.17411529]\n",
      " ...\n",
      " [ 0.33288838  1.81791098 -0.56618697 ... -0.00546101 -3.65690279\n",
      "  -3.30766096]\n",
      " [ 5.1916114   2.79716284  3.89745765 ...  0.95669344 -0.77966031\n",
      "  -1.22908724]\n",
      " [ 3.0886605   1.38326941  3.2183775  ... -0.72235584 -0.35159096\n",
      "   1.58306451]]\n",
      "MAP 0.7495590610449745\n",
      "--------------------------------------------------------------------------------------------\n",
      "Img0.5_ALL_E230.npz\n",
      "sum_alpha 3.0077772833277945\n",
      "RS shape (150, 88)\n",
      "num of positive data in testing: 820.0\n",
      "total testing data: 2700\n",
      "top1\n",
      "prec  0.68 recall  0.12439024390243902\n",
      "F1_score: 0.21030927835051547\n",
      "top3\n",
      "prec  0.6755555555555556 recall  0.37073170731707317\n",
      "F1_score: 0.47874015748031495\n",
      "top5\n",
      "prec  0.648 recall  0.5926829268292683\n",
      "F1_score: 0.6191082802547772\n",
      "NDCG: 0.7962523414751714\n",
      "target: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "testRS: [[ 5.7506303   4.50218666  5.05435039 ...  5.04178158 -1.72970472\n",
      "  -1.80286596]\n",
      " [-0.44522773 -1.77412394  0.60623732 ...  0.16875399 -1.51538545\n",
      "   3.13499639]\n",
      " [ 1.02849125  0.96173615  3.37001914 ... -1.33043377 -0.18460743\n",
      "  -0.46781141]\n",
      " ...\n",
      " [ 1.20953296 -1.45156218  0.64566782 ...  1.37849127  0.98684927\n",
      "  -0.09623908]\n",
      " [ 3.40977769  1.17914933  1.77348128 ...  0.19262775 -3.2730144\n",
      "  -2.7253556 ]\n",
      " [ 3.76688985  6.77877456  6.20351687 ...  1.13942882  1.05623639\n",
      "   5.82722703]]\n",
      "MAP 0.7212716790132534\n",
      "--------------------------------------------------------------------------------------------\n",
      "Img0.5_ALL_E240.npz\n",
      "sum_alpha 2.896947441975477\n",
      "RS shape (150, 88)\n",
      "num of positive data in testing: 820.0\n",
      "total testing data: 2700\n",
      "top1\n",
      "prec  0.7333333333333333 recall  0.13414634146341464\n",
      "F1_score: 0.2268041237113402\n",
      "top3\n",
      "prec  0.6866666666666666 recall  0.37682926829268293\n",
      "F1_score: 0.4866141732283465\n",
      "top5\n",
      "prec  0.6453333333333333 recall  0.5902439024390244\n",
      "F1_score: 0.6165605095541401\n",
      "NDCG: 0.8103718751010756\n",
      "target: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "testRS: [[ 2.49807987 -2.37567188  1.13615836 ... -1.43330639 -4.26033655\n",
      "  -6.27381394]\n",
      " [ 0.70357513  0.32576896  1.65375042 ...  1.01908101 -1.91263709\n",
      "  -0.14558629]\n",
      " [-1.981789    4.275821    1.29394374 ... -2.54883739 -1.64278658\n",
      "  -2.4378955 ]\n",
      " ...\n",
      " [ 1.51581592  1.6998157   0.41668763 ...  0.84126637 -0.65205512\n",
      "  -0.08788426]\n",
      " [ 3.355323    0.21248879  2.65912831 ...  0.4626759  -2.90664983\n",
      "  -1.82548952]\n",
      " [ 1.45636008  5.1925973   3.68829356 ... -1.51332751 -2.15371421\n",
      "   3.71148937]]\n",
      "MAP 0.7323328252962239\n",
      "--------------------------------------------------------------------------------------------\n",
      "Img0.5_ALL_E250.npz\n",
      "sum_alpha 3.145307672828637\n",
      "RS shape (150, 88)\n",
      "num of positive data in testing: 820.0\n",
      "total testing data: 2700\n",
      "top1\n",
      "prec  0.78 recall  0.14268292682926828\n",
      "F1_score: 0.24123711340206183\n",
      "top3\n",
      "prec  0.6777777777777778 recall  0.3719512195121951\n",
      "F1_score: 0.48031496062992135\n",
      "top5\n",
      "prec  0.6266666666666667 recall  0.573170731707317\n",
      "F1_score: 0.5987261146496816\n",
      "NDCG: 0.8036479669565793\n",
      "target: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "testRS: [[ 3.28234304 -0.27480181  2.08915408 ... -0.19357143 -2.50262096\n",
      "  -5.35767059]\n",
      " [ 0.25618522 -0.72705495  0.65441959 ...  0.56649895 -2.09115537\n",
      "   0.07864929]\n",
      " [-0.5413433   2.040034    0.35326978 ... -1.66455641 -1.40348711\n",
      "  -2.06706013]\n",
      " ...\n",
      " [ 0.30069294  0.2305488  -0.81448774 ... -0.52719614 -1.31668804\n",
      "  -1.03625434]\n",
      " [ 6.46321634  3.41557992  4.89431698 ...  3.79243924 -0.09624096\n",
      "   0.34931995]\n",
      " [ 3.61991838  3.22603203  3.02888621 ... -2.72510886 -2.34779976\n",
      "   2.61198275]]\n",
      "MAP 0.7238774709714811\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "par_files = list(set([file.split('_E')[0] for file in all_files]))\n",
    "print(par_files)\n",
    "for par_file in par_files:\n",
    "    NDCG_List = []\n",
    "    MAP_List = []\n",
    "    DIM_List = []\n",
    "    TOP1_Prec = []\n",
    "    TOP3_Prec = []\n",
    "    TOP5_Prec = []\n",
    "    TOP1_F1 = []\n",
    "    TOP3_F1 = []\n",
    "    TOP5_F1 = []\n",
    "    TOP1_Recall = []\n",
    "    TOP3_Recall = []\n",
    "    TOP5_Recall = []\n",
    "    \n",
    "    csv_path = '../Data/grid_search_weight/Our/Dimension/'\n",
    "    for file in all_files:\n",
    "        if par_file in file:\n",
    "            print(file)\n",
    "            par_data = np.load(path+file)\n",
    "            U = par_data['U']\n",
    "            Y = par_data['Y']\n",
    "            A = par_data['A']\n",
    "            E = par_data['E']\n",
    "            #W1 = par_data['W1']\n",
    "            Wu = par_data['Wu']\n",
    "            Wy = par_data['Wy']\n",
    "            Wa = par_data['Wa']\n",
    "            Wv = par_data['Wv']\n",
    "            B = par_data['B']\n",
    "            \"\"\"print(U.shape)\n",
    "            print(Y.shape)\n",
    "            print(A.shape)\n",
    "            print(E.shape)\n",
    "            print(B.shape)\"\"\"\n",
    "            RS = testing(U, Y, A, E,Wu, Wy, Wa, Wv,B)\n",
    "            target,testRS,sumtarget = getScoreMatrix(RS)\n",
    "            prec_1,recall_1,f1_1 = getTOP1(target,testRS,sumtarget)\n",
    "            prec_3,recall_3,f1_3 = getTOP3(target,testRS,sumtarget)\n",
    "            prec_5,recall_5,f1_5 = getTOP5(target,testRS,sumtarget)\n",
    "            pre_matrix,avg_ndcg = NDCG(target,testRS)\n",
    "            Map_value = MAP(target,testRS)\n",
    "            NDCG_List.append(avg_ndcg)\n",
    "            MAP_List.append(Map_value)\n",
    "            DIM_List.append(file.split('_E')[1])\n",
    "            TOP1_Prec.append(prec_1)\n",
    "            TOP1_Recall.append(recall_1)\n",
    "            TOP1_F1.append(f1_1)\n",
    "            TOP3_Prec.append(prec_3)\n",
    "            TOP3_Recall.append(recall_3)\n",
    "            TOP3_F1.append(f1_3)\n",
    "            TOP5_Prec.append(prec_5)\n",
    "            TOP5_Recall.append(recall_5)\n",
    "            TOP5_F1.append(f1_5)\n",
    "            print('--------------------------------------------------------------------------------------------')\n",
    "    #print(NDCG_List)\n",
    "    #print(DIM_List)\n",
    "    result_dict = {'Dims':DIM_List,'NDCG':NDCG_List,'MAP':MAP_List,\n",
    "                   'TOP1 Precision':TOP1_Prec,'TOP1 Recall':TOP1_Recall,'TOP1 F1':TOP1_F1,\n",
    "                  'TOP3 Precision':TOP3_Prec,'TOP3 Recall':TOP3_Recall,'TOP3 F1':TOP3_F1,\n",
    "                  'TOP5 Precision':TOP5_Prec,'TOP5 Recall':TOP5_Recall,'TOP5 F1':TOP5_F1}\n",
    "    df = pd.DataFrame(result_dict)\n",
    "    df.to_csv(csv_path+par_file+'_.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate Feature Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Img0.5_no_300following_E200.npz', 'Img0.5_no_300image_E200.npz', 'Img0.5_no_300social_E200.npz', 'Img0.5_no_300text_E200.npz', 'Img0.5_no_300video_E200.npz', 'Img0.5_only_Image_E200.npz', 'Img0.5_only_text_E200.npz']\n"
     ]
    }
   ],
   "source": [
    "#With Embedding\n",
    "import os \n",
    "#從grid_search_weight中找尋不同的file \n",
    "path = '../Data/npy/mask_feature/result300/'\n",
    "all_files = os.listdir(path)\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_files = list(set([file.split('_')[1]+'_'+file.split('_')[2] for file in all_files]))\n",
    "print(par_files)\n",
    "for par_file in par_files:\n",
    "    NDCG_List = []\n",
    "    MAP_List = []\n",
    "    DIM_List = []\n",
    "    TOP1_Prec = []\n",
    "    TOP3_Prec = []\n",
    "    TOP5_Prec = []\n",
    "    TOP1_F1 = []\n",
    "    TOP3_F1 = []\n",
    "    TOP5_F1 = []\n",
    "    TOP1_Recall = []\n",
    "    TOP3_Recall = []\n",
    "    TOP5_Recall = []\n",
    "    \n",
    "    #csv_path = '../Data/grid_search_weight/CSV_Tan/'\n",
    "    csv_path = '../Data/npy/mask_feature/csv/'\n",
    "    for file in all_files:\n",
    "        if par_file in file:\n",
    "            print(file)\n",
    "            par_data = np.load(path+file)\n",
    "            U = par_data['U']\n",
    "            Y = par_data['Y']\n",
    "            A = par_data['A']\n",
    "            E = par_data['E']\n",
    "            #W1 = par_data['W1']\n",
    "            Wu = par_data['Wu']\n",
    "            Wy = par_data['Wy']\n",
    "            Wa = par_data['Wa']\n",
    "            Wv = par_data['Wv']\n",
    "            B = par_data['B']\n",
    "            RS = testing(U, Y, A, E,Wu, Wy, Wa, Wv,B)\n",
    "            target,testRS,sumtarget = getScoreMatrix(RS)\n",
    "            print('target',target)\n",
    "            prec_1,recall_1,f1_1 = getTOP1(target,testRS,sumtarget)\n",
    "            prec_3,recall_3,f1_3 = getTOP3(target,testRS,sumtarget)\n",
    "            prec_5,recall_5,f1_5 = getTOP5(target,testRS,sumtarget)\n",
    "            pre_matrix,avg_ndcg = NDCG(target,testRS)\n",
    "            Map_value = MAP(target,pre_matrix)\n",
    "            NDCG_List.append(avg_ndcg)\n",
    "            MAP_List.append(Map_value)\n",
    "            DIM_List.append(file.split('_')[1])\n",
    "            TOP1_Prec.append(prec_1)\n",
    "            TOP1_Recall.append(recall_1)\n",
    "            TOP1_F1.append(f1_1)\n",
    "            TOP3_Prec.append(prec_3)\n",
    "            TOP3_Recall.append(recall_3)\n",
    "            TOP3_F1.append(f1_3)\n",
    "            TOP5_Prec.append(prec_5)\n",
    "            TOP5_Recall.append(recall_5)\n",
    "            TOP5_F1.append(f1_5)\n",
    "            print('--------------------------------------------------------------------------------------------')\n",
    "    #print(NDCG_List)\n",
    "    #print(DIM_List)\n",
    "    result_dict = {'Dims':DIM_List,'NDCG':NDCG_List,'MAP':MAP_List,\n",
    "                   'TOP1 Precision':TOP1_Prec,'TOP1 Recall':TOP1_Recall,'TOP1 F1':TOP1_F1,\n",
    "                  'TOP3 Precision':TOP3_Prec,'TOP3 Recall':TOP3_Recall,'TOP3 F1':TOP3_F1,\n",
    "                  'TOP5 Precision':TOP5_Prec,'TOP5 Recall':TOP5_Recall,'TOP5 F1':TOP5_F1}\n",
    "    df = pd.DataFrame(result_dict)\n",
    "    df.to_csv(csv_path+par_file+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['onlyImg.npz', 'ImgVideo.npz']\n",
      "vbpr_onlyImg.npz\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'A is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-abbbd07c1713>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpar_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'U'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpar_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpar_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpar_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'E'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m#W1 = par_data['W1']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not a file in the archive\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'A is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "#For VBPR\n",
    "par_files = list(set([file.split('_')[1] for file in all_files]))\n",
    "print(par_files)\n",
    "for par_file in par_files:\n",
    "    NDCG_List = []\n",
    "    MAP_List = []\n",
    "    DIM_List = []\n",
    "    TOP1_Prec = []\n",
    "    TOP3_Prec = []\n",
    "    TOP5_Prec = []\n",
    "    TOP1_F1 = []\n",
    "    TOP3_F1 = []\n",
    "    TOP5_F1 = []\n",
    "    TOP1_Recall = []\n",
    "    TOP3_Recall = []\n",
    "    TOP5_Recall = []\n",
    "    \n",
    "    csv_path = '../Data/grid_search_weight/CSV_Tan/'\n",
    "    #csv_path = '../Data/npy/mask_feature/csv/'\n",
    "    for file in all_files:\n",
    "        if par_file in file:\n",
    "            print(file)\n",
    "            par_data = np.load(path+file)\n",
    "            U = par_data['U']\n",
    "            Y = par_data['Y']\n",
    "            A = par_data['A']\n",
    "            E = par_data['E']\n",
    "            #W1 = par_data['W1']\n",
    "            Wu = parRS,sumtarget = getScoreMatrix(RS)\n",
    "            print('target',target)\n",
    "            prec_1,recall_1,f1_1 = getTOP1(target,testRS,sumtarget)\n",
    "            prec_3,recall_3,f1_3 = getTOP3(target,testRS,sumtarget)\n",
    "            prec_5,recall_5,f1_5 = getTOP5(target,testRS,sumtarget)\n",
    "            pre_matrix,avg_data['Wu']\n",
    "            Wy = par_data['Wy']\n",
    "            Wa = par_data['Wa']\n",
    "            Wv = par_data['Wv']\n",
    "            B = par_data['B']\n",
    "            RS = testing(U, Y, A, E,Wu, Wy, Wa, Wv,B)\n",
    "            target,test_ndcg = NDCG(target,testRS)\n",
    "            Map_value = MAP(target,pre_matrix)\n",
    "            NDCG_List.append(avg_ndcg)\n",
    "            MAP_List.append(Map_value)\n",
    "            DIM_List.append(file.split('_')[1])\n",
    "            TOP1_Prec.append(prec_1)\n",
    "            TOP1_Recall.append(recall_1)\n",
    "            TOP1_F1.append(f1_1)\n",
    "            TOP3_Prec.append(prec_3)\n",
    "            TOP3_Recall.append(recall_3)\n",
    "            TOP3_F1.append(f1_3)\n",
    "            TOP5_Prec.append(prec_5)\n",
    "            TOP5_Recall.append(recall_5)\n",
    "            TOP5_F1.append(f1_5)\n",
    "            print('--------------------------------------------------------------------------------------------')\n",
    "    #print(NDCG_List)\n",
    "    #print(DIM_List)\n",
    "    result_dict = {'Dims':DIM_List,'NDCG':NDCG_List,'MAP':MAP_List,\n",
    "                   'TOP1 Precision':TOP1_Prec,'TOP1 Recall':TOP1_Recall,'TOP1 F1':TOP1_F1,\n",
    "                  'TOP3 Precision':TOP3_Prec,'TOP3 Recall':TOP3_Recall,'TOP3 F1':TOP3_F1,\n",
    "                  'TOP5 Precision':TOP5_Prec,'TOP5 Recall':TOP5_Recall,'TOP5 F1':TOP5_F1}\n",
    "    df = pd.DataFrame(result_dict)\n",
    "    df.to_csv(csv_path+par_file+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_files = list(set([file.split('_Edims')[0] for file in all_files]))\n",
    "print(par_files)\n",
    "for par_file in par_files:\n",
    "    NDCG_List = []\n",
    "    MAP_List = []\n",
    "    DIM_List = []\n",
    "    TOP1_Prec = []\n",
    "    TOP3_Prec = []\n",
    "    TOP5_Prec = []\n",
    "    TOP1_F1 = []\n",
    "    TOP3_F1 = []\n",
    "    TOP5_F1 = []\n",
    "    TOP1_Recall = []\n",
    "    TOP3_Recall = []\n",
    "    TOP5_Recall = []\n",
    "    \n",
    "    csv_path = '../Data/grid_search_weight/CSV_Tan/'\n",
    "    for file in all_files:\n",
    "        if par_file in file:\n",
    "            print(file)\n",
    "            par_data = np.load(path+file)\n",
    "            U = par_data['U']\n",
    "            Y = par_data['Y']\n",
    "            A = par_data['A']\n",
    "            E = par_data['E']\n",
    "            #W1 = par_data['W1']\n",
    "            Wu = par_data['Wu']\n",
    "            Wy = par_data['Wy']\n",
    "            Wa = par_data['Wa']\n",
    "            Wv = par_data['Wv']\n",
    "            B = par_data['B']\n",
    "            RS = testing(U, Y, A, E,Wu, Wy, Wa, Wv,B)\n",
    "            target,testRS,sumtarget = getScoreMatrix(RS)\n",
    "            prec_1,recall_1,f1_1 = getTOP1(target,testRS,sumtarget)\n",
    "            prec_3,recall_3,f1_3 = getTOP3(target,testRS,sumtarget)\n",
    "            prec_5,recall_5,f1_5 = getTOP5(target,testRS,sumtarget)\n",
    "            pre_matrix,avg_ndcg = NDCG(target,testRS)\n",
    "            Map_value = MAP(target,pre_matrix)\n",
    "            NDCG_List.append(avg_ndcg)\n",
    "            MAP_List.append(Map_value)\n",
    "            DIM_List.append(file.split('Edims')[1].split('.npz')[0])\n",
    "            TOP1_Prec.append(prec_1)\n",
    "            TOP1_Recall.append(recall_1)\n",
    "            TOP1_F1.append(f1_1)\n",
    "            TOP3_Prec.append(prec_3)\n",
    "            TOP3_Recall.append(recall_3)\n",
    "            TOP3_F1.append(f1_3)\n",
    "            TOP5_Prec.append(prec_5)\n",
    "            TOP5_Recall.append(recall_5)\n",
    "            TOP5_F1.append(f1_5)\n",
    "            print('--------------------------------------------------------------------------------------------')\n",
    "    #print(NDCG_List)\n",
    "    #print(DIM_List)\n",
    "    result_dict = {'Dims':DIM_List,'NDCG':NDCG_List,'MAP':MAP_List,\n",
    "                   'TOP1 Precision':TOP1_Prec,'TOP1 Recall':TOP1_Recall,'TOP1 F1':TOP1_F1,\n",
    "                  'TOP3 Precision':TOP3_Prec,'TOP3 Recall':TOP3_Recall,'TOP3 F1':TOP3_F1,\n",
    "                  'TOP5 Precision':TOP5_Prec,'TOP5 Recall':TOP5_Recall,'TOP5 F1':TOP5_F1}\n",
    "    df = pd.DataFrame(result_dict)\n",
    "    df.to_csv(csv_path+par_file+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDCG For Different Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## code here !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN(sortlist,n):\n",
    "    topList = []\n",
    "    for i in range(n):\n",
    "        topList.append(sortlist.index(max(sortlist)))\n",
    "        #print(max(sortlist))\n",
    "        #print(sortlist.index(max(sortlist)))\n",
    "        sortlist[sortlist.index(max(sortlist))] = -1000000000\n",
    "    return topList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1]\n",
      "[3, 6, 2]\n",
      "[1, 2, 13, 4, 5, 3, 17]\n",
      "[1, 10, 8, 2, 5, 4]\n",
      "[4, 1, 12]\n",
      "[1, 15, 11]\n",
      "[2, 1, 10, 0]\n",
      "[3, 2, 5, 7, 4, 18]\n",
      "[3, 18, 8, 5, 13]\n",
      "[12, 16, 7, 0, 9]\n",
      "avg_accuarcy for count_0: 0.24\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "count_0_all = []\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),int(np.sum(target[i])))\n",
    "    count_0_all.append(top_0)\n",
    "    print(top_0)\n",
    "\n",
    "acc_0 = 0\n",
    "total = 0\n",
    "for i in range(len(count_0_all)):\n",
    "    for j in range(len(count_0_all[i])):\n",
    "        #print(int(np.sum(target[i])))\n",
    "        total+=int(np.sum(target[i]))\n",
    "        if count_0_all[i][j] < int(np.sum(target[i])): #代表是0或1 (也就是target)\n",
    "            acc_0 += 1\n",
    "avg_acc = acc_0/100\n",
    "print('avg_accuarcy for count_0:',avg_acc)\n",
    "print(acc_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOP1,TOP3,TOP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = (2*prec*rec)/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDCG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14409628, 0.14409674, 0.14135303, 0.14211949, 0.14409625,\n",
       "       0.14211893, 0.14211929])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_list = [0.02162337, 0.02162659, 0.00240219, 0.00780985, 0.02162318, 0.00780592, 0.00780849]\n",
    "softmax(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 3],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "user = []\n",
    "for i in range(3):\n",
    "    temp_t = []\n",
    "    temp_t.append(1)\n",
    "    temp_t.append(2)\n",
    "    temp_t.append(3)\n",
    "    user.append(temp_t)\n",
    "np.array(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333333"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([0, 0, 1, 1])\n",
    "y_scores = np.array([-1, 1, 0,2])\n",
    "average_precision_score(y_true, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
