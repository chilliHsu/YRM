{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\pydot_ng\\__init__.py:30: UserWarning: Couldn't import _dotparser, loading of dot files will not be possible.\n",
      "  \"Couldn't import _dotparser, \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_following = np.load('../Data/npy/user_following_1489.npy')\n",
    "all_feature = np.load('../Data/npy/all_2939D_img0.5.npy')\n",
    "user_category = np.load('../Data/npy/user_category_1489.npy')\n",
    "YouTuber_category = np.load('../Data/npy/YouTuber_category_0.7.npy')\n",
    "active_users = np.load('../Data/npy/active_userID_1489.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video feaute shape (88, 512)\n",
      "text feature shape (88, 300)\n",
      "image feature shape (88, 2048)\n",
      "following feature shape (88, 64)\n",
      "social feature shape (88, 15)\n"
     ]
    }
   ],
   "source": [
    "video_f = np.load('../Data/npy/Video_512D_6650.npy')\n",
    "text_f = np.load('../Data/npy/Text_300D.npy')\n",
    "image_f = np.load('../Data/npy/Image_50_2048D.npy')\n",
    "following_f = np.load('../Data/npy/Following_64D.npy')\n",
    "social_f = np.load('../Data/npy/social_Norm15D.npy')\n",
    "print('video feaute shape',video_f.shape)\n",
    "print('text feature shape',text_f.shape)\n",
    "print('image feature shape',image_f.shape)\n",
    "print('following feature shape',following_f.shape)\n",
    "print('social feature shape',social_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual feature shape: (88, 2048)\n"
     ]
    }
   ],
   "source": [
    "#visual_feature = np.concatenate((video_feature, image_feature), axis=1)\n",
    "#print('visual feature shape:',visual_feature.shape)\n",
    "visual_feature = image_f\n",
    "print('visual feature shape:',visual_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test_amount = 150 #150 user for testing\n",
    "yt_test_amount = 18 #18 YouTuber for testing for each tested user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test(user_following,feature,user_category,item_category,active_users,user_test_amount,yt_test_amount):\n",
    "    print('Generate_train_test----')\n",
    "    #The shape of orignal data\n",
    "    print('user_following shape ',user_following.shape)\n",
    "    print('feature shape ',feature.shape)\n",
    "    print('user_category shape ',user_category.shape)\n",
    "    print('YouTuber_category shape ',item_category.shape)\n",
    "    user_category_norm = np.zeros(user_category.shape)\n",
    "    for i in range(len(user_category)):\n",
    "        user_category_norm[i] = user_category[i]/np.max(user_category[i])\n",
    "    print('user_category after normalized by max...')\n",
    "    print('user_category_norm shape ',user_category_norm.shape)\n",
    "    \n",
    "    #following youtuber for each user\n",
    "    following_true = []\n",
    "    for i in range(len(user_following)):\n",
    "        each_user = []\n",
    "        for j in range(len(user_following[i])):\n",
    "            if user_following[i][j] == 1:\n",
    "                each_user.append(j)\n",
    "        following_true.append(each_user)\n",
    "    #print(following_true)\n",
    "    #number of followings for each user\n",
    "    minlen = 10000\n",
    "    maxlen = 0\n",
    "    num_of_follower = []\n",
    "    for i in range(len(following_true)):\n",
    "        if len(following_true[i]) < minlen:\n",
    "            minlen = len(following_true[i])\n",
    "        if len(following_true[i]) > maxlen:\n",
    "            maxlen = len(following_true[i])\n",
    "        num_of_follower.append(len(following_true[i]))\n",
    "    print('Min number of followings ',minlen)\n",
    "    print('Max number of followings ',maxlen)\n",
    "    \n",
    "    num_of_users = user_following.shape[0]\n",
    "    num_of_youtubers = item_category[0]\n",
    "    \n",
    "    \"\"\"\n",
    "    Spliting training and testing data\n",
    "    \"\"\"\n",
    "    #testing user id random choice\n",
    "    user_idx = [i for i in range(len(user_following))]\n",
    "    random.seed(5)\n",
    "    #choose test_id and sorted from small to large\n",
    "    test_idx = sorted(random.sample(user_idx,user_test_amount))\n",
    "    \n",
    "    train_t = []\n",
    "    train_f = []\n",
    "    test_t = []\n",
    "    test_f = []\n",
    "    \n",
    "    print('test_idx',test_idx)\n",
    "    test_pos = -1\n",
    "    for i in range(num_of_users):\n",
    "        t_for_train = []\n",
    "        f_for_train = []\n",
    "        if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "            for j in range(88):\n",
    "                if user_following[i][j] == 1:\n",
    "                    t_for_train.append(j)\n",
    "                else:\n",
    "                    f_for_train.append(j)\n",
    "            train_t.append(t_for_train)\n",
    "            train_f.append(f_for_train)\n",
    "\n",
    "        else: #if in test id, choose 2 true and other \n",
    "            test_pos += 1\n",
    "            temp_t = []\n",
    "            temp_f = []\n",
    "            for j in range(88):\n",
    "                if user_following[i][j] == 1:\n",
    "                    temp_t.append(j)\n",
    "                else:\n",
    "                    temp_f.append(j)\n",
    "            t_for_test = random.sample(temp_t,math.ceil(0.5*len(temp_t)))\n",
    "            f_for_test  = random.sample(temp_f,yt_test_amount-len(t_for_test))\n",
    "\n",
    "            test_t.append(t_for_test)\n",
    "            test_f.append(f_for_test)\n",
    "\n",
    "            #other for training\n",
    "            t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "            f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "            train_t.append(t_for_train)\n",
    "            train_f.append(f_for_train)\n",
    "            \n",
    "    # train_t[i] 代表的是user i positive feedback\n",
    "    print('The length of train_t:',len(train_t))\n",
    "    print('The length of train_f:',len(train_f))\n",
    "    print('The length of test_t:',len(test_t))\n",
    "    print('The length of test_f:',len(test_f))\n",
    "    return train_t,train_f,test_t,test_f,user_category_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate_train_test----\n",
      "user_following shape  (1489, 88)\n",
      "feature shape  (88, 2048)\n",
      "user_category shape  (1489, 17)\n",
      "YouTuber_category shape  (88, 17)\n",
      "user_category after normalized by max...\n",
      "user_category_norm shape  (1489, 17)\n",
      "Min number of followings  5\n",
      "Max number of followings  34\n",
      "test_idx [3, 6, 10, 18, 26, 37, 44, 46, 59, 65, 67, 75, 95, 99, 106, 114, 116, 133, 135, 147, 160, 165, 186, 188, 208, 221, 231, 243, 259, 270, 284, 298, 303, 304, 321, 326, 330, 339, 340, 360, 363, 370, 372, 378, 402, 403, 407, 419, 426, 428, 441, 443, 486, 503, 504, 510, 512, 513, 523, 524, 540, 564, 572, 592, 605, 611, 617, 626, 627, 633, 634, 639, 642, 646, 648, 679, 692, 696, 697, 704, 705, 726, 727, 732, 734, 739, 742, 749, 752, 761, 770, 779, 784, 797, 827, 831, 835, 849, 857, 863, 886, 911, 927, 933, 946, 947, 953, 960, 967, 984, 985, 990, 1049, 1050, 1074, 1085, 1092, 1104, 1113, 1116, 1124, 1175, 1184, 1200, 1207, 1216, 1220, 1230, 1235, 1250, 1264, 1265, 1275, 1277, 1281, 1283, 1307, 1329, 1333, 1335, 1388, 1404, 1411, 1414, 1426, 1438, 1443, 1449, 1474, 1476]\n",
      "The length of train_t: 1489\n",
      "The length of train_f: 1489\n",
      "The length of test_t: 150\n",
      "The length of test_f: 150\n"
     ]
    }
   ],
   "source": [
    "train_t,train_f,test_t,test_f,user_category_norm = generate_train_test(user_following,visual_feature,user_category,YouTuber_category,active_users,user_test_amount,yt_test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 9.758226997985226\n",
      "testing 5.466666666666667\n"
     ]
    }
   ],
   "source": [
    "#average num of following for training user\n",
    "total_train = 0\n",
    "for t in train_t:\n",
    "    total_train += len(t)\n",
    "avg = total_train/len(user_following)\n",
    "print('training',avg)\n",
    "#average num of following for testing user\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test/user_test_amount\n",
    "print('testing',avg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_auxilary = [i for i in range(88)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(user_following)\n",
    "m = 88  \n",
    "k = 64\n",
    "l = visual_feature.shape[1]\n",
    "embedding_dims = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(save_name): \n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    loss_acc_list = []\n",
    "    t0=time.time()\n",
    "    \n",
    "    train_yes_id=[] \n",
    "    for q in range(7):\n",
    "        print('Iteraction:',q)\n",
    "        train_auc=0\n",
    "        total_loss=0\n",
    "        xuij_auc=0\n",
    "        length = 0\n",
    "        for z in range(n):\n",
    "            \"\"\"\n",
    "            yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "            yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "            r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "            \"\"\"\n",
    "        \n",
    "            #取positive \n",
    "            train_t_sample = random.sample(train_t[z],len(train_t[z]))\n",
    "            #print('number of positive feedback', len(train_t_sample))\n",
    "        \n",
    "            #train_f_sample = random.sample(train_f[z],20)\n",
    "            for ta in train_t_sample:\n",
    "                #pos = sample.index(ta)\n",
    "                \n",
    "                image_1=np.expand_dims(visual_feature[ta],0) #(1,2048)\n",
    "                train_f_sample = random.sample(train_f[z],10)\n",
    "                \n",
    "                for b in train_f_sample:\n",
    "                    image_2=np.expand_dims(visual_feature[b],0) #(1,2048)\n",
    "                    _auc, _loss,_=sess.run([auc,loss,train_op], feed_dict={user: [z],\n",
    "                                        i: [ta], j: [b],image_i:image_1,image_j:image_2})\n",
    "\n",
    "                    train_auc+=_auc\n",
    "                    total_loss+=_loss\n",
    "                    length += 1\n",
    "\n",
    "        print(\"total_loss:-----------------\", total_loss/length)\n",
    "        print(\"train_auc:-------------------\", train_auc/length)\n",
    "        loss_acc_list.append([total_loss/length,train_auc/length,time.time()-t0])\n",
    "        print('time:',time.time()-t0,' sec')\n",
    "    print('Total cost ',time.time()-t0,' sec')   \n",
    "    U, Y, E,B =sess.run([user_latent, item_latent, embedding,Beta])\n",
    "    np.savez('../Data/grid_search_weight/vbpr/'+save_name+'.npz', \n",
    "                        U=U, Y=Y, E=E,B=B)\n",
    "    return U, Y, E, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Dims []\n",
      "Now Dims: 200\n",
      "WARNING:tensorflow:From c:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-13-713ecd6c4bd6>:185: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.43166068]]\n",
      "train_auc:------------------- 0.8432484514796972\n",
      "time: 195.60016345977783  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.35582776]]\n",
      "train_auc:------------------- 0.8807432897453544\n",
      "time: 391.0248763561249  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.33395679]]\n",
      "train_auc:------------------- 0.8905024088093599\n",
      "time: 586.6089749336243  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.31863308]]\n",
      "train_auc:------------------- 0.8982105987611838\n",
      "time: 782.7676899433136  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.30706128]]\n",
      "train_auc:------------------- 0.9035512732278046\n",
      "time: 979.4152183532715  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.30169964]]\n",
      "train_auc:------------------- 0.9071507226428079\n",
      "time: 1176.4349520206451  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.29657737]]\n",
      "train_auc:------------------- 0.9098692360633173\n",
      "time: 1374.993451833725  sec\n",
      "Total cost  1374.993451833725  sec\n",
      "Finish dims:, 200\n"
     ]
    }
   ],
   "source": [
    "par_weights = [0.01]\n",
    "beta_weights = [0.001]\n",
    "Embedding_weights = [0.01]\n",
    "Embedding_dims = [200]\n",
    "\n",
    "testcount = 0\n",
    "finish_list = []\n",
    "for paru_weight in par_weights:\n",
    "    for pary_weight in par_weights:\n",
    "        for beta_weight in beta_weights:\n",
    "            for Embedding_weight in Embedding_weights:\n",
    "                for embedding_dims in Embedding_dims:\n",
    "                    clear_output()\n",
    "                    print('Finished Dims',finish_list)\n",
    "                    finish_list.append(embedding_dims)\n",
    "                    print('Now Dims:',embedding_dims)\n",
    "                    \"\"\"\n",
    "                    n: the number of users\n",
    "                    m: the number of YouTubers\n",
    "                    k: latent dims\n",
    "                    l: feature dims\n",
    "                    \"\"\"\n",
    "                    tf.reset_default_graph()\n",
    "\n",
    "                    user = tf.placeholder(tf.int32,shape=(1,))\n",
    "                    i = tf.placeholder(tf.int32, shape=(1,))\n",
    "                    j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "                    #多少個auxliary \n",
    "                    \"\"\"\n",
    "                    xf = tf.placeholder(tf.float32, shape=(None,l))\n",
    "                    l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "                    l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "                    positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "                    positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "                    r = tf.placeholder(tf.float32,shape=(None,))\n",
    "                    \"\"\"\n",
    "\n",
    "\n",
    "                    image_i = tf.placeholder(tf.float32, shape=(1,l))\n",
    "                    image_j = tf.placeholder(tf.float32, shape=(1,l))\n",
    "\n",
    "                    with tf.variable_scope(\"item_level\"):\n",
    "                        user_latent = tf.get_variable(\"user_latent\", [n, k],\n",
    "                                                              initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "                        item_latent = tf.get_variable(\"item_latent\", [m, k],\n",
    "                                                              initializer=tf.random_normal_initializer(0,0.1,seed=3)) \n",
    "                        #aux_item = tf.get_variable(\"aux_item\", [m, k],\n",
    "                        #                                      initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "                        \"\"\"\n",
    "                        Wu = tf.get_variable(\"Wu\", [n,m,k],  \n",
    "                                                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "                        Wy = tf.get_variable(\"Wy\", [n,m,k],   \n",
    "                                                             initializer=tf.contrib.layers.xavier_initializer())\n",
    "                        Wa = tf.get_variable(\"Wa\", [n,m,k],  \n",
    "                                                             initializer=tf.contrib.layers.xavier_initializer())\n",
    "                        Wv = tf.get_variable(\"Wv\", [n,m,embedding_dims],  \n",
    "                                                            initializer=tf.contrib.layers.xavier_initializer())\n",
    "                        \"\"\"\n",
    "                       \n",
    "                        #Wve =  tf.get_variable(\"Wve\", [embedding_dims,l],  \n",
    "                        #                                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "                        #每個user 對於每個YouTuber都有一個權重\n",
    "                        #w1拿掉，wu\n",
    "                        #hyper?\n",
    "\n",
    "                        aux_new = tf.get_variable(\"aux_new\", [1,k], initializer=tf.constant_initializer(0.0))\n",
    "                        ########## Error part, how to get auxisize dynamically\n",
    "                        ####aux_size= tf.get_variable(name='aux_size', initializer=l_id.get_shape().as_list()[-1])\n",
    "\n",
    "                    with tf.variable_scope('feature_level'):\n",
    "                        embedding = tf.get_variable(\"embedding\", [embedding_dims,l],\n",
    "                                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "                        Beta = tf.get_variable(\"beta\", [n,embedding_dims],\n",
    "                                    initializer=tf.random_normal_initializer(0.01,0.001,seed=10))\n",
    "\n",
    "                    #lookup the latent factors by user and id\n",
    "                    u = tf.nn.embedding_lookup(user_latent, user) #(1*k) 第幾個user latent factor\n",
    "                    vi = tf.nn.embedding_lookup(item_latent, i) \n",
    "                    vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "\n",
    "                    \"\"\"\n",
    "                    wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user)) #(m*k)\n",
    "                    wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user)) #(m*k)\n",
    "                    wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user)) #(m*k)\n",
    "                    wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user)) #(m,l)\n",
    "                    \"\"\"\n",
    "                    beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n",
    "\n",
    "                    \"\"\"\n",
    "                    a_list=tf.Variable([])\n",
    "                    q = tf.constant(0)\n",
    "                    def att_cond(q,a_list):\n",
    "                        return tf.less(q,l_id_len[0])\n",
    "                    def att_body(q,a_list):\n",
    "                        xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "                        wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "                        wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "                        waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "                        wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "                        a_list = tf.concat([a_list,[(tf.nn.relu( tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                tf.matmul(wvui,tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "                        q += 1\n",
    "                        return q,  a_list\n",
    "\n",
    "                    _, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "                    # for while for smoothing\n",
    "                    #a_list_soft=tf.nn.softmax(a_list)\n",
    "                    a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "                    a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "                    \n",
    "                    norm_par = [wu,wy,wa,wv]\n",
    "\n",
    "                    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "                    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "                    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "                    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "                    wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "                    wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "                    wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "                    wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "                    last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "                    \n",
    "                    aux_np = tf.expand_dims(tf.zeros(k),0) #dimension (1,64)\n",
    "                    \n",
    "                    q = tf.constant(0)\n",
    "                    def sum_att_cond(q,aux_np):\n",
    "                        return tf.less(q,l_id_len[0])\n",
    "\n",
    "                    def sum_att_body(q,aux_np):\n",
    "                        #aux_np+=a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)\n",
    "                        aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "                        q += 1\n",
    "                        return q, aux_np\n",
    "\n",
    "                    _,aux_np = tf.while_loop(sum_att_cond,sum_att_body,[q,aux_np])\n",
    "                    \"\"\"\n",
    "\n",
    "                    \"\"\"\n",
    "                    for q in range(3): #取q個auxliary item\n",
    "                        aux_np+=a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    #aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "                    #tf.print('aux attention:',aux_np)\n",
    "                    #aux_np+=u #user_latent factor + sum (alpha*auxilary)\n",
    "                    aux_new=tf.assign(aux_new,u) #把aux_new 的 值變成aux_np\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    \"\"\"\n",
    "                    latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "                    feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "                    latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "                    feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "                    only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "                    only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    #矩陣中對應函數各自相乘\n",
    "                    # ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "                    xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "                    xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "                    xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "\n",
    "                    l2_norm = tf.add_n([\n",
    "                                0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "                                0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "                                0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "                                beta_weight * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "                                Embedding_weight * tf.reduce_sum(tf.multiply(embedding,embedding)),\n",
    "\n",
    "                                ])\n",
    "\n",
    "                    loss = l2_norm -tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "                    train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "                    auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "\n",
    "                    Ur, Yr,Er,Br = training('vbpr_onlyImg')\n",
    "                    print('Finish dims:,',embedding_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
