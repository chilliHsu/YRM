{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing data positive feedback dynamic (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_following = np.load('../Data/npy/user_following_1489.npy')[:100]\n",
    "all_3374 = np.load('../Data/npy/all_3374D.npy')\n",
    "user_category = np.load('../Data/npy/user_category_1489.npy')[:100]\n",
    "YouTuber_category = np.load('../Data/npy/YouTuber_category_0.7.npy')\n",
    "active_users = np.load('../Data/npy/active_userID_1489.npy')[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  0  2 24  1  0  0 11 47  7 25 32 10  1 16  1  6 24  3  2  1  6  4  0\n",
      " 39 39 10 16 27 22  0  2 17 15  0  2  0  8  2  1 28 16  3 33  9 24  0  3\n",
      "  0  9  0  0  0  2 28  2  2 18  0  3 23  0  2 39  0  1  1 65  0  2 18 21\n",
      "  7  1 47 14 19  1  3 66  3  0 28  3 20  0  6  0]\n",
      "The num of followers over 5: 42\n"
     ]
    }
   ],
   "source": [
    "#The number of followers for each YouTuber\n",
    "YouTuber_followers = np.sum(user_following, axis=0)\n",
    "print(YouTuber_followers)\n",
    "over5 = 0\n",
    "for num in YouTuber_followers:\n",
    "    if num >= 5:\n",
    "        over5+=1\n",
    "print('The num of followers over 5:',over5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_following shape  (100, 88)\n",
      "all_3374 shape  (88, 3374)\n",
      "user_category shape  (100, 17)\n",
      "YouTuber_category shape  (88, 17)\n"
     ]
    }
   ],
   "source": [
    "print('user_following shape ',user_following.shape)\n",
    "print('all_3374 shape ',all_3374.shape)\n",
    "print('user_category shape ',user_category.shape)\n",
    "print('YouTuber_category shape ',YouTuber_category.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_category after normalized by max...\n",
      "user_category_norm shape  (100, 17)\n"
     ]
    }
   ],
   "source": [
    "user_category_norm = np.zeros(user_category.shape)\n",
    "for i in range(len(user_category)):\n",
    "    user_category_norm[i] = user_category[i]/np.max(user_category[i])\n",
    "print('user_category after normalized by max...')\n",
    "print('user_category_norm shape ',user_category_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "following_true = [0]*len(user_following)\n",
    "for i in range(len(user_following)):\n",
    "    each_user = []\n",
    "    for j in range(len(user_following[i])):\n",
    "        if user_following[i][j] == 1:\n",
    "            each_user.append(j)\n",
    "    following_true[i] = each_user\n",
    "#print(following_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followings  5\n",
      "Max number of followings  21\n"
     ]
    }
   ],
   "source": [
    "#最少跟最多的following \n",
    "minlen = 10000\n",
    "maxlen = 0\n",
    "num_of_follower = []\n",
    "for i in range(len(following_true)):\n",
    "    if len(following_true[i]) < minlen:\n",
    "        minlen = len(following_true[i])\n",
    "    if len(following_true[i]) > maxlen:\n",
    "        maxlen = len(following_true[i])\n",
    "    num_of_follower.append(len(following_true[i]))\n",
    "print('Min number of followings ',minlen)\n",
    "print('Max number of followings ',maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over 8: 68\n",
      "over 10: 56\n",
      "over 12: 28\n",
      "avg 10: 12.517857142857142\n"
     ]
    }
   ],
   "source": [
    "over_10 = 0\n",
    "over_8 = 0\n",
    "over_12 = 0\n",
    "user_idx_over10 = []\n",
    "avg_over10 = 0\n",
    "for i in range(len(num_of_follower)):\n",
    "    num = num_of_follower[i]\n",
    "    if num >= 10:\n",
    "        over_10 += 1\n",
    "        user_idx_over10.append(i)\n",
    "        avg_over10+=num\n",
    "    if num >= 8:\n",
    "        over_8 += 1\n",
    "    if num >= 12:\n",
    "        over_12 += 1\n",
    "print('over 8:',over_8)\n",
    "print('over 10:',over_10)\n",
    "print('over 12:',over_12)\n",
    "print('avg 10:',avg_over10/len(user_idx_over10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_amount = 10\n",
    "yt_test_amount = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx = [i for i in range(len(user_following))]\n",
    "#user_idx = user_idx_over10\n",
    "#test_idx is the number of user for testing\n",
    "random.seed(3)\n",
    "test_idx = random.sample(user_idx,test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3\n",
      "2\n",
      "6 3\n",
      "3\n",
      "14 7\n",
      "7\n",
      "11 6\n",
      "5\n",
      "5 3\n",
      "2\n",
      "6 3\n",
      "3\n",
      "7 4\n",
      "3\n",
      "11 6\n",
      "5\n",
      "10 5\n",
      "5\n",
      "9 5\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Training  and Testing --New\n",
    "train_t = [0]*(len(user_following))\n",
    "train_f = [0]*(len(user_following))\n",
    "# Testing \n",
    "test_t = [0]*test_amount\n",
    "test_f = [0]*test_amount\n",
    "test_pos = -1\n",
    "\n",
    "for i in range(len(user_following)):\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "        for j in range(88):\n",
    "            if user_following[i][j] == 1:\n",
    "                t_for_train.append(j)\n",
    "            else:\n",
    "                f_for_train.append(j)\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train\n",
    "        \n",
    "    else: #if in test id, choose 2 true and other \n",
    "        test_pos += 1\n",
    "        temp_t = []\n",
    "        temp_f = []\n",
    "        for j in range(88):\n",
    "            if user_following[i][j] == 1:\n",
    "                temp_t.append(j)\n",
    "            else:\n",
    "                temp_f.append(j)\n",
    "        print(len(temp_t),math.ceil(0.5*len(temp_t)))\n",
    "        t_for_test = random.sample(temp_t,math.ceil(0.5*len(temp_t)))\n",
    "        f_for_test  = random.sample(temp_f,yt_test_amount-len(t_for_test))\n",
    "        \n",
    "        test_t[test_pos] = t_for_test\n",
    "        test_f[test_pos] = f_for_test\n",
    "        \n",
    "        #other for training\n",
    "        t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "        print(len(t_for_train ))\n",
    "        f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test/test_amount\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 100\n",
      "The length of train_f: 100\n",
      "The length of test_t: 10\n",
      "The length of test_f: 10\n"
     ]
    }
   ],
   "source": [
    "# train_t[i] 代表的是user i positive feedback\n",
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_t))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation  Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(user_following)\n",
    "m = 88  \n",
    "k = 128\n",
    "l = 3374\n",
    "embedding_dims = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(save_name): \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    loss_acc_list = []\n",
    "    t0=time.time()\n",
    "\n",
    "    #use_true=init_list_of_objects(136)\n",
    "    #use_test=init_list_of_objects(136)\n",
    "\n",
    "    #train_pair_t=[] #positive feedback\n",
    "    #train_pair_f=[] #negative feedback\n",
    "    train_yes_id=[] \n",
    "    for q in range(10):\n",
    "        #clear_output()\n",
    "        print('Iteraction:',q)\n",
    "        train_auc=0\n",
    "        total_loss=0\n",
    "        xuij_auc=0\n",
    "        length = 0\n",
    "        for z in range(n):\n",
    "            \"\"\"\n",
    "            yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "            yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "            r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "            \"\"\"\n",
    "            yes=[]\n",
    "            yesr=[]\n",
    "        \n",
    "        \n",
    "            sample=random.sample(train_t[z],len(train_t[z])) #選全部的Positive\n",
    "            train_yes_id.append(sample) #sample全部丟進去\n",
    "        \n",
    "            #sample=random.sample(train_t[z]+train_f[z],len(train_t[z])+len(train_f[z]))\n",
    "        \n",
    "            #change\n",
    "            r_3=np.zeros(len(sample)) \n",
    "         \n",
    "            for b in range(len(sample)):\n",
    "                yes.append(all_3374[sample[b]])\n",
    "                yesr.append(YouTuber_category[sample[b]]*user_category_norm[z])\n",
    "                #print('YouTuber_category ', YouTuber_category[sample[k]])\n",
    "                #print('User_category ',user_category_norm[z])\n",
    "            #print(yesr)\n",
    "        \n",
    "            for b in range(len(yesr)):\n",
    "                r_3[b]=max(yesr[b])\n",
    "            #print('r_3:',r_3)\n",
    "        \n",
    "            yes=np.array(yes)\n",
    "        \n",
    "            #not_used_list = list(set(train_t[z]).difference(set(sample)))\n",
    "        \n",
    "            #取positive \n",
    "            train_t_sample = random.sample(train_t[z],len(train_t[z]))\n",
    "            #print('number of positive feedback', len(train_t_sample))\n",
    "        \n",
    "            train_f_sample = random.sample(train_f[z],20)\n",
    "            for ta in train_t_sample:\n",
    "                #print(ta,'--> positive feedback')\n",
    "            \n",
    "                pos = sample.index(ta)\n",
    "                #new_sample = np.delete(sample,[pos])\n",
    "                #new_yes = np.delete(yes,[pos],axis=0)\n",
    "                #new_r_3 = np.delete(r_3,[pos])\n",
    "                new_sample = sample\n",
    "                new_yes = yes\n",
    "                new_r_3 = r_3\n",
    "                #print(len(yes),len(new_yes))\n",
    "                #print(yes)\n",
    "                #print(new_yes)\n",
    "            \n",
    "            \n",
    "            \n",
    "                #ta=random.choice(train_t[z]) #ta is true positve photo\n",
    "                #train_pair_t.append(ta)\n",
    "                image_1=np.expand_dims(all_3374[ta],0) #(1,2048)\n",
    "                #print('Image_1 shape ',image_1.shape)\n",
    "                #train_f_sample = random.sample(train_f[z],20)\n",
    "                #print('True:',train_t_sample,'Now:',ta)\n",
    "                #print('False:',train_f_sample)\n",
    "                for b in train_f_sample:\n",
    "                    #print('likes:',ta,';Not likes:',b)\n",
    "                    #b=random.choice(train_f[z])  #b is no feedback photo\n",
    "                    #train_pair_f.append(b)\n",
    "                    image_2=np.expand_dims(all_3374[b],0) #(1,2048)\n",
    "                    #print('Image_2 shape',image_2.shape)\n",
    "            \n",
    "                    #use_test[z].append(b)\n",
    "                    _last_be_relu,_norm_par,_a_list,r3,_auc, _loss,_=sess.run([last_be_relu,norm_par,a_list,a_list_soft,auc,loss,train_op], feed_dict={user: [z],\n",
    "                                        i: [ta], j: [b], xf: new_yes , l_id:new_sample, l_id_len:[len(new_sample)],r:new_r_3,\n",
    "                                        image_i:image_1,image_j:image_2})\n",
    "                \n",
    "                    #print(XUIJ)\n",
    "                    #print('loss=',_loss)\n",
    "                    #print('auc=',_auc)\n",
    "                    #print('user positive negative',z,ta,b)\n",
    "                    #for each_par in _norm_par:\n",
    "                    #    print(each_par.shape)\n",
    "                    #    print(each_par)\n",
    "                    #print('be_relu,wu,wy,wa,wv',_last_be_relu)\n",
    "                    #print('alpha softmax:',r3)\n",
    "                    #print('before softmax:',_a_list)\n",
    "                    #print('---------------------------------------------------')\n",
    "        \n",
    "                    train_auc+=_auc\n",
    "                    total_loss+=_loss\n",
    "                    length += 1\n",
    "                #now1+=1\n",
    "        \n",
    "            #np.savez('../Data/latent_factor/YRM_up10/'+str(q)+'_'+str(z)+'.npz', User=U_history, YouTuber=Y_history)\n",
    "    \n",
    "        #print('mine:',xuij_auc/136)    \n",
    "        #print('a_list_soft:',r3)\n",
    "        print(\"total_loss:-----------------\", total_loss/length)\n",
    "        print(\"train_auc:-------------------\", train_auc/length)\n",
    "        \n",
    "        loss_acc_list.append([total_loss/length,train_auc/length,time.time()-t0])\n",
    "        print('time:',time.time()-t0,' sec')\n",
    "    #print('Total cost ',time.time()-t0,' sec')   \n",
    "    U, Y, A, E, Au, Ay, Aa, Av,B =sess.run([user_latent, item_latent, aux_item, embedding, Wu, Wy, Wa, Wv,Beta])\n",
    "    np.savez('../Data/grid_search_weight/new_dims/'+save_name+'.npz', \n",
    "                        U=U, Y=Y, A=A, E=E, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av,B=B)\n",
    "    return U, Y, A, E, Au, Ay, Aa, Av,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.01 1 1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[2.401668]]\n",
      "train_auc:------------------- 0.9595188284518829\n",
      "time: 172.1864197254181  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.47301975]]\n",
      "train_auc:------------------- 0.9815899581589959\n",
      "time: 344.4140074253082  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.41074175]]\n",
      "train_auc:------------------- 0.9866108786610879\n",
      "time: 516.2560789585114  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.3410428]]\n",
      "train_auc:------------------- 0.9878138075313807\n",
      "time: 688.1078984737396  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.28813824]]\n",
      "train_auc:------------------- 0.9836297071129707\n",
      "time: 860.0533907413483  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.25065586]]\n",
      "train_auc:------------------- 0.9791841004184101\n",
      "time: 1032.0190222263336  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.22590321]]\n",
      "train_auc:------------------- 0.9776150627615062\n",
      "time: 1203.7753105163574  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.20317069]]\n",
      "train_auc:------------------- 0.9771443514644351\n",
      "time: 1375.6014502048492  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.18709882]]\n",
      "train_auc:------------------- 0.9761506276150628\n",
      "time: 1547.5101792812347  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.1705375]]\n",
      "train_auc:------------------- 0.9782426778242678\n",
      "time: 1719.3399112224579  sec\n",
      "Finish, 0.01_0.01_1_1\n",
      "0.01 0.01 1 0.1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.6091034]]\n",
      "train_auc:------------------- 0.9450836820083682\n",
      "time: 173.08070611953735  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.367458]]\n",
      "train_auc:------------------- 0.963755230125523\n",
      "time: 345.4067225456238  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.33631516]]\n",
      "train_auc:------------------- 0.9749476987447698\n",
      "time: 517.8586337566376  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.3052164]]\n",
      "train_auc:------------------- 0.9809623430962343\n",
      "time: 690.0825128555298  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.271131]]\n",
      "train_auc:------------------- 0.9876046025104602\n",
      "time: 862.3414216041565  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.2481707]]\n",
      "train_auc:------------------- 0.9858786610878661\n",
      "time: 1034.6572816371918  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.23061755]]\n",
      "train_auc:------------------- 0.986663179916318\n",
      "time: 1206.9883480072021  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.21229558]]\n",
      "train_auc:------------------- 0.9856171548117155\n",
      "time: 1379.2399866580963  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.19459395]]\n",
      "train_auc:------------------- 0.9850418410041841\n",
      "time: 1551.4898099899292  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.18124545]]\n",
      "train_auc:------------------- 0.9855125523012552\n",
      "time: 1723.8366160392761  sec\n",
      "Finish, 0.01_0.01_1_0.1\n",
      "0.01 0.01 1 0.01 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.3661762]]\n",
      "train_auc:------------------- 0.9321129707112971\n",
      "time: 172.34588479995728  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.290304]]\n",
      "train_auc:------------------- 0.9579497907949791\n",
      "time: 344.31760025024414  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.276495]]\n",
      "train_auc:------------------- 0.9625\n",
      "time: 516.2756793498993  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.2523002]]\n",
      "train_auc:------------------- 0.971652719665272\n",
      "time: 688.209469795227  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.23166406]]\n",
      "train_auc:------------------- 0.9768828451882845\n",
      "time: 860.1419744491577  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.2180682]]\n",
      "train_auc:------------------- 0.9764644351464435\n",
      "time: 1032.1076996326447  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.19981469]]\n",
      "train_auc:------------------- 0.9824267782426779\n",
      "time: 1204.1377172470093  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.18881169]]\n",
      "train_auc:------------------- 0.9861401673640168\n",
      "time: 1376.1331596374512  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.18133979]]\n",
      "train_auc:------------------- 0.9829497907949791\n",
      "time: 1548.026119709015  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.17147805]]\n",
      "train_auc:------------------- 0.9865062761506276\n",
      "time: 1719.9804439544678  sec\n",
      "Finish, 0.01_0.01_1_0.01\n",
      "0.01 0.01 0.1 1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[2.2950885]]\n",
      "train_auc:------------------- 0.9565899581589958\n",
      "time: 172.44207859039307  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.34118968]]\n",
      "train_auc:------------------- 0.9760460251046025\n",
      "time: 344.31376814842224  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.32266006]]\n",
      "train_auc:------------------- 0.9768305439330544\n",
      "time: 515.9584653377533  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.28527805]]\n",
      "train_auc:------------------- 0.9856694560669456\n",
      "time: 687.7380335330963  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.26204923]]\n",
      "train_auc:------------------- 0.987081589958159\n",
      "time: 859.4381668567657  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.23905075]]\n",
      "train_auc:------------------- 0.9893828451882846\n",
      "time: 1031.066436290741  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.21559103]]\n",
      "train_auc:------------------- 0.9912133891213389\n",
      "time: 1202.7671029567719  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.20183127]]\n",
      "train_auc:------------------- 0.9915271966527197\n",
      "time: 1374.4132692813873  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.19122565]]\n",
      "train_auc:------------------- 0.9888598326359833\n",
      "time: 1546.1078038215637  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.1743275]]\n",
      "train_auc:------------------- 0.9912133891213389\n",
      "time: 1717.8375790119171  sec\n",
      "Finish, 0.01_0.01_0.1_1\n",
      "0.01 0.01 0.1 0.1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.52051806]]\n",
      "train_auc:------------------- 0.9529811715481171\n",
      "time: 170.59774589538574  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.26112205]]\n",
      "train_auc:------------------- 0.9671025104602511\n",
      "time: 340.9722089767456  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.24284919]]\n",
      "train_auc:------------------- 0.9738493723849372\n",
      "time: 511.3066129684448  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.23229575]]\n",
      "train_auc:------------------- 0.9754707112970711\n",
      "time: 681.6911523342133  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.21142316]]\n",
      "train_auc:------------------- 0.9807008368200837\n",
      "time: 852.0847022533417  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.19943039]]\n",
      "train_auc:------------------- 0.9819037656903765\n",
      "time: 1022.5007848739624  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.19004449]]\n",
      "train_auc:------------------- 0.9859832635983263\n",
      "time: 1192.8571019172668  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.1796859]]\n",
      "train_auc:------------------- 0.9863493723849373\n",
      "time: 1363.1886007785797  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.17173128]]\n",
      "train_auc:------------------- 0.9879707112970711\n",
      "time: 1533.4958765506744  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.16186014]]\n",
      "train_auc:------------------- 0.9896966527196652\n",
      "time: 1703.8064405918121  sec\n",
      "Finish, 0.01_0.01_0.1_0.1\n",
      "0.01 0.01 0.1 0.01 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.3236513]]\n",
      "train_auc:------------------- 0.9335251046025105\n",
      "time: 172.11696362495422  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.21546817]]\n",
      "train_auc:------------------- 0.9605648535564854\n",
      "time: 344.0360498428345  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.20219041]]\n",
      "train_auc:------------------- 0.9648535564853556\n",
      "time: 515.779932975769  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.17885418]]\n",
      "train_auc:------------------- 0.9745292887029289\n",
      "time: 687.685338973999  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.18281579]]\n",
      "train_auc:------------------- 0.9730648535564853\n",
      "time: 859.484780550003  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.17054676]]\n",
      "train_auc:------------------- 0.977092050209205\n",
      "time: 1031.3736300468445  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.15244165]]\n",
      "train_auc:------------------- 0.9825313807531381\n",
      "time: 1203.1985201835632  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.14530316]]\n",
      "train_auc:------------------- 0.9845188284518829\n",
      "time: 1375.0409371852875  sec\n",
      "Iteraction: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:----------------- [[0.14347523]]\n",
      "train_auc:------------------- 0.9848326359832636\n",
      "time: 1546.840432882309  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.13478759]]\n",
      "train_auc:------------------- 0.9869246861924686\n",
      "time: 1718.609989643097  sec\n",
      "Finish, 0.01_0.01_0.1_0.01\n",
      "0.01 0.01 0.01 1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[2.2783098]]\n",
      "train_auc:------------------- 0.9583682008368201\n",
      "time: 173.1306676864624  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.27166703]]\n",
      "train_auc:------------------- 0.9760460251046025\n",
      "time: 345.8827545642853  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.24005799]]\n",
      "train_auc:------------------- 0.9779811715481171\n",
      "time: 518.6777076721191  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.2183634]]\n",
      "train_auc:------------------- 0.9807008368200837\n",
      "time: 691.5116851329803  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.20963679]]\n",
      "train_auc:------------------- 0.9816422594142259\n",
      "time: 864.1979472637177  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.20935942]]\n",
      "train_auc:------------------- 0.9825313807531381\n",
      "time: 1036.9029746055603  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.18761379]]\n",
      "train_auc:------------------- 0.9865585774058577\n",
      "time: 1209.60347366333  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.17578317]]\n",
      "train_auc:------------------- 0.9882322175732218\n",
      "time: 1382.328716993332  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.17141758]]\n",
      "train_auc:------------------- 0.9883891213389121\n",
      "time: 1555.0428524017334  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.17210822]]\n",
      "train_auc:------------------- 0.9872384937238494\n",
      "time: 1727.8007681369781  sec\n",
      "Finish, 0.01_0.01_0.01_1\n",
      "0.01 0.01 0.01 0.1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.5088836]]\n",
      "train_auc:------------------- 0.9480648535564854\n",
      "time: 171.42935395240784  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.22679676]]\n",
      "train_auc:------------------- 0.9670502092050209\n",
      "time: 342.4287385940552  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.19183426]]\n",
      "train_auc:------------------- 0.9742677824267783\n",
      "time: 513.4072241783142  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.18467768]]\n",
      "train_auc:------------------- 0.9762552301255231\n",
      "time: 684.3644373416901  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.17200446]]\n",
      "train_auc:------------------- 0.9773535564853556\n",
      "time: 855.2531332969666  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.17656057]]\n",
      "train_auc:------------------- 0.9767259414225942\n",
      "time: 1026.1845517158508  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.16122654]]\n",
      "train_auc:------------------- 0.9795502092050209\n",
      "time: 1197.2020885944366  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.1568018]]\n",
      "train_auc:------------------- 0.9802301255230126\n",
      "time: 1368.1543657779694  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.1557326]]\n",
      "train_auc:------------------- 0.9801778242677824\n",
      "time: 1538.9925141334534  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.14672154]]\n",
      "train_auc:------------------- 0.9836297071129707\n",
      "time: 1709.985420703888  sec\n",
      "Finish, 0.01_0.01_0.01_0.1\n",
      "0.01 0.01 0.01 0.01 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.31173328]]\n",
      "train_auc:------------------- 0.9355125523012552\n",
      "time: 173.49198198318481  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.20264551]]\n",
      "train_auc:------------------- 0.9581589958158996\n",
      "time: 346.68617272377014  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.16539648]]\n",
      "train_auc:------------------- 0.9685146443514644\n",
      "time: 519.8953204154968  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.14842832]]\n",
      "train_auc:------------------- 0.974581589958159\n",
      "time: 693.0958511829376  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.14434388]]\n",
      "train_auc:------------------- 0.9742677824267783\n",
      "time: 866.226576089859  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.1316664]]\n",
      "train_auc:------------------- 0.9782426778242678\n",
      "time: 1039.353439092636  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.14254774]]\n",
      "train_auc:------------------- 0.9752615062761506\n",
      "time: 1212.4712805747986  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.12424354]]\n",
      "train_auc:------------------- 0.981694560669456\n",
      "time: 1385.6159591674805  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.12735642]]\n",
      "train_auc:------------------- 0.9802301255230126\n",
      "time: 1558.7406923770905  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.11689415]]\n",
      "train_auc:------------------- 0.9851987447698745\n",
      "time: 1732.0309879779816  sec\n",
      "Finish, 0.01_0.01_0.01_0.01\n",
      "0.01 0.001 1 1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[2.3950787]]\n",
      "train_auc:------------------- 0.9612447698744769\n",
      "time: 172.64366173744202  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.47259465]]\n",
      "train_auc:------------------- 0.9819037656903765\n",
      "time: 344.93610286712646  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.4071125]]\n",
      "train_auc:------------------- 0.9878661087866109\n",
      "time: 517.2930598258972  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.34226224]]\n",
      "train_auc:------------------- 0.9860355648535565\n",
      "time: 689.6455829143524  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.29126075]]\n",
      "train_auc:------------------- 0.9834205020920502\n",
      "time: 862.0838918685913  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.2544471]]\n",
      "train_auc:------------------- 0.9783995815899582\n",
      "time: 1034.454591035843  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.22776847]]\n",
      "train_auc:------------------- 0.9744246861924686\n",
      "time: 1206.8343126773834  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.20539574]]\n",
      "train_auc:------------------- 0.9757322175732217\n",
      "time: 1379.1613266468048  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.18719283]]\n",
      "train_auc:------------------- 0.9753138075313807\n",
      "time: 1551.5459759235382  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.17600456]]\n",
      "train_auc:------------------- 0.9751569037656904\n",
      "time: 1723.91290640831  sec\n",
      "Finish, 0.01_0.001_1_1\n",
      "0.01 0.001 1 0.1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.607792]]\n",
      "train_auc:------------------- 0.948326359832636\n",
      "time: 172.35625004768372  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.37206706]]\n",
      "train_auc:------------------- 0.9638075313807531\n",
      "time: 344.3489947319031  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.33522868]]\n",
      "train_auc:------------------- 0.9729602510460251\n",
      "time: 516.4224195480347  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.31146038]]\n",
      "train_auc:------------------- 0.9783472803347281\n",
      "time: 688.4379534721375  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.2758263]]\n",
      "train_auc:------------------- 0.9846757322175732\n",
      "time: 860.4389007091522  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.24491018]]\n",
      "train_auc:------------------- 0.9858786610878661\n",
      "time: 1032.4406445026398  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.22780882]]\n",
      "train_auc:------------------- 0.9860355648535565\n",
      "time: 1204.5097546577454  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.20670958]]\n",
      "train_auc:------------------- 0.9882845188284519\n",
      "time: 1376.6034240722656  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.19479176]]\n",
      "train_auc:------------------- 0.9856171548117155\n",
      "time: 1548.6533467769623  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.17873015]]\n",
      "train_auc:------------------- 0.986663179916318\n",
      "time: 1720.7580122947693  sec\n",
      "Finish, 0.01_0.001_1_0.1\n",
      "0.01 0.001 1 0.01 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.35146746]]\n",
      "train_auc:------------------- 0.9402719665271967\n",
      "time: 172.40612292289734  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.27957502]]\n",
      "train_auc:------------------- 0.9600941422594143\n",
      "time: 344.4922614097595  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.2677312]]\n",
      "train_auc:------------------- 0.9645397489539749\n",
      "time: 516.4203042984009  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.24797732]]\n",
      "train_auc:------------------- 0.9706066945606695\n",
      "time: 688.510746717453  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.23366475]]\n",
      "train_auc:------------------- 0.9731694560669456\n",
      "time: 860.6473250389099  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.2183181]]\n",
      "train_auc:------------------- 0.9782426778242678\n",
      "time: 1032.7101142406464  sec\n",
      "Iteraction: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:----------------- [[0.19969806]]\n",
      "train_auc:------------------- 0.9835251046025104\n",
      "time: 1204.782915353775  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.19145289]]\n",
      "train_auc:------------------- 0.9845188284518829\n",
      "time: 1376.8189771175385  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.17963152]]\n",
      "train_auc:------------------- 0.9849372384937238\n",
      "time: 1548.9640889167786  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.16566473]]\n",
      "train_auc:------------------- 0.9869769874476988\n",
      "time: 1721.1128549575806  sec\n",
      "Finish, 0.01_0.001_1_0.01\n",
      "0.01 0.001 0.1 1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[2.2988248]]\n",
      "train_auc:------------------- 0.9575836820083682\n",
      "time: 171.19646668434143  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.3415696]]\n",
      "train_auc:------------------- 0.9772489539748954\n",
      "time: 342.19838404655457  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.31775048]]\n",
      "train_auc:------------------- 0.9793410041841004\n",
      "time: 513.2224395275116  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.28406775]]\n",
      "train_auc:------------------- 0.9855125523012552\n",
      "time: 684.1909725666046  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.26016304]]\n",
      "train_auc:------------------- 0.9864539748953974\n",
      "time: 855.1363499164581  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.23725495]]\n",
      "train_auc:------------------- 0.989173640167364\n",
      "time: 1026.1443042755127  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.21266176]]\n",
      "train_auc:------------------- 0.9917364016736402\n",
      "time: 1197.145929813385  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.2061263]]\n",
      "train_auc:------------------- 0.9895397489539749\n",
      "time: 1368.1764538288116  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.1919238]]\n",
      "train_auc:------------------- 0.990847280334728\n",
      "time: 1539.2133491039276  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.18158387]]\n",
      "train_auc:------------------- 0.9903242677824268\n",
      "time: 1710.1915490627289  sec\n",
      "Finish, 0.01_0.001_0.1_1\n",
      "0.01 0.001 0.1 0.1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.5085392]]\n",
      "train_auc:------------------- 0.9542887029288702\n",
      "time: 172.97997856140137  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.26613763]]\n",
      "train_auc:------------------- 0.9652719665271966\n",
      "time: 345.75108432769775  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.24613002]]\n",
      "train_auc:------------------- 0.97081589958159\n",
      "time: 518.6324043273926  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.22816555]]\n",
      "train_auc:------------------- 0.9768828451882845\n",
      "time: 691.4976704120636  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.21277505]]\n",
      "train_auc:------------------- 0.9797071129707113\n",
      "time: 864.2574892044067  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.1987095]]\n",
      "train_auc:------------------- 0.9833158995815899\n",
      "time: 1037.0515604019165  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.19108841]]\n",
      "train_auc:------------------- 0.9836820083682009\n",
      "time: 1209.8693096637726  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.17831428]]\n",
      "train_auc:------------------- 0.9868723849372385\n",
      "time: 1382.6731629371643  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.17100699]]\n",
      "train_auc:------------------- 0.9877615062761507\n",
      "time: 1555.4502882957458  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.16249399]]\n",
      "train_auc:------------------- 0.9892259414225941\n",
      "time: 1728.20800614357  sec\n",
      "Finish, 0.01_0.001_0.1_0.1\n",
      "0.01 0.001 0.1 0.01 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.31368867]]\n",
      "train_auc:------------------- 0.9337866108786611\n",
      "time: 173.25773334503174  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.2081484]]\n",
      "train_auc:------------------- 0.9611924686192469\n",
      "time: 346.16159892082214  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.19556376]]\n",
      "train_auc:------------------- 0.967520920502092\n",
      "time: 519.1402218341827  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.18263657]]\n",
      "train_auc:------------------- 0.9706066945606695\n",
      "time: 692.1182444095612  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.17320518]]\n",
      "train_auc:------------------- 0.9744769874476987\n",
      "time: 865.0528657436371  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.16584943]]\n",
      "train_auc:------------------- 0.9768828451882845\n",
      "time: 1038.0165457725525  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.15751895]]\n",
      "train_auc:------------------- 0.9802824267782427\n",
      "time: 1211.1682393550873  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.14931476]]\n",
      "train_auc:------------------- 0.9849372384937238\n",
      "time: 1384.7132415771484  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.15012245]]\n",
      "train_auc:------------------- 0.981694560669456\n",
      "time: 1557.7028081417084  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.13315202]]\n",
      "train_auc:------------------- 0.9872907949790795\n",
      "time: 1730.6697595119476  sec\n",
      "Finish, 0.01_0.001_0.1_0.01\n",
      "0.01 0.001 0.01 1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[2.2682223]]\n",
      "train_auc:------------------- 0.960826359832636\n",
      "time: 171.23205471038818  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.27541482]]\n",
      "train_auc:------------------- 0.9760460251046025\n",
      "time: 342.2562072277069  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.23166884]]\n",
      "train_auc:------------------- 0.9814853556485356\n",
      "time: 513.2555584907532  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.2215681]]\n",
      "train_auc:------------------- 0.9806485355648535\n",
      "time: 684.3679051399231  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.21412207]]\n",
      "train_auc:------------------- 0.9819560669456067\n",
      "time: 855.3214933872223  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.20372275]]\n",
      "train_auc:------------------- 0.9825836820083682\n",
      "time: 1026.329259634018  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.18364215]]\n",
      "train_auc:------------------- 0.9880753138075313\n",
      "time: 1197.3228018283844  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.18760799]]\n",
      "train_auc:------------------- 0.9859309623430962\n",
      "time: 1368.2326047420502  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.17080183]]\n",
      "train_auc:------------------- 0.9881799163179916\n",
      "time: 1539.2848856449127  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.16409446]]\n",
      "train_auc:------------------- 0.9901150627615063\n",
      "time: 1710.2668693065643  sec\n",
      "Finish, 0.01_0.001_0.01_1\n",
      "0.01 0.001 0.01 0.1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.5043156]]\n",
      "train_auc:------------------- 0.9503138075313807\n",
      "time: 173.40899515151978  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.22540917]]\n",
      "train_auc:------------------- 0.9681485355648536\n",
      "time: 346.500524520874  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.19575281]]\n",
      "train_auc:------------------- 0.9731694560669456\n",
      "time: 519.5314056873322  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.18297897]]\n",
      "train_auc:------------------- 0.975836820083682\n",
      "time: 692.5556194782257  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.17712416]]\n",
      "train_auc:------------------- 0.9778242677824268\n",
      "time: 865.6285073757172  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.16127336]]\n",
      "train_auc:------------------- 0.9804916317991632\n",
      "time: 1038.7988250255585  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.16230868]]\n",
      "train_auc:------------------- 0.9803870292887029\n",
      "time: 1211.9260804653168  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.15611917]]\n",
      "train_auc:------------------- 0.9819560669456067\n",
      "time: 1385.079003572464  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.16262747]]\n",
      "train_auc:------------------- 0.979968619246862\n",
      "time: 1558.2016026973724  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.13833451]]\n",
      "train_auc:------------------- 0.9854602510460251\n",
      "time: 1731.3835940361023  sec\n",
      "Finish, 0.01_0.001_0.01_0.1\n",
      "0.01 0.001 0.01 0.01 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.3054247]]\n",
      "train_auc:------------------- 0.9385460251046025\n",
      "time: 172.59014129638672  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.1958358]]\n",
      "train_auc:------------------- 0.9623953974895397\n",
      "time: 344.7338228225708  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.16434152]]\n",
      "train_auc:------------------- 0.9698221757322176\n",
      "time: 516.9609298706055  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.15008469]]\n",
      "train_auc:------------------- 0.9730125523012553\n",
      "time: 689.2129461765289  sec\n",
      "Iteraction: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:----------------- [[0.14570868]]\n",
      "train_auc:------------------- 0.9736924686192469\n",
      "time: 861.394740819931  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.13533208]]\n",
      "train_auc:------------------- 0.9780857740585774\n",
      "time: 1033.6327812671661  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.13670151]]\n",
      "train_auc:------------------- 0.9766213389121339\n",
      "time: 1205.7475752830505  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.12693769]]\n",
      "train_auc:------------------- 0.980805439330544\n",
      "time: 1377.8576803207397  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.12121915]]\n",
      "train_auc:------------------- 0.9819560669456067\n",
      "time: 1549.9632542133331  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.11192633]]\n",
      "train_auc:------------------- 0.983734309623431\n",
      "time: 1722.1845738887787  sec\n",
      "Finish, 0.01_0.001_0.01_0.01\n",
      "0.01 0.0001 1 1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[2.3938453]]\n",
      "train_auc:------------------- 0.9617154811715481\n",
      "time: 172.4263129234314  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.47599617]]\n",
      "train_auc:------------------- 0.980805439330544\n",
      "time: 344.53782510757446  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.40983826]]\n",
      "train_auc:------------------- 0.9889644351464435\n",
      "time: 516.6593191623688  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.3483365]]\n",
      "train_auc:------------------- 0.9847803347280335\n",
      "time: 688.8361322879791  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.29596588]]\n",
      "train_auc:------------------- 0.9819037656903765\n",
      "time: 861.0145838260651  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.24975085]]\n",
      "train_auc:------------------- 0.9822698744769874\n",
      "time: 1033.1724092960358  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.22295251]]\n",
      "train_auc:------------------- 0.9797594142259414\n",
      "time: 1205.2925415039062  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.19942161]]\n",
      "train_auc:------------------- 0.9776150627615062\n",
      "time: 1377.4032905101776  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.18451878]]\n",
      "train_auc:------------------- 0.9774581589958159\n",
      "time: 1549.5400259494781  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.17561187]]\n",
      "train_auc:------------------- 0.9752615062761506\n",
      "time: 1721.6889917850494  sec\n",
      "Finish, 0.01_0.0001_1_1\n",
      "0.01 0.0001 1 0.1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.60547096]]\n",
      "train_auc:------------------- 0.9470188284518829\n",
      "time: 172.13085794448853  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.37035704]]\n",
      "train_auc:------------------- 0.964592050209205\n",
      "time: 343.9369523525238  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.33900538]]\n",
      "train_auc:------------------- 0.9713389121338912\n",
      "time: 515.910736322403  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.30300248]]\n",
      "train_auc:------------------- 0.9809100418410042\n",
      "time: 687.8172743320465  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.27386275]]\n",
      "train_auc:------------------- 0.984989539748954\n",
      "time: 859.7504827976227  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.24465513]]\n",
      "train_auc:------------------- 0.9895397489539749\n",
      "time: 1031.6273803710938  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.22289224]]\n",
      "train_auc:------------------- 0.9872907949790795\n",
      "time: 1203.52965092659  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.20897318]]\n",
      "train_auc:------------------- 0.984152719665272\n",
      "time: 1375.4180328845978  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.19462489]]\n",
      "train_auc:------------------- 0.9857740585774059\n",
      "time: 1547.3503313064575  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.18140848]]\n",
      "train_auc:------------------- 0.983786610878661\n",
      "time: 1719.2377390861511  sec\n",
      "Finish, 0.01_0.0001_1_0.1\n",
      "0.01 0.0001 1 0.01 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.35661253]]\n",
      "train_auc:------------------- 0.9382845188284519\n",
      "time: 170.73415970802307  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.27955806]]\n",
      "train_auc:------------------- 0.9600941422594143\n",
      "time: 341.15226316452026  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.2704284]]\n",
      "train_auc:------------------- 0.9642782426778242\n",
      "time: 511.62416315078735  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.25085396]]\n",
      "train_auc:------------------- 0.9714958158995816\n",
      "time: 682.0490026473999  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.2318039]]\n",
      "train_auc:------------------- 0.9735878661087866\n",
      "time: 852.4817337989807  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.21990938]]\n",
      "train_auc:------------------- 0.9803347280334728\n",
      "time: 1022.8886978626251  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.2004444]]\n",
      "train_auc:------------------- 0.9832112970711298\n",
      "time: 1193.3218200206757  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.19120026]]\n",
      "train_auc:------------------- 0.9835774058577406\n",
      "time: 1363.693220615387  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.1829768]]\n",
      "train_auc:------------------- 0.9854602510460251\n",
      "time: 1534.1042594909668  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.17435832]]\n",
      "train_auc:------------------- 0.9855648535564854\n",
      "time: 1704.5621416568756  sec\n",
      "Finish, 0.01_0.0001_1_0.01\n",
      "0.01 0.0001 0.1 1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[2.2957652]]\n",
      "train_auc:------------------- 0.9603556485355649\n",
      "time: 173.11109900474548  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.337851]]\n",
      "train_auc:------------------- 0.9756799163179917\n",
      "time: 345.7788622379303  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.30890796]]\n",
      "train_auc:------------------- 0.9807531380753138\n",
      "time: 518.4737222194672  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.29045722]]\n",
      "train_auc:------------------- 0.9827405857740585\n",
      "time: 691.2540283203125  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.26088935]]\n",
      "train_auc:------------------- 0.9862970711297071\n",
      "time: 863.9962995052338  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.23463771]]\n",
      "train_auc:------------------- 0.9896443514644352\n",
      "time: 1036.7075703144073  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.21328981]]\n",
      "train_auc:------------------- 0.9901150627615063\n",
      "time: 1209.475844860077  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.20421685]]\n",
      "train_auc:------------------- 0.9901673640167364\n",
      "time: 1382.2238581180573  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.1920494]]\n",
      "train_auc:------------------- 0.9890690376569038\n",
      "time: 1555.012374162674  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.18132584]]\n",
      "train_auc:------------------- 0.9901150627615063\n",
      "time: 1727.769645690918  sec\n",
      "Finish, 0.01_0.0001_0.1_1\n",
      "0.01 0.0001 0.1 0.1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.5400003]]\n",
      "train_auc:------------------- 0.9430962343096234\n",
      "time: 173.1790735721588  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.26900408]]\n",
      "train_auc:------------------- 0.9653242677824267\n",
      "time: 346.00005054473877  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.24375764]]\n",
      "train_auc:------------------- 0.9721757322175733\n",
      "time: 518.8813450336456  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.22258344]]\n",
      "train_auc:------------------- 0.9780857740585774\n",
      "time: 691.6738948822021  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.21159828]]\n",
      "train_auc:------------------- 0.9773535564853556\n",
      "time: 864.5430705547333  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.1995336]]\n",
      "train_auc:------------------- 0.9822698744769874\n",
      "time: 1037.259853363037  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.18469205]]\n",
      "train_auc:------------------- 0.9868723849372385\n",
      "time: 1210.1485919952393  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.1741896]]\n",
      "train_auc:------------------- 0.9877092050209205\n",
      "time: 1382.8676943778992  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.16734092]]\n",
      "train_auc:------------------- 0.9885460251046025\n",
      "time: 1555.6389291286469  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.16564421]]\n",
      "train_auc:------------------- 0.9881799163179916\n",
      "time: 1728.4941973686218  sec\n",
      "Finish, 0.01_0.0001_0.1_0.1\n",
      "0.01 0.0001 0.1 0.01 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.30624565]]\n",
      "train_auc:------------------- 0.9362970711297071\n",
      "time: 172.71851110458374  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.20447864]]\n",
      "train_auc:------------------- 0.9630753138075314\n",
      "time: 344.95235681533813  sec\n",
      "Iteraction: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:----------------- [[0.19738719]]\n",
      "train_auc:------------------- 0.9661087866108786\n",
      "time: 516.5474398136139  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.18535373]]\n",
      "train_auc:------------------- 0.9712343096234309\n",
      "time: 687.6913080215454  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.17952071]]\n",
      "train_auc:------------------- 0.9751569037656904\n",
      "time: 858.8258008956909  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.16162066]]\n",
      "train_auc:------------------- 0.9801778242677824\n",
      "time: 1030.0006051063538  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.15871863]]\n",
      "train_auc:------------------- 0.980805439330544\n",
      "time: 1201.132029056549  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.14696708]]\n",
      "train_auc:------------------- 0.9849372384937238\n",
      "time: 1372.0939102172852  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.14609575]]\n",
      "train_auc:------------------- 0.9857217573221757\n",
      "time: 1543.192709684372  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.14096059]]\n",
      "train_auc:------------------- 0.9855648535564854\n",
      "time: 1714.1989822387695  sec\n",
      "Finish, 0.01_0.0001_0.1_0.01\n",
      "0.01 0.0001 0.01 1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[2.2709386]]\n",
      "train_auc:------------------- 0.9597280334728033\n",
      "time: 173.18972992897034  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.27916187]]\n",
      "train_auc:------------------- 0.974163179916318\n",
      "time: 346.05805587768555  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.23617175]]\n",
      "train_auc:------------------- 0.980020920502092\n",
      "time: 518.9137318134308  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.22749713]]\n",
      "train_auc:------------------- 0.9797594142259414\n",
      "time: 691.9405825138092  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.21216407]]\n",
      "train_auc:------------------- 0.9817991631799163\n",
      "time: 865.0180351734161  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.20732479]]\n",
      "train_auc:------------------- 0.982897489539749\n",
      "time: 1038.412099123001  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.18472429]]\n",
      "train_auc:------------------- 0.9875523012552301\n",
      "time: 1212.8317511081696  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.1772266]]\n",
      "train_auc:------------------- 0.9883891213389121\n",
      "time: 1387.221512556076  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.17695692]]\n",
      "train_auc:------------------- 0.9873953974895398\n",
      "time: 1560.5871105194092  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.16303931]]\n",
      "train_auc:------------------- 0.9893828451882846\n",
      "time: 1733.4591584205627  sec\n",
      "Finish, 0.01_0.0001_0.01_1\n",
      "0.01 0.0001 0.01 0.1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.5104265]]\n",
      "train_auc:------------------- 0.9490062761506276\n",
      "time: 172.4925274848938  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.2252042]]\n",
      "train_auc:------------------- 0.9663702928870292\n",
      "time: 344.62577390670776  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.20385337]]\n",
      "train_auc:------------------- 0.9710251046025105\n",
      "time: 516.7515170574188  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.17983772]]\n",
      "train_auc:------------------- 0.9777719665271967\n",
      "time: 688.9607853889465  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.17205343]]\n",
      "train_auc:------------------- 0.9784518828451882\n",
      "time: 861.0960519313812  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.16660148]]\n",
      "train_auc:------------------- 0.9802824267782427\n",
      "time: 1033.3486285209656  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.1493882]]\n",
      "train_auc:------------------- 0.9832635983263598\n",
      "time: 1205.4922773838043  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.15581958]]\n",
      "train_auc:------------------- 0.9820083682008368\n",
      "time: 1377.6389226913452  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.14120208]]\n",
      "train_auc:------------------- 0.985826359832636\n",
      "time: 1549.9643862247467  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.14970572]]\n",
      "train_auc:------------------- 0.9831589958158996\n",
      "time: 1722.1693575382233  sec\n",
      "Finish, 0.01_0.0001_0.01_0.1\n",
      "0.01 0.0001 0.01 0.01 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.2990269]]\n",
      "train_auc:------------------- 0.9380230125523012\n",
      "time: 172.40233492851257  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.19269684]]\n",
      "train_auc:------------------- 0.9611924686192469\n",
      "time: 344.4802346229553  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.17814988]]\n",
      "train_auc:------------------- 0.9649058577405858\n",
      "time: 516.547271490097  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.15505655]]\n",
      "train_auc:------------------- 0.972907949790795\n",
      "time: 688.7083065509796  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.14633542]]\n",
      "train_auc:------------------- 0.9757845188284519\n",
      "time: 860.7162365913391  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.13842545]]\n",
      "train_auc:------------------- 0.9766213389121339\n",
      "time: 1032.801720380783  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.12477706]]\n",
      "train_auc:------------------- 0.9825836820083682\n",
      "time: 1204.9472370147705  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.12646343]]\n",
      "train_auc:------------------- 0.9806485355648535\n",
      "time: 1377.064757823944  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.11570666]]\n",
      "train_auc:------------------- 0.9843096234309623\n",
      "time: 1549.127922296524  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.12242837]]\n",
      "train_auc:------------------- 0.9819560669456067\n",
      "time: 1721.3392369747162  sec\n",
      "Finish, 0.01_0.0001_0.01_0.01\n",
      "0.01 1e-05 1 1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[2.4002843]]\n",
      "train_auc:------------------- 0.9618723849372385\n",
      "time: 171.6423716545105  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.47393098]]\n",
      "train_auc:------------------- 0.9809100418410042\n",
      "time: 342.83796882629395  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.4074652]]\n",
      "train_auc:------------------- 0.9871861924686193\n",
      "time: 514.0401108264923  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.34555992]]\n",
      "train_auc:------------------- 0.985826359832636\n",
      "time: 685.2538983821869  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.2893045]]\n",
      "train_auc:------------------- 0.9857740585774059\n",
      "time: 856.4645760059357  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.24961142]]\n",
      "train_auc:------------------- 0.9820083682008368\n",
      "time: 1027.7607824802399  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.22131462]]\n",
      "train_auc:------------------- 0.9786087866108787\n",
      "time: 1198.944060087204  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.2008577]]\n",
      "train_auc:------------------- 0.9756799163179917\n",
      "time: 1370.1646416187286  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.19011244]]\n",
      "train_auc:------------------- 0.9750523012552301\n",
      "time: 1541.3492546081543  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.17684878]]\n",
      "train_auc:------------------- 0.9754707112970711\n",
      "time: 1712.5773649215698  sec\n",
      "Finish, 0.01_1e-05_1_1\n",
      "0.01 1e-05 1 0.1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.6146654]]\n",
      "train_auc:------------------- 0.9463912133891214\n",
      "time: 171.37987160682678  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.37349272]]\n",
      "train_auc:------------------- 0.9626046025104602\n",
      "time: 342.30930495262146  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.34467268]]\n",
      "train_auc:------------------- 0.972907949790795\n",
      "time: 513.3889198303223  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.3071058]]\n",
      "train_auc:------------------- 0.9802824267782427\n",
      "time: 684.4601831436157  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.2754241]]\n",
      "train_auc:------------------- 0.9832112970711298\n",
      "time: 855.515305519104  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.25042218]]\n",
      "train_auc:------------------- 0.9859309623430962\n",
      "time: 1026.6010887622833  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.22099109]]\n",
      "train_auc:------------------- 0.9873430962343096\n",
      "time: 1197.6735928058624  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.20821622]]\n",
      "train_auc:------------------- 0.9850418410041841\n",
      "time: 1368.7422630786896  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.19408944]]\n",
      "train_auc:------------------- 0.9842573221757323\n",
      "time: 1539.8741171360016  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.18243687]]\n",
      "train_auc:------------------- 0.9859309623430962\n",
      "time: 1710.9839262962341  sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish, 0.01_1e-05_1_0.1\n",
      "0.01 1e-05 1 0.01 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.3707007]]\n",
      "train_auc:------------------- 0.9346234309623431\n",
      "time: 173.56282949447632  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.2905917]]\n",
      "train_auc:------------------- 0.9555962343096235\n",
      "time: 346.855256319046  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.26916888]]\n",
      "train_auc:------------------- 0.9660564853556486\n",
      "time: 520.0999524593353  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.24663365]]\n",
      "train_auc:------------------- 0.9725418410041841\n",
      "time: 693.4170715808868  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.23221883]]\n",
      "train_auc:------------------- 0.9760460251046025\n",
      "time: 866.7879745960236  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.21027508]]\n",
      "train_auc:------------------- 0.9803870292887029\n",
      "time: 1040.1018941402435  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.20203964]]\n",
      "train_auc:------------------- 0.982897489539749\n",
      "time: 1213.3828132152557  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.19123821]]\n",
      "train_auc:------------------- 0.983786610878661\n",
      "time: 1386.7001466751099  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.17798594]]\n",
      "train_auc:------------------- 0.9856694560669456\n",
      "time: 1560.0233330726624  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.17001186]]\n",
      "train_auc:------------------- 0.9886506276150627\n",
      "time: 1733.9987800121307  sec\n",
      "Finish, 0.01_1e-05_1_0.01\n",
      "0.01 1e-05 0.1 1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[2.294182]]\n",
      "train_auc:------------------- 0.9602510460251046\n",
      "time: 173.0262758731842  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.33964032]]\n",
      "train_auc:------------------- 0.9757322175732217\n",
      "time: 345.8130786418915  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.31333244]]\n",
      "train_auc:------------------- 0.9794979079497907\n",
      "time: 518.5917510986328  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.28264883]]\n",
      "train_auc:------------------- 0.9838389121338912\n",
      "time: 691.3401820659637  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.2620994]]\n",
      "train_auc:------------------- 0.9880230125523013\n",
      "time: 864.0797581672668  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.23488545]]\n",
      "train_auc:------------------- 0.990847280334728\n",
      "time: 1036.7685551643372  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.21668006]]\n",
      "train_auc:------------------- 0.9889644351464435\n",
      "time: 1209.5508460998535  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.20118497]]\n",
      "train_auc:------------------- 0.9918933054393305\n",
      "time: 1382.2266943454742  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.19280377]]\n",
      "train_auc:------------------- 0.9902196652719665\n",
      "time: 1554.963205575943  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.18291447]]\n",
      "train_auc:------------------- 0.9902719665271966\n",
      "time: 1727.729789018631  sec\n",
      "Finish, 0.01_1e-05_0.1_1\n",
      "0.01 1e-05 0.1 0.1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.52929705]]\n",
      "train_auc:------------------- 0.9481694560669456\n",
      "time: 172.72899651527405  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.27262592]]\n",
      "train_auc:------------------- 0.9643305439330544\n",
      "time: 344.9604232311249  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.23932059]]\n",
      "train_auc:------------------- 0.9736924686192469\n",
      "time: 517.3344104290009  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.22351567]]\n",
      "train_auc:------------------- 0.9787133891213389\n",
      "time: 689.7036969661713  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.21397549]]\n",
      "train_auc:------------------- 0.9809100418410042\n",
      "time: 862.0526537895203  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.20059413]]\n",
      "train_auc:------------------- 0.9820083682008368\n",
      "time: 1034.223871231079  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.18661703]]\n",
      "train_auc:------------------- 0.9855648535564854\n",
      "time: 1206.5488793849945  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.17421462]]\n",
      "train_auc:------------------- 0.9881276150627615\n",
      "time: 1378.8276019096375  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.16847683]]\n",
      "train_auc:------------------- 0.9873953974895398\n",
      "time: 1551.182559967041  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.16070169]]\n",
      "train_auc:------------------- 0.9888075313807532\n",
      "time: 1723.4407632350922  sec\n",
      "Finish, 0.01_1e-05_0.1_0.1\n",
      "0.01 1e-05 0.1 0.01 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.30807212]]\n",
      "train_auc:------------------- 0.9414748953974895\n",
      "time: 173.35639572143555  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.22108655]]\n",
      "train_auc:------------------- 0.9573744769874477\n",
      "time: 346.2959191799164  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.20111752]]\n",
      "train_auc:------------------- 0.9664748953974895\n",
      "time: 519.3125274181366  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.18160516]]\n",
      "train_auc:------------------- 0.9740585774058578\n",
      "time: 692.3132681846619  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.17224132]]\n",
      "train_auc:------------------- 0.977510460251046\n",
      "time: 865.2824709415436  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.16995826]]\n",
      "train_auc:------------------- 0.9785041841004184\n",
      "time: 1038.3004393577576  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.15899807]]\n",
      "train_auc:------------------- 0.9799163179916318\n",
      "time: 1211.3362588882446  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.15142651]]\n",
      "train_auc:------------------- 0.984152719665272\n",
      "time: 1384.4128744602203  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.1368069]]\n",
      "train_auc:------------------- 0.9868723849372385\n",
      "time: 1557.4783849716187  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.13853507]]\n",
      "train_auc:------------------- 0.9861401673640168\n",
      "time: 1730.4989144802094  sec\n",
      "Finish, 0.01_1e-05_0.1_0.01\n",
      "0.01 1e-05 0.01 1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[2.2728388]]\n",
      "train_auc:------------------- 0.9583158995815899\n",
      "time: 172.62979745864868  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.27664226]]\n",
      "train_auc:------------------- 0.9750523012552301\n",
      "time: 344.9765658378601  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.23639534]]\n",
      "train_auc:------------------- 0.9803347280334728\n",
      "time: 517.318776845932  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.22319919]]\n",
      "train_auc:------------------- 0.9798117154811715\n",
      "time: 689.6888151168823  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.21217272]]\n",
      "train_auc:------------------- 0.9830020920502092\n",
      "time: 862.0167453289032  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.20058328]]\n",
      "train_auc:------------------- 0.9838389121338912\n",
      "time: 1034.4378821849823  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.18620862]]\n",
      "train_auc:------------------- 0.9857217573221757\n",
      "time: 1206.793902873993  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.18097357]]\n",
      "train_auc:------------------- 0.9859832635983263\n",
      "time: 1379.1433851718903  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.16284788]]\n",
      "train_auc:------------------- 0.989592050209205\n",
      "time: 1551.5384423732758  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.17161773]]\n",
      "train_auc:------------------- 0.9872907949790795\n",
      "time: 1723.8658010959625  sec\n",
      "Finish, 0.01_1e-05_0.01_1\n",
      "0.01 1e-05 0.01 0.1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.51455337]]\n",
      "train_auc:------------------- 0.949163179916318\n",
      "time: 172.44115161895752  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.21826379]]\n",
      "train_auc:------------------- 0.9703451882845189\n",
      "time: 344.5872037410736  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.19944169]]\n",
      "train_auc:------------------- 0.9719142259414226\n",
      "time: 516.6467661857605  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.18171875]]\n",
      "train_auc:------------------- 0.9764121338912134\n",
      "time: 688.73810505867  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.16825028]]\n",
      "train_auc:------------------- 0.9777196652719665\n",
      "time: 860.8771469593048  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.1597879]]\n",
      "train_auc:------------------- 0.9817468619246862\n",
      "time: 1033.049433708191  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.16211456]]\n",
      "train_auc:------------------- 0.9814853556485356\n",
      "time: 1205.2621614933014  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.15513806]]\n",
      "train_auc:------------------- 0.9810146443514645\n",
      "time: 1377.3937084674835  sec\n",
      "Iteraction: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:----------------- [[0.14001273]]\n",
      "train_auc:------------------- 0.9857217573221757\n",
      "time: 1549.4606258869171  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.14726007]]\n",
      "train_auc:------------------- 0.9834728033472804\n",
      "time: 1721.577942609787  sec\n",
      "Finish, 0.01_1e-05_0.01_0.1\n",
      "0.01 1e-05 0.01 0.01 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.30458924]]\n",
      "train_auc:------------------- 0.9413179916317992\n",
      "time: 172.30079650878906  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.18889277]]\n",
      "train_auc:------------------- 0.9627092050209205\n",
      "time: 344.24811601638794  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.17118275]]\n",
      "train_auc:------------------- 0.968723849372385\n",
      "time: 516.2776250839233  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.16243395]]\n",
      "train_auc:------------------- 0.9700313807531381\n",
      "time: 688.3180012702942  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.1505895]]\n",
      "train_auc:------------------- 0.9733263598326359\n",
      "time: 860.4137010574341  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.13788505]]\n",
      "train_auc:------------------- 0.977510460251046\n",
      "time: 1032.4777734279633  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.12609619]]\n",
      "train_auc:------------------- 0.9802301255230126\n",
      "time: 1204.4902658462524  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.12157581]]\n",
      "train_auc:------------------- 0.9824790794979079\n",
      "time: 1376.5507125854492  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.11787411]]\n",
      "train_auc:------------------- 0.9820083682008368\n",
      "time: 1548.5903062820435  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.11797135]]\n",
      "train_auc:------------------- 0.984152719665272\n",
      "time: 1720.6043674945831  sec\n",
      "Finish, 0.01_1e-05_0.01_0.01\n",
      "0.001 0.01 1 1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[2.407276]]\n",
      "train_auc:------------------- 0.9572175732217573\n",
      "time: 171.36234593391418  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.4729676]]\n",
      "train_auc:------------------- 0.980805439330544\n",
      "time: 342.4238772392273  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.4062848]]\n",
      "train_auc:------------------- 0.9886506276150627\n",
      "time: 513.5357718467712  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.34950677]]\n",
      "train_auc:------------------- 0.984571129707113\n",
      "time: 684.6084752082825  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.2919178]]\n",
      "train_auc:------------------- 0.9830543933054393\n",
      "time: 855.7277276515961  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.25224409]]\n",
      "train_auc:------------------- 0.9788702928870293\n",
      "time: 1026.857041835785  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.21887997]]\n",
      "train_auc:------------------- 0.9798117154811715\n",
      "time: 1197.9476912021637  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.2073982]]\n",
      "train_auc:------------------- 0.9757845188284519\n",
      "time: 1369.8986647129059  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.18688059]]\n",
      "train_auc:------------------- 0.9760983263598326\n",
      "time: 1540.9912679195404  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.17442603]]\n",
      "train_auc:------------------- 0.9757322175732217\n",
      "time: 1711.994099855423  sec\n",
      "Finish, 0.001_0.01_1_1\n",
      "0.001 0.01 1 0.1 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.60621697]]\n",
      "train_auc:------------------- 0.9449267782426778\n",
      "time: 173.53050589561462  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.36952755]]\n",
      "train_auc:------------------- 0.9646443514644352\n",
      "time: 347.11305260658264  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.33538327]]\n",
      "train_auc:------------------- 0.9744246861924686\n",
      "time: 521.3553907871246  sec\n",
      "Iteraction: 3\n",
      "total_loss:----------------- [[0.30612782]]\n",
      "train_auc:------------------- 0.9794979079497907\n",
      "time: 695.3845086097717  sec\n",
      "Iteraction: 4\n",
      "total_loss:----------------- [[0.26649404]]\n",
      "train_auc:------------------- 0.9862970711297071\n",
      "time: 869.3569576740265  sec\n",
      "Iteraction: 5\n",
      "total_loss:----------------- [[0.24813907]]\n",
      "train_auc:------------------- 0.9867677824267782\n",
      "time: 1044.0269775390625  sec\n",
      "Iteraction: 6\n",
      "total_loss:----------------- [[0.22231568]]\n",
      "train_auc:------------------- 0.988336820083682\n",
      "time: 1217.9909813404083  sec\n",
      "Iteraction: 7\n",
      "total_loss:----------------- [[0.20796137]]\n",
      "train_auc:------------------- 0.986663179916318\n",
      "time: 1391.8419787883759  sec\n",
      "Iteraction: 8\n",
      "total_loss:----------------- [[0.18821602]]\n",
      "train_auc:------------------- 0.9872907949790795\n",
      "time: 1565.6520261764526  sec\n",
      "Iteraction: 9\n",
      "total_loss:----------------- [[0.18287355]]\n",
      "train_auc:------------------- 0.9835774058577406\n",
      "time: 1739.4076690673828  sec\n",
      "Finish, 0.001_0.01_1_0.1\n",
      "0.001 0.01 1 0.01 :START!!---------------\n",
      "Iteraction: 0\n",
      "total_loss:----------------- [[0.36971936]]\n",
      "train_auc:------------------- 0.9334205020920502\n",
      "time: 173.09050345420837  sec\n",
      "Iteraction: 1\n",
      "total_loss:----------------- [[0.29431906]]\n",
      "train_auc:------------------- 0.950418410041841\n",
      "time: 345.80338501930237  sec\n",
      "Iteraction: 2\n",
      "total_loss:----------------- [[0.27105018]]\n",
      "train_auc:------------------- 0.9645397489539749\n",
      "time: 519.168039560318  sec\n",
      "Iteraction: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-edd426d54cbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxuij\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                 \u001b[0mUr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAyr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAvr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpary_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpary_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m                 \u001b[1;31m#np.savez('../Data/grid_search_weight/new_dims/'+str(pary_weight)+'_'+str(pary_weight)+'_'+str(beta_weight)+'_'+str(Embedding_weight)+'.npz',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;31m#         U=Ur, Y=Yr, A=Ar, E=Er, Wu=Aur, Wy=Ayr, Wa=Aar, Wv=Avr,B=Br)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-83-8518b5b7af87>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(save_name)\u001b[0m\n\u001b[0;32m     90\u001b[0m                     _last_be_relu,_norm_par,_a_list,r3,_auc, _loss,_=sess.run([last_be_relu,norm_par,a_list,a_list_soft,auc,loss,train_op], feed_dict={user: [z],\n\u001b[0;32m     91\u001b[0m                                         \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mta\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_yes\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0ml_id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnew_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_id_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnew_r_3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                                         image_i:image_1,image_j:image_2})\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[1;31m#print(XUIJ)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ntu\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "par_weights = [0.01,0.001,0.0001,0.00001]\n",
    "beta_weights = [1,0.1,0.01]\n",
    "Embedding_weights = [1,0.1,0.01]\n",
    "for paru_weight in par_weights:\n",
    "    for pary_weight in par_weights:\n",
    "        for beta_weight in beta_weights:\n",
    "            for Embedding_weight in Embedding_weights:\n",
    "                print(paru_weight,pary_weight,beta_weight,Embedding_weight,':START!!---------------')\n",
    "                #clear_output()\n",
    "                \"\"\"\n",
    "                n: the number of users\n",
    "                m: the number of YouTubers\n",
    "                k: latent dims\n",
    "                l: feature dims\n",
    "                \"\"\"\n",
    "                tf.reset_default_graph()\n",
    "\n",
    "                user = tf.placeholder(tf.int32,shape=(1,))\n",
    "                i = tf.placeholder(tf.int32, shape=(1,))\n",
    "                j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "                #多少個auxliary \n",
    "                xf = tf.placeholder(tf.float32, shape=(None,l))\n",
    "                l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "                l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "                r = tf.placeholder(tf.float32,shape=(None,))\n",
    "\n",
    "\n",
    "                image_i = tf.placeholder(tf.float32, shape=(1,l))\n",
    "                image_j = tf.placeholder(tf.float32, shape=(1,l))\n",
    "\n",
    "                with tf.variable_scope(\"item_level\"):\n",
    "                    user_latent = tf.get_variable(\"user_latent\", [n, k],\n",
    "                                                      initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "                    item_latent = tf.get_variable(\"item_latent\", [m, k],\n",
    "                                                      initializer=tf.random_normal_initializer(0,0.1,seed=3)) \n",
    "                    aux_item = tf.get_variable(\"aux_item\", [m, k],\n",
    "                                                      initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "                    Wu = tf.get_variable(\"Wu\", [n,m,k],  #n*m*kt\n",
    "                                                      initializer=tf.contrib.layers.xavier_initializer())\n",
    "                    Wy = tf.get_variable(\"Wy\", [n,m,k],  #1*k 每個user都有一個wy\n",
    "                                                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "                    Wa = tf.get_variable(\"Wa\", [n,m,k],  #1*k\n",
    "                                                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "                    Wv = tf.get_variable(\"Wv\", [n,m,l],  #1*l\n",
    "                                                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "                    #每個user 對於每個YouTuber都有一個權重\n",
    "                    #w1拿掉，wu\n",
    "                    #hyper?\n",
    "                    \n",
    "                    aux_new = tf.get_variable(\"aux_new\", [1,k], initializer=tf.constant_initializer(0.0))\n",
    "                    ########## Error part, how to get auxisize dynamically\n",
    "                    ####aux_size= tf.get_variable(name='aux_size', initializer=l_id.get_shape().as_list()[-1])\n",
    "\n",
    "                with tf.variable_scope('feature_level'):\n",
    "                    embedding = tf.get_variable(\"embedding\", [embedding_dims,l],\n",
    "                                                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "                    Beta = tf.get_variable(\"beta\", [n,embedding_dims],\n",
    "                                             # initializer=tf.contrib.layers.xavier_initializer())\n",
    "                                                     initializer=tf.random_normal_initializer(0.01,0.001,seed=10))\n",
    "\n",
    "                #lookup the latent factors by user and id\n",
    "                u = tf.nn.embedding_lookup(user_latent, user) #(1*k) 第幾個user latent factor\n",
    "                vi = tf.nn.embedding_lookup(item_latent, i) \n",
    "                vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "                \n",
    "                \n",
    "                wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user)) #(m*k)\n",
    "                wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user)) #(m*k)\n",
    "                wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user)) #(m*k)\n",
    "                wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user)) #(m,l)\n",
    "                beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n",
    "\n",
    "\n",
    "                a_list=tf.Variable([])\n",
    "                q = tf.constant(0)\n",
    "                def att_cond(q,a_list):\n",
    "                    return tf.less(q,l_id_len[0])\n",
    "                def att_body(q,a_list):\n",
    "                    xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "                    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0)\n",
    "                    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0)\n",
    "                    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0)\n",
    "                    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0)\n",
    "                    a_list = tf.concat([a_list,[(tf.nn.relu( tf.matmul(wuui, u, transpose_b=True) +\n",
    "                            tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                            tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                            tf.matmul(wvui, xfi, transpose_b=True))[0][0])*r[q]]],0)\n",
    "                    q += 1\n",
    "                    return q,  a_list\n",
    "                _, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "                a_list_soft=tf.nn.softmax(a_list)\n",
    "                \n",
    "                norm_par = [wu,wy,wa,wv]\n",
    "                \n",
    "                wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "                wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "                waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "                wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "                wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "                wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "                wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "                wv_be_relu = tf.matmul(wvui, tf.expand_dims(xf[-1],0), transpose_b=True)\n",
    "                last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "                                       \n",
    "                aux_np = tf.expand_dims(tf.zeros(k),0) #dimension (1,32)\n",
    "                q = tf.constant(0)\n",
    "                def sum_att_cond(q,aux_np):\n",
    "                    return tf.less(q,l_id_len[0])\n",
    "\n",
    "                def sum_att_body(q,aux_np):\n",
    "                    #aux_np+=a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)\n",
    "                    aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "                    q += 1\n",
    "                    return q, aux_np\n",
    "\n",
    "                _,aux_np = tf.while_loop(sum_att_cond,sum_att_body,[q,aux_np])\n",
    "\n",
    "                \"\"\"\n",
    "                for q in range(3): #取q個auxliary item\n",
    "                    aux_np+=a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)\n",
    "                \"\"\"\n",
    "\n",
    "                aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "                #tf.print('aux attention:',aux_np)\n",
    "                aux_np+=u #user_latent factor + sum (alpha*auxilary)\n",
    "                aux_new=tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "\n",
    "                latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "                feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "                latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "                feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "                only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "                only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "                #矩陣中對應函數各自相乘\n",
    "                # ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "                xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "                xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "                xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "        \n",
    "                l2_norm = tf.add_n([\n",
    "                            0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "                            0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "                            0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "\n",
    "\n",
    "                            paru_weight * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "                            pary_weight * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "                            pary_weight * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "                            pary_weight * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "\n",
    "                            beta_weight * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "                            Embedding_weight * tf.reduce_sum(tf.multiply(embedding,embedding)),\n",
    "\n",
    "                          ])\n",
    "\n",
    "                loss = l2_norm -tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "                train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "                auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "                \n",
    "                Ur, Yr, Ar, Er, Aur, Ayr, Aar, Avr,Br = training(str(pary_weight)+'_'+str(pary_weight)+'_'+str(beta_weight)+'_'+str(Embedding_weight))\n",
    "                #np.savez('../Data/grid_search_weight/new_dims/'+str(pary_weight)+'_'+str(pary_weight)+'_'+str(beta_weight)+'_'+str(Embedding_weight)+'.npz', \n",
    "                #         U=Ur, Y=Yr, A=Ar, E=Er, Wu=Aur, Wy=Ayr, Wa=Aar, Wv=Avr,B=Br)\n",
    "                print('Finish,',str(paru_weight)+'_'+str(pary_weight)+'_'+str(beta_weight)+'_'+str(Embedding_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(U, Y, A, E, A1, Au, Ay, Aa, Av,B):\n",
    "    #print(A1)\n",
    "    result=np.zeros((test_amount,88))\n",
    "    RS=np.zeros((test_amount,88))\n",
    "    #test_idx --> Test 的 index\n",
    "    max1 = 0\n",
    "    maxu = 0\n",
    "    maxy = 0\n",
    "    maxa = 0\n",
    "    maxv = 0\n",
    "    min1 = 100000000000000000\n",
    "    minu = 100000000000000000\n",
    "    miny = 100000000000000000\n",
    "    mina = 100000000000000000\n",
    "    minv = 100000000000000000\n",
    "    test_yes_id=[]\n",
    "    for s in range(test_amount):\n",
    "        print(s,test_idx[s])\n",
    "\n",
    "        yes=[]\n",
    "        sample=random.sample(train_t[test_idx[s]],len(train_t[test_idx[s]])) #從training part 的positive feedback 取出YouTuber 當成Auxilary\n",
    "        #sample=result_yes_id[now]\n",
    "        test_yes_id.append(sample)\n",
    "        alpha=np.zeros([len(sample)])\n",
    "\n",
    "        for a in range(len(sample)):\n",
    "            r =np.max(YouTuber_category[sample[a]]*user_category_norm[test_idx[s]]) #sample a 的category vec *user_category vec\n",
    "            #print(test_idx[s])\n",
    "            #print(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0)))\n",
    "\n",
    "            #Observe each part in attention , below par are all (128,1)\n",
    "            testW1 = np.sum(A1[test_idx[s]])\n",
    "            #print(A1[test_idx[s]])\n",
    "            WuUu = np.sum(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0).T))\n",
    "            WyYy = np.sum(np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T))\n",
    "            WaAa = np.sum(np.dot(Aa[test_idx[s]],np.expand_dims(A[sample[a]],0).T))\n",
    "            WvVy = np.sum(np.dot(Av[test_idx[s]],np.expand_dims(all_3374[sample[a]],0).T))\n",
    "            print('The sum of each par -->\\nw1:',testW1,'\\nWuU:',WuUu,'\\nwyY:',WyYy,'\\nWaA:',WaAa,'\\nWvV:',WvVy)\n",
    "            if testW1 > max1:\n",
    "                max1 = testW1\n",
    "            if testW1 < min1:\n",
    "                min1 = testW1\n",
    "            if WuUu > maxu:\n",
    "                maxu = WuUu\n",
    "            if WuUu < minu:\n",
    "                minu = WuUu\n",
    "            if WyYy > maxy:\n",
    "                maxy = WyYy\n",
    "            if WyYy < miny:\n",
    "                miny = WyYy\n",
    "            if WaAa > maxa:\n",
    "                maxa = WaAa\n",
    "            if WaAa < mina:\n",
    "                mina = WaAa\n",
    "            if WvVy > maxv:\n",
    "                mxv = WvVy\n",
    "            if WvVy < minv:\n",
    "                minv = WvVy\n",
    "            #Have w1\n",
    "            #alpha[a]=np.dot(A1[test_idx[s]],(relu(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0).T)+np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T)+np.dot(Aa[test_idx[s]],\n",
    "            #                    np.expand_dims(A[sample[a]],0).T)+ np.dot(Av[test_idx[s]],np.expand_dims(all_3374[sample[a]],0).T))))*r\n",
    "            #Without w1\n",
    "            alpha[a]=np.sum((relu(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0).T)+np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T)+np.dot(Aa[test_idx[s]],\n",
    "                                np.expand_dims(A[sample[a]],0).T)+ np.dot(Av[test_idx[s]],np.expand_dims(all_3374[sample[a]],0).T))))*r\n",
    "        mul=np.zeros((1,128))\n",
    "        print('alpha------------',alpha)\n",
    "        print('softmax alpha--------------',softmax(alpha))\n",
    "        for i in range(len(sample)):\n",
    "            mul+=softmax(alpha)[i]*A[sample[i]] #attention alpha*Ai part \n",
    "        new_mul=mul+U[test_idx[s]]  #(U+auxilary)\n",
    "        for k in range(88):\n",
    "            result[s][k]=np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "            RS[s][k] = np.dot(new_mul,Y[k].T)+np.dot(B[test_idx[s]],np.dot(E, all_3374[k].T))\n",
    "    #print(max1,maxu,maxy,maxa,maxv)\n",
    "    #print(min1,minu,miny,mina,minv)\n",
    "    return RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "#從grid_search_weight中找尋不同的file \n",
    "path = '../Data/grid_search_weight/0105/'\n",
    "files = os.listdir(path)\n",
    "#U, Y, A, E, A1, Au, Ay, Aa, Av,B =sess.run([user_latent, item_latent, aux_item, embedding, W1, Wu, Wy, Wa, Wv,Beta])\n",
    "for file in files:\n",
    "    par_data = np.load(path+file)\n",
    "    U = par_data['U']\n",
    "    Y = par_data['Y']\n",
    "    A = par_data['A']\n",
    "    E = par_data['E']\n",
    "    W1 = par_data['W1']\n",
    "    Wu = par_data['Wu']\n",
    "    Wy = par_data['Wy']\n",
    "    Wa = par_data['Wa']\n",
    "    Wv = par_data['Wv']\n",
    "    B = par_data['B']\n",
    "    RS = testing(U, Y, A, E, W1, Wu, Wy, Wa, Wv,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent factor and Each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, Y, A, E, A1, Au, Ay, Aa, Av,B =sess.run([user_latent, item_latent, aux_item, embedding, W1, Wu, Wy, Wa, Wv,Beta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('User latent shape: ',U.shape)\n",
    "print('photo latent shape: ', Y.shape)\n",
    "print('Auxilary latent shape: ',A.shape)\n",
    "print('W1 weight shape: ',A1.shape)\n",
    "print('Wu weight shape:',Au.shape)\n",
    "print('Wy weight shape:', Ay.shape)\n",
    "print('Wa weight shape:',Aa.shape)\n",
    "print('Wv weight shape:',Av.shape)\n",
    "print('Beta shape:',B.shape)\n",
    "print('Embedding shape:',E.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-e7a19ef77cc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser_latent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_latent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_item\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBeta\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "U, Y, A, E, Au, Ay, Aa, Av,B =sess.run([user_latent, item_latent, aux_item, embedding, Wu, Wy, Wa, Wv,Beta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result=np.zeros((test_amount,88))\n",
    "RS=np.zeros((test_amount,88))\n",
    "#test_idx --> Test 的 index\n",
    "\n",
    "test_yes_id=[]\n",
    "for s in range(test_amount):\n",
    "    print(s,test_idx[s])\n",
    "\n",
    "    yes=[]\n",
    "    sample=random.sample(train_t[test_idx[s]],len(train_t[test_idx[s]])) #從training part 的positive feedback 取出YouTuber 當成Auxilary\n",
    "    #sample=result_yes_id[now]\n",
    "    test_yes_id.append(sample)\n",
    "    alpha=np.zeros([len(sample)])\n",
    "    \n",
    "    for a in range(len(sample)):\n",
    "        r =np.max(YouTuber_category[sample[a]]*user_category_norm[test_idx[s]]) #sample a 的category vec *user_category vec\n",
    "        #print(test_idx[s])\n",
    "        #print(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0)))\n",
    "        \n",
    "        #Observe each part in attention , below par are all (128,1)\n",
    "        testW1 = np.sum(np.multiply(A1[test_idx[s]],A1[test_idx[s]]))\n",
    "        WuUu = np.sum(np.multiply(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0).T),np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0).T)))\n",
    "        WyYy = np.sum(np.multiply(np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T),np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T)))\n",
    "        WaAa = np.sum(np.multiply(np.dot(Aa[test_idx[s]],np.expand_dims(A[sample[a]],0).T),np.dot(Aa[test_idx[s]],np.expand_dims(A[sample[a]],0).T)))\n",
    "        WvVy = np.sum(np.multiply(np.dot(Av[test_idx[s]],np.expand_dims(all_3374[sample[a]],0).T),np.dot(Av[test_idx[s]],np.expand_dims(all_3374[sample[a]],0).T)))\n",
    "        print('w1:',testW1,'\\nWuU:',WuUu,'\\nwyY:',WyYy,'\\nWaA:',WaAa,'\\nWvV:',WvVy)\n",
    "        \n",
    "        alpha[a]=np.dot(A1[test_idx[s]],(relu(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0).T)+np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T)+np.dot(Aa[test_idx[s]],\n",
    "                            np.expand_dims(A[sample[a]],0).T)+ np.dot(Av[test_idx[s]],np.expand_dims(all_3374[sample[a]],0).T))))*r\n",
    "    mul=np.zeros((1,128))\n",
    "    print('alpha------------',alpha)\n",
    "    print('softmax alpha--------------',softmax(alpha))\n",
    "    for i in range(len(sample)):\n",
    "        mul+=softmax(alpha)[i]*A[sample[i]] #attention alpha*Ai part \n",
    "    new_mul=mul+U[test_idx[s]]  #(U+auxilary)\n",
    "    for k in range(88):\n",
    "        result[s][k]=np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "        RS[s][k] = np.dot(new_mul,Y[k].T)+np.dot(B[test_idx[s]],np.dot(E, all_3374[k].T))\n",
    "#print(RS[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#取出test的資料\n",
    "testRS = np.zeros((test_amount,yt_test_amount)) #shape 150*20\n",
    "target = np.zeros((test_amount,yt_test_amount))\n",
    "#test_t 是true的\n",
    "#test_f 是false的\n",
    "        \n",
    "for z in range(test_amount):\n",
    "    user_id = test_idx[z]\n",
    "    #positive target YouTuber list\n",
    "    youtube_t = test_t[z] \n",
    "    #not target YouTuber list\n",
    "    youtube_f = test_f[z]\n",
    "    \n",
    "    #前兩個放target的RS\n",
    "    for i in range(len(youtube_t)):\n",
    "        testRS[z][i] = RS[z][youtube_t[i]]\n",
    "        target[z][i] = 1\n",
    "    for i in range(len(youtube_f)):\n",
    "        testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumtarget = 0\n",
    "for i in range(len(target)):\n",
    "    #print(np.sum(target[i]))\n",
    "    sumtarget += np.sum(target[i])\n",
    "print('num of positive data in testing:',sumtarget)\n",
    "print('total testing data:',test_amount*yt_test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN(sortlist,n):\n",
    "    topList = []\n",
    "    for i in range(n):\n",
    "        topList.append(sortlist.index(max(sortlist)))\n",
    "        #print(max(sortlist))\n",
    "        #print(sortlist.index(max(sortlist)))\n",
    "        sortlist[sortlist.index(max(sortlist))] = -1000000000\n",
    "    return topList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_0_all = []\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),int(np.sum(target[i])))\n",
    "    count_0_all.append(top_0)\n",
    "    print(top_0)\n",
    "\n",
    "acc_0 = 0\n",
    "total = 0\n",
    "for i in range(len(count_0_all)):\n",
    "    for j in range(len(count_0_all[i])):\n",
    "        #print(int(np.sum(target[i])))\n",
    "        total+=int(np.sum(target[i]))\n",
    "        if count_0_all[i][j] < int(np.sum(target[i])): #代表是0或1 (也就是target)\n",
    "            acc_0 += 1\n",
    "avg_acc = acc_0/100\n",
    "print('avg_accuarcy for count_0:',avg_acc)\n",
    "print(acc_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = (2*prec*rec)/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),1) #取一個\n",
    "    count_0_all.append(top_0)\n",
    "    print(top_0)\n",
    "    if top_0[0] < int(np.sum(target[i])):\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_prec = correct/len(testRS)\n",
    "top1_recall = correct/(sumtarget)\n",
    "print('prec ',top1_prec,'recall ',top1_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1 score\n",
    "print('F1_score:',F1_score(top1_prec,top1_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_3 = topN(list(testRS[i]),3) #取一個\n",
    "    count_0_all.append(top_3)\n",
    "    #print(top_3)\n",
    "    for j in range(len(top_3)):\n",
    "        if top_3[j] < int(np.sum(target[i])):\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_prec = correct/(len(testRS)*3)\n",
    "top3_recall = correct/(sumtarget)\n",
    "print('prec ',top3_prec,'recall ',top3_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1 score\n",
    "print('F1_score:',F1_score(top3_prec,top3_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_5 = topN(list(testRS[i]),5) #取一個\n",
    "    count_0_all.append(top_5)\n",
    "    #print(top_5)\n",
    "    for j in range(len(top_5)):\n",
    "        if top_5[j] < int(np.sum(target[i])):\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_prec = correct/(len(testRS)*5)\n",
    "top5_recall = correct/(sumtarget)\n",
    "print('prec ',top5_prec,'recall ',top5_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1 score\n",
    "print('F1_score:',F1_score(top5_prec,top5_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User_latent_factor = loaddata['User']\n",
    "#YouTuber_latent_factor = loaddata['YouTuber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('../Data/latent_factor/YRM_up10_ALL/Final/1226.npz', User=U, YouTuber=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x - np.max(x)\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax([-0.000000000000000000000000000000000000001,0.00000000000000000000000000000000000001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stuff\n",
      "ddkdkk\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stuff\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
